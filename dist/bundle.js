/******/ (function(modules) { // webpackBootstrap
/******/ 	// The module cache
/******/ 	var installedModules = {};
/******/
/******/ 	// The require function
/******/ 	function __webpack_require__(moduleId) {
/******/
/******/ 		// Check if module is in cache
/******/ 		if(installedModules[moduleId]) {
/******/ 			return installedModules[moduleId].exports;
/******/ 		}
/******/ 		// Create a new module (and put it into the cache)
/******/ 		var module = installedModules[moduleId] = {
/******/ 			i: moduleId,
/******/ 			l: false,
/******/ 			exports: {}
/******/ 		};
/******/
/******/ 		// Execute the module function
/******/ 		modules[moduleId].call(module.exports, module, module.exports, __webpack_require__);
/******/
/******/ 		// Flag the module as loaded
/******/ 		module.l = true;
/******/
/******/ 		// Return the exports of the module
/******/ 		return module.exports;
/******/ 	}
/******/
/******/
/******/ 	// expose the modules object (__webpack_modules__)
/******/ 	__webpack_require__.m = modules;
/******/
/******/ 	// expose the module cache
/******/ 	__webpack_require__.c = installedModules;
/******/
/******/ 	// define getter function for harmony exports
/******/ 	__webpack_require__.d = function(exports, name, getter) {
/******/ 		if(!__webpack_require__.o(exports, name)) {
/******/ 			Object.defineProperty(exports, name, { enumerable: true, get: getter });
/******/ 		}
/******/ 	};
/******/
/******/ 	// define __esModule on exports
/******/ 	__webpack_require__.r = function(exports) {
/******/ 		if(typeof Symbol !== 'undefined' && Symbol.toStringTag) {
/******/ 			Object.defineProperty(exports, Symbol.toStringTag, { value: 'Module' });
/******/ 		}
/******/ 		Object.defineProperty(exports, '__esModule', { value: true });
/******/ 	};
/******/
/******/ 	// create a fake namespace object
/******/ 	// mode & 1: value is a module id, require it
/******/ 	// mode & 2: merge all properties of value into the ns
/******/ 	// mode & 4: return value when already ns object
/******/ 	// mode & 8|1: behave like require
/******/ 	__webpack_require__.t = function(value, mode) {
/******/ 		if(mode & 1) value = __webpack_require__(value);
/******/ 		if(mode & 8) return value;
/******/ 		if((mode & 4) && typeof value === 'object' && value && value.__esModule) return value;
/******/ 		var ns = Object.create(null);
/******/ 		__webpack_require__.r(ns);
/******/ 		Object.defineProperty(ns, 'default', { enumerable: true, value: value });
/******/ 		if(mode & 2 && typeof value != 'string') for(var key in value) __webpack_require__.d(ns, key, function(key) { return value[key]; }.bind(null, key));
/******/ 		return ns;
/******/ 	};
/******/
/******/ 	// getDefaultExport function for compatibility with non-harmony modules
/******/ 	__webpack_require__.n = function(module) {
/******/ 		var getter = module && module.__esModule ?
/******/ 			function getDefault() { return module['default']; } :
/******/ 			function getModuleExports() { return module; };
/******/ 		__webpack_require__.d(getter, 'a', getter);
/******/ 		return getter;
/******/ 	};
/******/
/******/ 	// Object.prototype.hasOwnProperty.call
/******/ 	__webpack_require__.o = function(object, property) { return Object.prototype.hasOwnProperty.call(object, property); };
/******/
/******/ 	// __webpack_public_path__
/******/ 	__webpack_require__.p = "";
/******/
/******/
/******/ 	// Load entry module and return exports
/******/ 	return __webpack_require__(__webpack_require__.s = 0);
/******/ })
/************************************************************************/
/******/ ({

/***/ "../../../../usr/local/lib/node_modules/webpack/node_modules/node-libs-browser/mock/empty.js":
/*!**************************************************************!*\
  !*** (webpack)/node_modules/node-libs-browser/mock/empty.js ***!
  \**************************************************************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("\n\n//# sourceURL=webpack:///(webpack)/node_modules/node-libs-browser/mock/empty.js?");

/***/ }),

/***/ "./antlr4/BufferedTokenStream.js":
/*!***************************************!*\
  !*** ./antlr4/BufferedTokenStream.js ***!
  \***************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("//\n/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\n// This implementation of {@link TokenStream} loads tokens from a\n// {@link TokenSource} on-demand, and places the tokens in a buffer to provide\n// access to any previous token by index.\n//\n// <p>\n// This token stream ignores the value of {@link Token//getChannel}. If your\n// parser requires the token stream filter tokens to only those on a particular\n// channel, such as {@link Token//DEFAULT_CHANNEL} or\n// {@link Token//HIDDEN_CHANNEL}, use a filtering token stream such a\n// {@link CommonTokenStream}.</p>\n\nvar Token = __webpack_require__(/*! ./Token */ \"./antlr4/Token.js\").Token;\nvar Lexer = __webpack_require__(/*! ./Lexer */ \"./antlr4/Lexer.js\").Lexer;\nvar Interval = __webpack_require__(/*! ./IntervalSet */ \"./antlr4/IntervalSet.js\").Interval;\n\n// this is just to keep meaningful parameter types to Parser\nfunction TokenStream() {\n\treturn this;\n}\n\nfunction BufferedTokenStream(tokenSource) {\n\n\tTokenStream.call(this);\n\t// The {@link TokenSource} from which tokens for this stream are fetched.\n\tthis.tokenSource = tokenSource;\n\n\t// A collection of all tokens fetched from the token source. The list is\n\t// considered a complete view of the input once {@link //fetchedEOF} is set\n\t// to {@code true}.\n\tthis.tokens = [];\n\n\t// The index into {@link //tokens} of the current token (next token to\n\t// {@link //consume}). {@link //tokens}{@code [}{@link //p}{@code ]} should\n\t// be\n\t// {@link //LT LT(1)}.\n\t//\n\t// <p>This field is set to -1 when the stream is first constructed or when\n\t// {@link //setTokenSource} is called, indicating that the first token has\n\t// not yet been fetched from the token source. For additional information,\n\t// see the documentation of {@link IntStream} for a description of\n\t// Initializing Methods.</p>\n\tthis.index = -1;\n\n\t// Indicates whether the {@link Token//EOF} token has been fetched from\n\t// {@link //tokenSource} and added to {@link //tokens}. This field improves\n\t// performance for the following cases:\n\t//\n\t// <ul>\n\t// <li>{@link //consume}: The lookahead check in {@link //consume} to\n\t// prevent\n\t// consuming the EOF symbol is optimized by checking the values of\n\t// {@link //fetchedEOF} and {@link //p} instead of calling {@link\n\t// //LA}.</li>\n\t// <li>{@link //fetch}: The check to prevent adding multiple EOF symbols\n\t// into\n\t// {@link //tokens} is trivial with this field.</li>\n\t// <ul>\n\tthis.fetchedEOF = false;\n\treturn this;\n}\n\nBufferedTokenStream.prototype = Object.create(TokenStream.prototype);\nBufferedTokenStream.prototype.constructor = BufferedTokenStream;\n\nBufferedTokenStream.prototype.mark = function() {\n\treturn 0;\n};\n\nBufferedTokenStream.prototype.release = function(marker) {\n\t// no resources to release\n};\n\nBufferedTokenStream.prototype.reset = function() {\n\tthis.seek(0);\n};\n\nBufferedTokenStream.prototype.seek = function(index) {\n\tthis.lazyInit();\n\tthis.index = this.adjustSeekIndex(index);\n};\n\nBufferedTokenStream.prototype.get = function(index) {\n\tthis.lazyInit();\n\treturn this.tokens[index];\n};\n\nBufferedTokenStream.prototype.consume = function() {\n\tvar skipEofCheck = false;\n\tif (this.index >= 0) {\n\t\tif (this.fetchedEOF) {\n\t\t\t// the last token in tokens is EOF. skip check if p indexes any\n\t\t\t// fetched token except the last.\n\t\t\tskipEofCheck = this.index < this.tokens.length - 1;\n\t\t} else {\n\t\t\t// no EOF token in tokens. skip check if p indexes a fetched token.\n\t\t\tskipEofCheck = this.index < this.tokens.length;\n\t\t}\n\t} else {\n\t\t// not yet initialized\n\t\tskipEofCheck = false;\n\t}\n\tif (!skipEofCheck && this.LA(1) === Token.EOF) {\n\t\tthrow \"cannot consume EOF\";\n\t}\n\tif (this.sync(this.index + 1)) {\n\t\tthis.index = this.adjustSeekIndex(this.index + 1);\n\t}\n};\n\n// Make sure index {@code i} in tokens has a token.\n//\n// @return {@code true} if a token is located at index {@code i}, otherwise\n// {@code false}.\n// @see //get(int i)\n// /\nBufferedTokenStream.prototype.sync = function(i) {\n\tvar n = i - this.tokens.length + 1; // how many more elements we need?\n\tif (n > 0) {\n\t\tvar fetched = this.fetch(n);\n\t\treturn fetched >= n;\n\t}\n\treturn true;\n};\n\n// Add {@code n} elements to buffer.\n//\n// @return The actual number of elements added to the buffer.\n// /\nBufferedTokenStream.prototype.fetch = function(n) {\n\tif (this.fetchedEOF) {\n\t\treturn 0;\n\t}\n\tfor (var i = 0; i < n; i++) {\n\t\tvar t = this.tokenSource.nextToken();\n\t\tt.tokenIndex = this.tokens.length;\n\t\tthis.tokens.push(t);\n\t\tif (t.type === Token.EOF) {\n\t\t\tthis.fetchedEOF = true;\n\t\t\treturn i + 1;\n\t\t}\n\t}\n\treturn n;\n};\n\n// Get all tokens from start..stop inclusively///\nBufferedTokenStream.prototype.getTokens = function(start, stop, types) {\n\tif (types === undefined) {\n\t\ttypes = null;\n\t}\n\tif (start < 0 || stop < 0) {\n\t\treturn null;\n\t}\n\tthis.lazyInit();\n\tvar subset = [];\n\tif (stop >= this.tokens.length) {\n\t\tstop = this.tokens.length - 1;\n\t}\n\tfor (var i = start; i < stop; i++) {\n\t\tvar t = this.tokens[i];\n\t\tif (t.type === Token.EOF) {\n\t\t\tbreak;\n\t\t}\n\t\tif (types === null || types.contains(t.type)) {\n\t\t\tsubset.push(t);\n\t\t}\n\t}\n\treturn subset;\n};\n\nBufferedTokenStream.prototype.LA = function(i) {\n\treturn this.LT(i).type;\n};\n\nBufferedTokenStream.prototype.LB = function(k) {\n\tif (this.index - k < 0) {\n\t\treturn null;\n\t}\n\treturn this.tokens[this.index - k];\n};\n\nBufferedTokenStream.prototype.LT = function(k) {\n\tthis.lazyInit();\n\tif (k === 0) {\n\t\treturn null;\n\t}\n\tif (k < 0) {\n\t\treturn this.LB(-k);\n\t}\n\tvar i = this.index + k - 1;\n\tthis.sync(i);\n\tif (i >= this.tokens.length) { // return EOF token\n\t\t// EOF must be last token\n\t\treturn this.tokens[this.tokens.length - 1];\n\t}\n\treturn this.tokens[i];\n};\n\n// Allowed derived classes to modify the behavior of operations which change\n// the current stream position by adjusting the target token index of a seek\n// operation. The default implementation simply returns {@code i}. If an\n// exception is thrown in this method, the current stream index should not be\n// changed.\n//\n// <p>For example, {@link CommonTokenStream} overrides this method to ensure\n// that\n// the seek target is always an on-channel token.</p>\n//\n// @param i The target token index.\n// @return The adjusted target token index.\n\nBufferedTokenStream.prototype.adjustSeekIndex = function(i) {\n\treturn i;\n};\n\nBufferedTokenStream.prototype.lazyInit = function() {\n\tif (this.index === -1) {\n\t\tthis.setup();\n\t}\n};\n\nBufferedTokenStream.prototype.setup = function() {\n\tthis.sync(0);\n\tthis.index = this.adjustSeekIndex(0);\n};\n\n// Reset this token stream by setting its token source.///\nBufferedTokenStream.prototype.setTokenSource = function(tokenSource) {\n\tthis.tokenSource = tokenSource;\n\tthis.tokens = [];\n\tthis.index = -1;\n\tthis.fetchedEOF = false;\n};\n\n\n// Given a starting index, return the index of the next token on channel.\n// Return i if tokens[i] is on channel. Return -1 if there are no tokens\n// on channel between i and EOF.\n// /\nBufferedTokenStream.prototype.nextTokenOnChannel = function(i, channel) {\n\tthis.sync(i);\n\tif (i >= this.tokens.length) {\n\t\treturn -1;\n\t}\n\tvar token = this.tokens[i];\n\twhile (token.channel !== this.channel) {\n\t\tif (token.type === Token.EOF) {\n\t\t\treturn -1;\n\t\t}\n\t\ti += 1;\n\t\tthis.sync(i);\n\t\ttoken = this.tokens[i];\n\t}\n\treturn i;\n};\n\n// Given a starting index, return the index of the previous token on channel.\n// Return i if tokens[i] is on channel. Return -1 if there are no tokens\n// on channel between i and 0.\nBufferedTokenStream.prototype.previousTokenOnChannel = function(i, channel) {\n\twhile (i >= 0 && this.tokens[i].channel !== channel) {\n\t\ti -= 1;\n\t}\n\treturn i;\n};\n\n// Collect all tokens on specified channel to the right of\n// the current token up until we see a token on DEFAULT_TOKEN_CHANNEL or\n// EOF. If channel is -1, find any non default channel token.\nBufferedTokenStream.prototype.getHiddenTokensToRight = function(tokenIndex,\n\t\tchannel) {\n\tif (channel === undefined) {\n\t\tchannel = -1;\n\t}\n\tthis.lazyInit();\n\tif (tokenIndex < 0 || tokenIndex >= this.tokens.length) {\n\t\tthrow \"\" + tokenIndex + \" not in 0..\" + this.tokens.length - 1;\n\t}\n\tvar nextOnChannel = this.nextTokenOnChannel(tokenIndex + 1, Lexer.DEFAULT_TOKEN_CHANNEL);\n\tvar from_ = tokenIndex + 1;\n\t// if none onchannel to right, nextOnChannel=-1 so set to = last token\n\tvar to = nextOnChannel === -1 ? this.tokens.length - 1 : nextOnChannel;\n\treturn this.filterForChannel(from_, to, channel);\n};\n\n// Collect all tokens on specified channel to the left of\n// the current token up until we see a token on DEFAULT_TOKEN_CHANNEL.\n// If channel is -1, find any non default channel token.\nBufferedTokenStream.prototype.getHiddenTokensToLeft = function(tokenIndex,\n\t\tchannel) {\n\tif (channel === undefined) {\n\t\tchannel = -1;\n\t}\n\tthis.lazyInit();\n\tif (tokenIndex < 0 || tokenIndex >= this.tokens.length) {\n\t\tthrow \"\" + tokenIndex + \" not in 0..\" + this.tokens.length - 1;\n\t}\n\tvar prevOnChannel = this.previousTokenOnChannel(tokenIndex - 1, Lexer.DEFAULT_TOKEN_CHANNEL);\n\tif (prevOnChannel === tokenIndex - 1) {\n\t\treturn null;\n\t}\n\t// if none on channel to left, prevOnChannel=-1 then from=0\n\tvar from_ = prevOnChannel + 1;\n\tvar to = tokenIndex - 1;\n\treturn this.filterForChannel(from_, to, channel);\n};\n\nBufferedTokenStream.prototype.filterForChannel = function(left, right, channel) {\n\tvar hidden = [];\n\tfor (var i = left; i < right + 1; i++) {\n\t\tvar t = this.tokens[i];\n\t\tif (channel === -1) {\n\t\t\tif (t.channel !== Lexer.DEFAULT_TOKEN_CHANNEL) {\n\t\t\t\thidden.push(t);\n\t\t\t}\n\t\t} else if (t.channel === channel) {\n\t\t\thidden.push(t);\n\t\t}\n\t}\n\tif (hidden.length === 0) {\n\t\treturn null;\n\t}\n\treturn hidden;\n};\n\nBufferedTokenStream.prototype.getSourceName = function() {\n\treturn this.tokenSource.getSourceName();\n};\n\n// Get the text of all tokens in this buffer.///\nBufferedTokenStream.prototype.getText = function(interval) {\n\tthis.lazyInit();\n\tthis.fill();\n\tif (interval === undefined || interval === null) {\n\t\tinterval = new Interval(0, this.tokens.length - 1);\n\t}\n\tvar start = interval.start;\n\tif (start instanceof Token) {\n\t\tstart = start.tokenIndex;\n\t}\n\tvar stop = interval.stop;\n\tif (stop instanceof Token) {\n\t\tstop = stop.tokenIndex;\n\t}\n\tif (start === null || stop === null || start < 0 || stop < 0) {\n\t\treturn \"\";\n\t}\n\tif (stop >= this.tokens.length) {\n\t\tstop = this.tokens.length - 1;\n\t}\n\tvar s = \"\";\n\tfor (var i = start; i < stop + 1; i++) {\n\t\tvar t = this.tokens[i];\n\t\tif (t.type === Token.EOF) {\n\t\t\tbreak;\n\t\t}\n\t\ts = s + t.text;\n\t}\n\treturn s;\n};\n\n// Get all tokens from lexer until EOF///\nBufferedTokenStream.prototype.fill = function() {\n\tthis.lazyInit();\n\twhile (this.fetch(1000) === 1000) {\n\t\tcontinue;\n\t}\n};\n\nexports.BufferedTokenStream = BufferedTokenStream;\n\n\n//# sourceURL=webpack:///./antlr4/BufferedTokenStream.js?");

/***/ }),

/***/ "./antlr4/CharStreams.js":
/*!*******************************!*\
  !*** ./antlr4/CharStreams.js ***!
  \*******************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("//\n/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n//\n\nvar InputStream = __webpack_require__(/*! ./InputStream */ \"./antlr4/InputStream.js\").InputStream;\n\nvar isNodeJs = typeof window === 'undefined' && typeof importScripts === 'undefined';\nvar fs = isNodeJs ? __webpack_require__(/*! fs */ \"../../../../usr/local/lib/node_modules/webpack/node_modules/node-libs-browser/mock/empty.js\") : null;\n\n// Utility functions to create InputStreams from various sources.\n//\n// All returned InputStreams support the full range of Unicode\n// up to U+10FFFF (the default behavior of InputStream only supports\n// code points up to U+FFFF).\nvar CharStreams = {\n  // Creates an InputStream from a string.\n  fromString: function(str) {\n    return new InputStream(str, true);\n  },\n\n  // Asynchronously creates an InputStream from a blob given the\n  // encoding of the bytes in that blob (defaults to 'utf8' if\n  // encoding is null).\n  //\n  // Invokes onLoad(result) on success, onError(error) on\n  // failure.\n  fromBlob: function(blob, encoding, onLoad, onError) {\n    var reader = FileReader();\n    reader.onload = function(e) {\n      var is = new InputStream(e.target.result, true);\n      onLoad(is);\n    };\n    reader.onerror = onError;\n    reader.readAsText(blob, encoding);\n  },\n\n  // Creates an InputStream from a Buffer given the\n  // encoding of the bytes in that buffer (defaults to 'utf8' if\n  // encoding is null).\n  fromBuffer: function(buffer, encoding) {\n    return new InputStream(buffer.toString(encoding), true);\n  },\n\n  // Asynchronously creates an InputStream from a file on disk given\n  // the encoding of the bytes in that file (defaults to 'utf8' if\n  // encoding is null).\n  //\n  // Invokes callback(error, result) on completion.\n  fromPath: function(path, encoding, callback) {\n    fs.readFile(path, encoding, function(err, data) {\n      var is = null;\n      if (data !== null) {\n        is = new InputStream(data, true);\n      }\n      callback(err, is);\n    });\n  },\n\n  // Synchronously creates an InputStream given a path to a file\n  // on disk and the encoding of the bytes in that file (defaults to\n  // 'utf8' if encoding is null).\n  fromPathSync: function(path, encoding) {\n    var data = fs.readFileSync(path, encoding);\n    return new InputStream(data, true);\n  }\n};\n\nexports.CharStreams = CharStreams;\n\n\n//# sourceURL=webpack:///./antlr4/CharStreams.js?");

/***/ }),

/***/ "./antlr4/CommonTokenFactory.js":
/*!**************************************!*\
  !*** ./antlr4/CommonTokenFactory.js ***!
  \**************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("//\n/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n//\n\n//\n// This default implementation of {@link TokenFactory} creates\n// {@link CommonToken} objects.\n//\n\nvar CommonToken = __webpack_require__(/*! ./Token */ \"./antlr4/Token.js\").CommonToken;\n\nfunction TokenFactory() {\n\treturn this;\n}\n\nfunction CommonTokenFactory(copyText) {\n\tTokenFactory.call(this);\n    // Indicates whether {@link CommonToken//setText} should be called after\n    // constructing tokens to explicitly set the text. This is useful for cases\n    // where the input stream might not be able to provide arbitrary substrings\n    // of text from the input after the lexer creates a token (e.g. the\n    // implementation of {@link CharStream//getText} in\n    // {@link UnbufferedCharStream} throws an\n    // {@link UnsupportedOperationException}). Explicitly setting the token text\n    // allows {@link Token//getText} to be called at any time regardless of the\n    // input stream implementation.\n    //\n    // <p>\n    // The default value is {@code false} to avoid the performance and memory\n    // overhead of copying text for every token unless explicitly requested.</p>\n    //\n    this.copyText = copyText===undefined ? false : copyText;\n\treturn this;\n}\n\nCommonTokenFactory.prototype = Object.create(TokenFactory.prototype);\nCommonTokenFactory.prototype.constructor = CommonTokenFactory;\n\n//\n// The default {@link CommonTokenFactory} instance.\n//\n// <p>\n// This token factory does not explicitly copy token text when constructing\n// tokens.</p>\n//\nCommonTokenFactory.DEFAULT = new CommonTokenFactory();\n\nCommonTokenFactory.prototype.create = function(source, type, text, channel, start, stop, line, column) {\n    var t = new CommonToken(source, type, channel, start, stop);\n    t.line = line;\n    t.column = column;\n    if (text !==null) {\n        t.text = text;\n    } else if (this.copyText && source[1] !==null) {\n        t.text = source[1].getText(start,stop);\n    }\n    return t;\n};\n\nCommonTokenFactory.prototype.createThin = function(type, text) {\n    var t = new CommonToken(null, type);\n    t.text = text;\n    return t;\n};\n\nexports.CommonTokenFactory = CommonTokenFactory;\n\n\n//# sourceURL=webpack:///./antlr4/CommonTokenFactory.js?");

/***/ }),

/***/ "./antlr4/CommonTokenStream.js":
/*!*************************************!*\
  !*** ./antlr4/CommonTokenStream.js ***!
  \*************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("//\n/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n///\n\n//\n// This class extends {@link BufferedTokenStream} with functionality to filter\n// token streams to tokens on a particular channel (tokens where\n// {@link Token//getChannel} returns a particular value).\n//\n// <p>\n// This token stream provides access to all tokens by index or when calling\n// methods like {@link //getText}. The channel filtering is only used for code\n// accessing tokens via the lookahead methods {@link //LA}, {@link //LT}, and\n// {@link //LB}.</p>\n//\n// <p>\n// By default, tokens are placed on the default channel\n// ({@link Token//DEFAULT_CHANNEL}), but may be reassigned by using the\n// {@code ->channel(HIDDEN)} lexer command, or by using an embedded action to\n// call {@link Lexer//setChannel}.\n// </p>\n//\n// <p>\n// Note: lexer rules which use the {@code ->skip} lexer command or call\n// {@link Lexer//skip} do not produce tokens at all, so input text matched by\n// such a rule will not be available as part of the token stream, regardless of\n// channel.</p>\n///\n\nvar Token = __webpack_require__(/*! ./Token */ \"./antlr4/Token.js\").Token;\nvar BufferedTokenStream = __webpack_require__(/*! ./BufferedTokenStream */ \"./antlr4/BufferedTokenStream.js\").BufferedTokenStream;\n\nfunction CommonTokenStream(lexer, channel) {\n\tBufferedTokenStream.call(this, lexer);\n    this.channel = channel===undefined ? Token.DEFAULT_CHANNEL : channel;\n    return this;\n}\n\nCommonTokenStream.prototype = Object.create(BufferedTokenStream.prototype);\nCommonTokenStream.prototype.constructor = CommonTokenStream;\n\nCommonTokenStream.prototype.adjustSeekIndex = function(i) {\n    return this.nextTokenOnChannel(i, this.channel);\n};\n\nCommonTokenStream.prototype.LB = function(k) {\n    if (k===0 || this.index-k<0) {\n        return null;\n    }\n    var i = this.index;\n    var n = 1;\n    // find k good tokens looking backwards\n    while (n <= k) {\n        // skip off-channel tokens\n        i = this.previousTokenOnChannel(i - 1, this.channel);\n        n += 1;\n    }\n    if (i < 0) {\n        return null;\n    }\n    return this.tokens[i];\n};\n\nCommonTokenStream.prototype.LT = function(k) {\n    this.lazyInit();\n    if (k === 0) {\n        return null;\n    }\n    if (k < 0) {\n        return this.LB(-k);\n    }\n    var i = this.index;\n    var n = 1; // we know tokens[pos] is a good one\n    // find k good tokens\n    while (n < k) {\n        // skip off-channel tokens, but make sure to not look past EOF\n        if (this.sync(i + 1)) {\n            i = this.nextTokenOnChannel(i + 1, this.channel);\n        }\n        n += 1;\n    }\n    return this.tokens[i];\n};\n\n// Count EOF just once.///\nCommonTokenStream.prototype.getNumberOfOnChannelTokens = function() {\n    var n = 0;\n    this.fill();\n    for (var i =0; i< this.tokens.length;i++) {\n        var t = this.tokens[i];\n        if( t.channel===this.channel) {\n            n += 1;\n        }\n        if( t.type===Token.EOF) {\n            break;\n        }\n    }\n    return n;\n};\n\nexports.CommonTokenStream = CommonTokenStream;\n\n//# sourceURL=webpack:///./antlr4/CommonTokenStream.js?");

/***/ }),

/***/ "./antlr4/FileStream.js":
/*!******************************!*\
  !*** ./antlr4/FileStream.js ***!
  \******************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("//\n/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n//\n\n//\n//  This is an InputStream that is loaded from a file all at once\n//  when you construct the object.\n//\nvar InputStream = __webpack_require__(/*! ./InputStream */ \"./antlr4/InputStream.js\").InputStream;\nvar isNodeJs = typeof window === 'undefined' && typeof importScripts === 'undefined';\nvar fs = isNodeJs ? __webpack_require__(/*! fs */ \"../../../../usr/local/lib/node_modules/webpack/node_modules/node-libs-browser/mock/empty.js\") : null;\n\nfunction FileStream(fileName, decodeToUnicodeCodePoints) {\n\tvar data = fs.readFileSync(fileName, \"utf8\");\n\tInputStream.call(this, data, decodeToUnicodeCodePoints);\n\tthis.fileName = fileName;\n\treturn this;\n}\n\nFileStream.prototype = Object.create(InputStream.prototype);\nFileStream.prototype.constructor = FileStream;\n\nexports.FileStream = FileStream;\n\n\n//# sourceURL=webpack:///./antlr4/FileStream.js?");

/***/ }),

/***/ "./antlr4/InputStream.js":
/*!*******************************!*\
  !*** ./antlr4/InputStream.js ***!
  \*******************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("//\n/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n//\n\nvar Token = __webpack_require__(/*! ./Token */ \"./antlr4/Token.js\").Token;\n__webpack_require__(/*! ./polyfills/codepointat */ \"./antlr4/polyfills/codepointat.js\");\n__webpack_require__(/*! ./polyfills/fromcodepoint */ \"./antlr4/polyfills/fromcodepoint.js\");\n\n// Vacuum all input from a string and then treat it like a buffer.\n\nfunction _loadString(stream, decodeToUnicodeCodePoints) {\n\tstream._index = 0;\n\tstream.data = [];\n\tif (stream.decodeToUnicodeCodePoints) {\n\t\tfor (var i = 0; i < stream.strdata.length; ) {\n\t\t\tvar codePoint = stream.strdata.codePointAt(i);\n\t\t\tstream.data.push(codePoint);\n\t\t\ti += codePoint <= 0xFFFF ? 1 : 2;\n\t\t}\n\t} else {\n\t\tfor (var i = 0; i < stream.strdata.length; i++) {\n\t\t\tvar codeUnit = stream.strdata.charCodeAt(i);\n\t\t\tstream.data.push(codeUnit);\n\t\t}\n\t}\n\tstream._size = stream.data.length;\n}\n\n// If decodeToUnicodeCodePoints is true, the input is treated\n// as a series of Unicode code points.\n//\n// Otherwise, the input is treated as a series of 16-bit UTF-16 code\n// units.\nfunction InputStream(data, decodeToUnicodeCodePoints) {\n\tthis.name = \"<empty>\";\n\tthis.strdata = data;\n\tthis.decodeToUnicodeCodePoints = decodeToUnicodeCodePoints || false;\n\t_loadString(this);\n\treturn this;\n}\n\nObject.defineProperty(InputStream.prototype, \"index\", {\n\tget : function() {\n\t\treturn this._index;\n\t}\n});\n\nObject.defineProperty(InputStream.prototype, \"size\", {\n\tget : function() {\n\t\treturn this._size;\n\t}\n});\n\n// Reset the stream so that it's in the same state it was\n// when the object was created *except* the data array is not\n// touched.\n//\nInputStream.prototype.reset = function() {\n\tthis._index = 0;\n};\n\nInputStream.prototype.consume = function() {\n\tif (this._index >= this._size) {\n\t\t// assert this.LA(1) == Token.EOF\n\t\tthrow (\"cannot consume EOF\");\n\t}\n\tthis._index += 1;\n};\n\nInputStream.prototype.LA = function(offset) {\n\tif (offset === 0) {\n\t\treturn 0; // undefined\n\t}\n\tif (offset < 0) {\n\t\toffset += 1; // e.g., translate LA(-1) to use offset=0\n\t}\n\tvar pos = this._index + offset - 1;\n\tif (pos < 0 || pos >= this._size) { // invalid\n\t\treturn Token.EOF;\n\t}\n\treturn this.data[pos];\n};\n\nInputStream.prototype.LT = function(offset) {\n\treturn this.LA(offset);\n};\n\n// mark/release do nothing; we have entire buffer\nInputStream.prototype.mark = function() {\n\treturn -1;\n};\n\nInputStream.prototype.release = function(marker) {\n};\n\n// consume() ahead until p==_index; can't just set p=_index as we must\n// update line and column. If we seek backwards, just set p\n//\nInputStream.prototype.seek = function(_index) {\n\tif (_index <= this._index) {\n\t\tthis._index = _index; // just jump; don't update stream state (line,\n\t\t\t\t\t\t\t\t// ...)\n\t\treturn;\n\t}\n\t// seek forward\n\tthis._index = Math.min(_index, this._size);\n};\n\nInputStream.prototype.getText = function(start, stop) {\n\tif (stop >= this._size) {\n\t\tstop = this._size - 1;\n\t}\n\tif (start >= this._size) {\n\t\treturn \"\";\n\t} else {\n\t\tif (this.decodeToUnicodeCodePoints) {\n\t\t\tvar result = \"\";\n\t\t\tfor (var i = start; i <= stop; i++) {\n\t\t\t\tresult += String.fromCodePoint(this.data[i]);\n\t\t\t}\n\t\t\treturn result;\n\t\t} else {\n\t\t\treturn this.strdata.slice(start, stop + 1);\n\t\t}\n\t}\n};\n\nInputStream.prototype.toString = function() {\n\treturn this.strdata;\n};\n\nexports.InputStream = InputStream;\n\n\n//# sourceURL=webpack:///./antlr4/InputStream.js?");

/***/ }),

/***/ "./antlr4/IntervalSet.js":
/*!*******************************!*\
  !*** ./antlr4/IntervalSet.js ***!
  \*******************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\n/*jslint smarttabs:true */\n\nvar Token = __webpack_require__(/*! ./Token */ \"./antlr4/Token.js\").Token;\n\n/* stop is not included! */\nfunction Interval(start, stop) {\n\tthis.start = start;\n\tthis.stop = stop;\n\treturn this;\n}\n\nInterval.prototype.contains = function(item) {\n\treturn item >= this.start && item < this.stop;\n};\n\nInterval.prototype.toString = function() {\n\tif(this.start===this.stop-1) {\n\t\treturn this.start.toString();\n\t} else {\n\t\treturn this.start.toString() + \"..\" + (this.stop-1).toString();\n\t}\n};\n\n\nObject.defineProperty(Interval.prototype, \"length\", {\n\tget : function() {\n\t\treturn this.stop - this.start;\n\t}\n});\n\nfunction IntervalSet() {\n\tthis.intervals = null;\n\tthis.readOnly = false;\n}\n\nIntervalSet.prototype.first = function(v) {\n\tif (this.intervals === null || this.intervals.length===0) {\n\t\treturn Token.INVALID_TYPE;\n\t} else {\n\t\treturn this.intervals[0].start;\n\t}\n};\n\nIntervalSet.prototype.addOne = function(v) {\n\tthis.addInterval(new Interval(v, v + 1));\n};\n\nIntervalSet.prototype.addRange = function(l, h) {\n\tthis.addInterval(new Interval(l, h + 1));\n};\n\nIntervalSet.prototype.addInterval = function(v) {\n\tif (this.intervals === null) {\n\t\tthis.intervals = [];\n\t\tthis.intervals.push(v);\n\t} else {\n\t\t// find insert pos\n\t\tfor (var k = 0; k < this.intervals.length; k++) {\n\t\t\tvar i = this.intervals[k];\n\t\t\t// distinct range -> insert\n\t\t\tif (v.stop < i.start) {\n\t\t\t\tthis.intervals.splice(k, 0, v);\n\t\t\t\treturn;\n\t\t\t}\n\t\t\t// contiguous range -> adjust\n\t\t\telse if (v.stop === i.start) {\n\t\t\t\tthis.intervals[k].start = v.start;\n\t\t\t\treturn;\n\t\t\t}\n\t\t\t// overlapping range -> adjust and reduce\n\t\t\telse if (v.start <= i.stop) {\n\t\t\t\tthis.intervals[k] = new Interval(Math.min(i.start, v.start), Math.max(i.stop, v.stop));\n\t\t\t\tthis.reduce(k);\n\t\t\t\treturn;\n\t\t\t}\n\t\t}\n\t\t// greater than any existing\n\t\tthis.intervals.push(v);\n\t}\n};\n\nIntervalSet.prototype.addSet = function(other) {\n\tif (other.intervals !== null) {\n\t\tfor (var k = 0; k < other.intervals.length; k++) {\n\t\t\tvar i = other.intervals[k];\n\t\t\tthis.addInterval(new Interval(i.start, i.stop));\n\t\t}\n\t}\n\treturn this;\n};\n\nIntervalSet.prototype.reduce = function(k) {\n\t// only need to reduce if k is not the last\n\tif (k < this.intervalslength - 1) {\n\t\tvar l = this.intervals[k];\n\t\tvar r = this.intervals[k + 1];\n\t\t// if r contained in l\n\t\tif (l.stop >= r.stop) {\n\t\t\tthis.intervals.pop(k + 1);\n\t\t\tthis.reduce(k);\n\t\t} else if (l.stop >= r.start) {\n\t\t\tthis.intervals[k] = new Interval(l.start, r.stop);\n\t\t\tthis.intervals.pop(k + 1);\n\t\t}\n\t}\n};\n\nIntervalSet.prototype.complement = function(start, stop) {\n    var result = new IntervalSet();\n    result.addInterval(new Interval(start,stop+1));\n    for(var i=0; i<this.intervals.length; i++) {\n        result.removeRange(this.intervals[i]);\n    }\n    return result;\n};\n\nIntervalSet.prototype.contains = function(item) {\n\tif (this.intervals === null) {\n\t\treturn false;\n\t} else {\n\t\tfor (var k = 0; k < this.intervals.length; k++) {\n\t\t\tif(this.intervals[k].contains(item)) {\n\t\t\t\treturn true;\n\t\t\t}\n\t\t}\n\t\treturn false;\n\t}\n};\n\nObject.defineProperty(IntervalSet.prototype, \"length\", {\n\tget : function() {\n\t\tvar len = 0;\n\t\tthis.intervals.map(function(i) {len += i.length;});\n\t\treturn len;\n\t}\n});\n\nIntervalSet.prototype.removeRange = function(v) {\n    if(v.start===v.stop-1) {\n        this.removeOne(v.start);\n    } else if (this.intervals!==null) {\n        var k = 0;\n        for(var n=0; n<this.intervals.length; n++) {\n            var i = this.intervals[k];\n            // intervals are ordered\n            if (v.stop<=i.start) {\n                return;\n            }\n            // check for including range, split it\n            else if(v.start>i.start && v.stop<i.stop) {\n                this.intervals[k] = new Interval(i.start, v.start);\n                var x = new Interval(v.stop, i.stop);\n                this.intervals.splice(k, 0, x);\n                return;\n            }\n            // check for included range, remove it\n            else if(v.start<=i.start && v.stop>=i.stop) {\n                this.intervals.splice(k, 1);\n                k = k - 1; // need another pass\n            }\n            // check for lower boundary\n            else if(v.start<i.stop) {\n                this.intervals[k] = new Interval(i.start, v.start);\n            }\n            // check for upper boundary\n            else if(v.stop<i.stop) {\n                this.intervals[k] = new Interval(v.stop, i.stop);\n            }\n            k += 1;\n        }\n    }\n};\n\nIntervalSet.prototype.removeOne = function(v) {\n\tif (this.intervals !== null) {\n\t\tfor (var k = 0; k < this.intervals.length; k++) {\n\t\t\tvar i = this.intervals[k];\n\t\t\t// intervals is ordered\n\t\t\tif (v < i.start) {\n\t\t\t\treturn;\n\t\t\t}\n\t\t\t// check for single value range\n\t\t\telse if (v === i.start && v === i.stop - 1) {\n\t\t\t\tthis.intervals.splice(k, 1);\n\t\t\t\treturn;\n\t\t\t}\n\t\t\t// check for lower boundary\n\t\t\telse if (v === i.start) {\n\t\t\t\tthis.intervals[k] = new Interval(i.start + 1, i.stop);\n\t\t\t\treturn;\n\t\t\t}\n\t\t\t// check for upper boundary\n\t\t\telse if (v === i.stop - 1) {\n\t\t\t\tthis.intervals[k] = new Interval(i.start, i.stop - 1);\n\t\t\t\treturn;\n\t\t\t}\n\t\t\t// split existing range\n\t\t\telse if (v < i.stop - 1) {\n\t\t\t\tvar x = new Interval(i.start, v);\n\t\t\t\ti.start = v + 1;\n\t\t\t\tthis.intervals.splice(k, 0, x);\n\t\t\t\treturn;\n\t\t\t}\n\t\t}\n\t}\n};\n\nIntervalSet.prototype.toString = function(literalNames, symbolicNames, elemsAreChar) {\n\tliteralNames = literalNames || null;\n\tsymbolicNames = symbolicNames || null;\n\telemsAreChar = elemsAreChar || false;\n\tif (this.intervals === null) {\n\t\treturn \"{}\";\n\t} else if(literalNames!==null || symbolicNames!==null) {\n\t\treturn this.toTokenString(literalNames, symbolicNames);\n\t} else if(elemsAreChar) {\n\t\treturn this.toCharString();\n\t} else {\n\t\treturn this.toIndexString();\n\t}\n};\n\nIntervalSet.prototype.toCharString = function() {\n\tvar names = [];\n\tfor (var i = 0; i < this.intervals.length; i++) {\n\t\tvar v = this.intervals[i];\n\t\tif(v.stop===v.start+1) {\n\t\t\tif ( v.start===Token.EOF ) {\n\t\t\t\tnames.push(\"<EOF>\");\n\t\t\t} else {\n\t\t\t\tnames.push(\"'\" + String.fromCharCode(v.start) + \"'\");\n\t\t\t}\n\t\t} else {\n\t\t\tnames.push(\"'\" + String.fromCharCode(v.start) + \"'..'\" + String.fromCharCode(v.stop-1) + \"'\");\n\t\t}\n\t}\n\tif (names.length > 1) {\n\t\treturn \"{\" + names.join(\", \") + \"}\";\n\t} else {\n\t\treturn names[0];\n\t}\n};\n\n\nIntervalSet.prototype.toIndexString = function() {\n\tvar names = [];\n\tfor (var i = 0; i < this.intervals.length; i++) {\n\t\tvar v = this.intervals[i];\n\t\tif(v.stop===v.start+1) {\n\t\t\tif ( v.start===Token.EOF ) {\n\t\t\t\tnames.push(\"<EOF>\");\n\t\t\t} else {\n\t\t\t\tnames.push(v.start.toString());\n\t\t\t}\n\t\t} else {\n\t\t\tnames.push(v.start.toString() + \"..\" + (v.stop-1).toString());\n\t\t}\n\t}\n\tif (names.length > 1) {\n\t\treturn \"{\" + names.join(\", \") + \"}\";\n\t} else {\n\t\treturn names[0];\n\t}\n};\n\n\nIntervalSet.prototype.toTokenString = function(literalNames, symbolicNames) {\n\tvar names = [];\n\tfor (var i = 0; i < this.intervals.length; i++) {\n\t\tvar v = this.intervals[i];\n\t\tfor (var j = v.start; j < v.stop; j++) {\n\t\t\tnames.push(this.elementName(literalNames, symbolicNames, j));\n\t\t}\n\t}\n\tif (names.length > 1) {\n\t\treturn \"{\" + names.join(\", \") + \"}\";\n\t} else {\n\t\treturn names[0];\n\t}\n};\n\nIntervalSet.prototype.elementName = function(literalNames, symbolicNames, a) {\n\tif (a === Token.EOF) {\n\t\treturn \"<EOF>\";\n\t} else if (a === Token.EPSILON) {\n\t\treturn \"<EPSILON>\";\n\t} else {\n\t\treturn literalNames[a] || symbolicNames[a];\n\t}\n};\n\nexports.Interval = Interval;\nexports.IntervalSet = IntervalSet;\n\n\n//# sourceURL=webpack:///./antlr4/IntervalSet.js?");

/***/ }),

/***/ "./antlr4/LL1Analyzer.js":
/*!*******************************!*\
  !*** ./antlr4/LL1Analyzer.js ***!
  \*******************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("//\n/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n///\n\nvar Set = __webpack_require__(/*! ./Utils */ \"./antlr4/Utils.js\").Set;\nvar BitSet = __webpack_require__(/*! ./Utils */ \"./antlr4/Utils.js\").BitSet;\nvar Token = __webpack_require__(/*! ./Token */ \"./antlr4/Token.js\").Token;\nvar ATNConfig = __webpack_require__(/*! ./atn/ATNConfig */ \"./antlr4/atn/ATNConfig.js\").ATNConfig;\nvar Interval = __webpack_require__(/*! ./IntervalSet */ \"./antlr4/IntervalSet.js\").Interval;\nvar IntervalSet = __webpack_require__(/*! ./IntervalSet */ \"./antlr4/IntervalSet.js\").IntervalSet;\nvar RuleStopState = __webpack_require__(/*! ./atn/ATNState */ \"./antlr4/atn/ATNState.js\").RuleStopState;\nvar RuleTransition = __webpack_require__(/*! ./atn/Transition */ \"./antlr4/atn/Transition.js\").RuleTransition;\nvar NotSetTransition = __webpack_require__(/*! ./atn/Transition */ \"./antlr4/atn/Transition.js\").NotSetTransition;\nvar WildcardTransition = __webpack_require__(/*! ./atn/Transition */ \"./antlr4/atn/Transition.js\").WildcardTransition;\nvar AbstractPredicateTransition = __webpack_require__(/*! ./atn/Transition */ \"./antlr4/atn/Transition.js\").AbstractPredicateTransition;\n\nvar pc = __webpack_require__(/*! ./PredictionContext */ \"./antlr4/PredictionContext.js\");\nvar predictionContextFromRuleContext = pc.predictionContextFromRuleContext;\nvar PredictionContext = pc.PredictionContext;\nvar SingletonPredictionContext = pc.SingletonPredictionContext;\n\nfunction LL1Analyzer (atn) {\n    this.atn = atn;\n}\n\n//* Special value added to the lookahead sets to indicate that we hit\n//  a predicate during analysis if {@code seeThruPreds==false}.\n///\nLL1Analyzer.HIT_PRED = Token.INVALID_TYPE;\n\n\n//*\n// Calculates the SLL(1) expected lookahead set for each outgoing transition\n// of an {@link ATNState}. The returned array has one element for each\n// outgoing transition in {@code s}. If the closure from transition\n// <em>i</em> leads to a semantic predicate before matching a symbol, the\n// element at index <em>i</em> of the result will be {@code null}.\n//\n// @param s the ATN state\n// @return the expected symbols for each outgoing transition of {@code s}.\n///\nLL1Analyzer.prototype.getDecisionLookahead = function(s) {\n    if (s === null) {\n        return null;\n    }\n    var count = s.transitions.length;\n    var look = [];\n    for(var alt=0; alt< count; alt++) {\n        look[alt] = new IntervalSet();\n        var lookBusy = new Set();\n        var seeThruPreds = false; // fail to get lookahead upon pred\n        this._LOOK(s.transition(alt).target, null, PredictionContext.EMPTY,\n              look[alt], lookBusy, new BitSet(), seeThruPreds, false);\n        // Wipe out lookahead for this alternative if we found nothing\n        // or we had a predicate when we !seeThruPreds\n        if (look[alt].length===0 || look[alt].contains(LL1Analyzer.HIT_PRED)) {\n            look[alt] = null;\n        }\n    }\n    return look;\n};\n\n//*\n// Compute set of tokens that can follow {@code s} in the ATN in the\n// specified {@code ctx}.\n//\n// <p>If {@code ctx} is {@code null} and the end of the rule containing\n// {@code s} is reached, {@link Token//EPSILON} is added to the result set.\n// If {@code ctx} is not {@code null} and the end of the outermost rule is\n// reached, {@link Token//EOF} is added to the result set.</p>\n//\n// @param s the ATN state\n// @param stopState the ATN state to stop at. This can be a\n// {@link BlockEndState} to detect epsilon paths through a closure.\n// @param ctx the complete parser context, or {@code null} if the context\n// should be ignored\n//\n// @return The set of tokens that can follow {@code s} in the ATN in the\n// specified {@code ctx}.\n///\nLL1Analyzer.prototype.LOOK = function(s, stopState, ctx) {\n    var r = new IntervalSet();\n    var seeThruPreds = true; // ignore preds; get all lookahead\n\tctx = ctx || null;\n    var lookContext = ctx!==null ? predictionContextFromRuleContext(s.atn, ctx) : null;\n    this._LOOK(s, stopState, lookContext, r, new Set(), new BitSet(), seeThruPreds, true);\n    return r;\n};\n\n//*\n// Compute set of tokens that can follow {@code s} in the ATN in the\n// specified {@code ctx}.\n//\n// <p>If {@code ctx} is {@code null} and {@code stopState} or the end of the\n// rule containing {@code s} is reached, {@link Token//EPSILON} is added to\n// the result set. If {@code ctx} is not {@code null} and {@code addEOF} is\n// {@code true} and {@code stopState} or the end of the outermost rule is\n// reached, {@link Token//EOF} is added to the result set.</p>\n//\n// @param s the ATN state.\n// @param stopState the ATN state to stop at. This can be a\n// {@link BlockEndState} to detect epsilon paths through a closure.\n// @param ctx The outer context, or {@code null} if the outer context should\n// not be used.\n// @param look The result lookahead set.\n// @param lookBusy A set used for preventing epsilon closures in the ATN\n// from causing a stack overflow. Outside code should pass\n// {@code new Set<ATNConfig>} for this argument.\n// @param calledRuleStack A set used for preventing left recursion in the\n// ATN from causing a stack overflow. Outside code should pass\n// {@code new BitSet()} for this argument.\n// @param seeThruPreds {@code true} to true semantic predicates as\n// implicitly {@code true} and \"see through them\", otherwise {@code false}\n// to treat semantic predicates as opaque and add {@link //HIT_PRED} to the\n// result if one is encountered.\n// @param addEOF Add {@link Token//EOF} to the result if the end of the\n// outermost context is reached. This parameter has no effect if {@code ctx}\n// is {@code null}.\n///\nLL1Analyzer.prototype._LOOK = function(s, stopState , ctx, look, lookBusy, calledRuleStack, seeThruPreds, addEOF) {\n    var c = new ATNConfig({state:s, alt:0, context: ctx}, null);\n    if (lookBusy.contains(c)) {\n        return;\n    }\n    lookBusy.add(c);\n    if (s === stopState) {\n        if (ctx ===null) {\n            look.addOne(Token.EPSILON);\n            return;\n        } else if (ctx.isEmpty() && addEOF) {\n            look.addOne(Token.EOF);\n            return;\n        }\n    }\n    if (s instanceof RuleStopState ) {\n        if (ctx ===null) {\n            look.addOne(Token.EPSILON);\n            return;\n        } else if (ctx.isEmpty() && addEOF) {\n            look.addOne(Token.EOF);\n            return;\n        }\n        if (ctx !== PredictionContext.EMPTY) {\n            // run thru all possible stack tops in ctx\n            for(var i=0; i<ctx.length; i++) {\n                var returnState = this.atn.states[ctx.getReturnState(i)];\n                var removed = calledRuleStack.contains(returnState.ruleIndex);\n                try {\n                    calledRuleStack.remove(returnState.ruleIndex);\n                    this._LOOK(returnState, stopState, ctx.getParent(i), look, lookBusy, calledRuleStack, seeThruPreds, addEOF);\n                } finally {\n                    if (removed) {\n                        calledRuleStack.add(returnState.ruleIndex);\n                    }\n                }\n            }\n            return;\n        }\n    }\n    for(var j=0; j<s.transitions.length; j++) {\n        var t = s.transitions[j];\n        if (t.constructor === RuleTransition) {\n            if (calledRuleStack.contains(t.target.ruleIndex)) {\n                continue;\n            }\n            var newContext = SingletonPredictionContext.create(ctx, t.followState.stateNumber);\n            try {\n                calledRuleStack.add(t.target.ruleIndex);\n                this._LOOK(t.target, stopState, newContext, look, lookBusy, calledRuleStack, seeThruPreds, addEOF);\n            } finally {\n                calledRuleStack.remove(t.target.ruleIndex);\n            }\n        } else if (t instanceof AbstractPredicateTransition ) {\n            if (seeThruPreds) {\n                this._LOOK(t.target, stopState, ctx, look, lookBusy, calledRuleStack, seeThruPreds, addEOF);\n            } else {\n                look.addOne(LL1Analyzer.HIT_PRED);\n            }\n        } else if( t.isEpsilon) {\n            this._LOOK(t.target, stopState, ctx, look, lookBusy, calledRuleStack, seeThruPreds, addEOF);\n        } else if (t.constructor === WildcardTransition) {\n            look.addRange( Token.MIN_USER_TOKEN_TYPE, this.atn.maxTokenType );\n        } else {\n            var set = t.label;\n            if (set !== null) {\n                if (t instanceof NotSetTransition) {\n                    set = set.complement(Token.MIN_USER_TOKEN_TYPE, this.atn.maxTokenType);\n                }\n                look.addSet(set);\n            }\n        }\n    }\n};\n\nexports.LL1Analyzer = LL1Analyzer;\n\n\n\n//# sourceURL=webpack:///./antlr4/LL1Analyzer.js?");

/***/ }),

/***/ "./antlr4/Lexer.js":
/*!*************************!*\
  !*** ./antlr4/Lexer.js ***!
  \*************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n///\n\n// A lexer is recognizer that draws input symbols from a character stream.\n//  lexer grammars result in a subclass of this object. A Lexer object\n//  uses simplified match() and error recovery mechanisms in the interest of speed.\n\nvar Token = __webpack_require__(/*! ./Token */ \"./antlr4/Token.js\").Token;\nvar Recognizer = __webpack_require__(/*! ./Recognizer */ \"./antlr4/Recognizer.js\").Recognizer;\nvar CommonTokenFactory = __webpack_require__(/*! ./CommonTokenFactory */ \"./antlr4/CommonTokenFactory.js\").CommonTokenFactory;\nvar RecognitionException  = __webpack_require__(/*! ./error/Errors */ \"./antlr4/error/Errors.js\").RecognitionException;\nvar LexerNoViableAltException = __webpack_require__(/*! ./error/Errors */ \"./antlr4/error/Errors.js\").LexerNoViableAltException;\n\nfunction TokenSource() {\n\treturn this;\n}\n\nfunction Lexer(input) {\n\tRecognizer.call(this);\n\tthis._input = input;\n\tthis._factory = CommonTokenFactory.DEFAULT;\n\tthis._tokenFactorySourcePair = [ this, input ];\n\n\tthis._interp = null; // child classes must populate this\n\n\t// The goal of all lexer rules/methods is to create a token object.\n\t// this is an instance variable as multiple rules may collaborate to\n\t// create a single token. nextToken will return this object after\n\t// matching lexer rule(s). If you subclass to allow multiple token\n\t// emissions, then set this to the last token to be matched or\n\t// something nonnull so that the auto token emit mechanism will not\n\t// emit another token.\n\tthis._token = null;\n\n\t// What character index in the stream did the current token start at?\n\t// Needed, for example, to get the text for current token. Set at\n\t// the start of nextToken.\n\tthis._tokenStartCharIndex = -1;\n\n\t// The line on which the first character of the token resides///\n\tthis._tokenStartLine = -1;\n\n\t// The character position of first character within the line///\n\tthis._tokenStartColumn = -1;\n\n\t// Once we see EOF on char stream, next token will be EOF.\n\t// If you have DONE : EOF ; then you see DONE EOF.\n\tthis._hitEOF = false;\n\n\t// The channel number for the current token///\n\tthis._channel = Token.DEFAULT_CHANNEL;\n\n\t// The token type for the current token///\n\tthis._type = Token.INVALID_TYPE;\n\n\tthis._modeStack = [];\n\tthis._mode = Lexer.DEFAULT_MODE;\n\n\t// You can set the text for the current token to override what is in\n\t// the input char buffer. Use setText() or can set this instance var.\n\t// /\n\tthis._text = null;\n\n\treturn this;\n}\n\nLexer.prototype = Object.create(Recognizer.prototype);\nLexer.prototype.constructor = Lexer;\n\nLexer.DEFAULT_MODE = 0;\nLexer.MORE = -2;\nLexer.SKIP = -3;\n\nLexer.DEFAULT_TOKEN_CHANNEL = Token.DEFAULT_CHANNEL;\nLexer.HIDDEN = Token.HIDDEN_CHANNEL;\nLexer.MIN_CHAR_VALUE = 0x0000;\nLexer.MAX_CHAR_VALUE = 0x10FFFF;\n\nLexer.prototype.reset = function() {\n\t// wack Lexer state variables\n\tif (this._input !== null) {\n\t\tthis._input.seek(0); // rewind the input\n\t}\n\tthis._token = null;\n\tthis._type = Token.INVALID_TYPE;\n\tthis._channel = Token.DEFAULT_CHANNEL;\n\tthis._tokenStartCharIndex = -1;\n\tthis._tokenStartColumn = -1;\n\tthis._tokenStartLine = -1;\n\tthis._text = null;\n\n\tthis._hitEOF = false;\n\tthis._mode = Lexer.DEFAULT_MODE;\n\tthis._modeStack = [];\n\n\tthis._interp.reset();\n};\n\n// Return a token from this source; i.e., match a token on the char stream.\nLexer.prototype.nextToken = function() {\n\tif (this._input === null) {\n\t\tthrow \"nextToken requires a non-null input stream.\";\n\t}\n\n\t// Mark start location in char stream so unbuffered streams are\n\t// guaranteed at least have text of current token\n\tvar tokenStartMarker = this._input.mark();\n\ttry {\n\t\twhile (true) {\n\t\t\tif (this._hitEOF) {\n\t\t\t\tthis.emitEOF();\n\t\t\t\treturn this._token;\n\t\t\t}\n\t\t\tthis._token = null;\n\t\t\tthis._channel = Token.DEFAULT_CHANNEL;\n\t\t\tthis._tokenStartCharIndex = this._input.index;\n\t\t\tthis._tokenStartColumn = this._interp.column;\n\t\t\tthis._tokenStartLine = this._interp.line;\n\t\t\tthis._text = null;\n\t\t\tvar continueOuter = false;\n\t\t\twhile (true) {\n\t\t\t\tthis._type = Token.INVALID_TYPE;\n\t\t\t\tvar ttype = Lexer.SKIP;\n\t\t\t\ttry {\n\t\t\t\t\tttype = this._interp.match(this._input, this._mode);\n\t\t\t\t} catch (e) {\n\t\t\t\t    if(e instanceof RecognitionException) {\n                        this.notifyListeners(e); // report error\n                        this.recover(e);\n                    } else {\n                        console.log(e.stack);\n                        throw e;\n                    }\n\t\t\t\t}\n\t\t\t\tif (this._input.LA(1) === Token.EOF) {\n\t\t\t\t\tthis._hitEOF = true;\n\t\t\t\t}\n\t\t\t\tif (this._type === Token.INVALID_TYPE) {\n\t\t\t\t\tthis._type = ttype;\n\t\t\t\t}\n\t\t\t\tif (this._type === Lexer.SKIP) {\n\t\t\t\t\tcontinueOuter = true;\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t\tif (this._type !== Lexer.MORE) {\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\t\t\t}\n\t\t\tif (continueOuter) {\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\tif (this._token === null) {\n\t\t\t\tthis.emit();\n\t\t\t}\n\t\t\treturn this._token;\n\t\t}\n\t} finally {\n\t\t// make sure we release marker after match or\n\t\t// unbuffered char stream will keep buffering\n\t\tthis._input.release(tokenStartMarker);\n\t}\n};\n\n// Instruct the lexer to skip creating a token for current lexer rule\n// and look for another token. nextToken() knows to keep looking when\n// a lexer rule finishes with token set to SKIP_TOKEN. Recall that\n// if token==null at end of any token rule, it creates one for you\n// and emits it.\n// /\nLexer.prototype.skip = function() {\n\tthis._type = Lexer.SKIP;\n};\n\nLexer.prototype.more = function() {\n\tthis._type = Lexer.MORE;\n};\n\nLexer.prototype.mode = function(m) {\n\tthis._mode = m;\n};\n\nLexer.prototype.pushMode = function(m) {\n\tif (this._interp.debug) {\n\t\tconsole.log(\"pushMode \" + m);\n\t}\n\tthis._modeStack.push(this._mode);\n\tthis.mode(m);\n};\n\nLexer.prototype.popMode = function() {\n\tif (this._modeStack.length === 0) {\n\t\tthrow \"Empty Stack\";\n\t}\n\tif (this._interp.debug) {\n\t\tconsole.log(\"popMode back to \" + this._modeStack.slice(0, -1));\n\t}\n\tthis.mode(this._modeStack.pop());\n\treturn this._mode;\n};\n\n// Set the char stream and reset the lexer\nObject.defineProperty(Lexer.prototype, \"inputStream\", {\n\tget : function() {\n\t\treturn this._input;\n\t},\n\tset : function(input) {\n\t\tthis._input = null;\n\t\tthis._tokenFactorySourcePair = [ this, this._input ];\n\t\tthis.reset();\n\t\tthis._input = input;\n\t\tthis._tokenFactorySourcePair = [ this, this._input ];\n\t}\n});\n\nObject.defineProperty(Lexer.prototype, \"sourceName\", {\n\tget : function sourceName() {\n\t\treturn this._input.sourceName;\n\t}\n});\n\n// By default does not support multiple emits per nextToken invocation\n// for efficiency reasons. Subclass and override this method, nextToken,\n// and getToken (to push tokens into a list and pull from that list\n// rather than a single variable as this implementation does).\n// /\nLexer.prototype.emitToken = function(token) {\n\tthis._token = token;\n};\n\n// The standard method called to automatically emit a token at the\n// outermost lexical rule. The token object should point into the\n// char buffer start..stop. If there is a text override in 'text',\n// use that to set the token's text. Override this method to emit\n// custom Token objects or provide a new factory.\n// /\nLexer.prototype.emit = function() {\n\tvar t = this._factory.create(this._tokenFactorySourcePair, this._type,\n\t\t\tthis._text, this._channel, this._tokenStartCharIndex, this\n\t\t\t\t\t.getCharIndex() - 1, this._tokenStartLine,\n\t\t\tthis._tokenStartColumn);\n\tthis.emitToken(t);\n\treturn t;\n};\n\nLexer.prototype.emitEOF = function() {\n\tvar cpos = this.column;\n\tvar lpos = this.line;\n\tvar eof = this._factory.create(this._tokenFactorySourcePair, Token.EOF,\n\t\t\tnull, Token.DEFAULT_CHANNEL, this._input.index,\n\t\t\tthis._input.index - 1, lpos, cpos);\n\tthis.emitToken(eof);\n\treturn eof;\n};\n\nObject.defineProperty(Lexer.prototype, \"type\", {\n\tget : function() {\n\t\treturn this.type;\n\t},\n\tset : function(type) {\n\t\tthis._type = type;\n\t}\n});\n\nObject.defineProperty(Lexer.prototype, \"line\", {\n\tget : function() {\n\t\treturn this._interp.line;\n\t},\n\tset : function(line) {\n\t\tthis._interp.line = line;\n\t}\n});\n\nObject.defineProperty(Lexer.prototype, \"column\", {\n\tget : function() {\n\t\treturn this._interp.column;\n\t},\n\tset : function(column) {\n\t\tthis._interp.column = column;\n\t}\n});\n\n\n// What is the index of the current character of lookahead?///\nLexer.prototype.getCharIndex = function() {\n\treturn this._input.index;\n};\n\n// Return the text matched so far for the current token or any text override.\n//Set the complete text of this token; it wipes any previous changes to the text.\nObject.defineProperty(Lexer.prototype, \"text\", {\n\tget : function() {\n\t\tif (this._text !== null) {\n\t\t\treturn this._text;\n\t\t} else {\n\t\t\treturn this._interp.getText(this._input);\n\t\t}\n\t},\n\tset : function(text) {\n\t\tthis._text = text;\n\t}\n});\n// Return a list of all Token objects in input char stream.\n// Forces load of all tokens. Does not include EOF token.\n// /\nLexer.prototype.getAllTokens = function() {\n\tvar tokens = [];\n\tvar t = this.nextToken();\n\twhile (t.type !== Token.EOF) {\n\t\ttokens.push(t);\n\t\tt = this.nextToken();\n\t}\n\treturn tokens;\n};\n\nLexer.prototype.notifyListeners = function(e) {\n\tvar start = this._tokenStartCharIndex;\n\tvar stop = this._input.index;\n\tvar text = this._input.getText(start, stop);\n\tvar msg = \"token recognition error at: '\" + this.getErrorDisplay(text) + \"'\";\n\tvar listener = this.getErrorListenerDispatch();\n\tlistener.syntaxError(this, null, this._tokenStartLine,\n\t\t\tthis._tokenStartColumn, msg, e);\n};\n\nLexer.prototype.getErrorDisplay = function(s) {\n\tvar d = [];\n\tfor (var i = 0; i < s.length; i++) {\n\t\td.push(s[i]);\n\t}\n\treturn d.join('');\n};\n\nLexer.prototype.getErrorDisplayForChar = function(c) {\n\tif (c.charCodeAt(0) === Token.EOF) {\n\t\treturn \"<EOF>\";\n\t} else if (c === '\\n') {\n\t\treturn \"\\\\n\";\n\t} else if (c === '\\t') {\n\t\treturn \"\\\\t\";\n\t} else if (c === '\\r') {\n\t\treturn \"\\\\r\";\n\t} else {\n\t\treturn c;\n\t}\n};\n\nLexer.prototype.getCharErrorDisplay = function(c) {\n\treturn \"'\" + this.getErrorDisplayForChar(c) + \"'\";\n};\n\n// Lexers can normally match any char in it's vocabulary after matching\n// a token, so do the easy thing and just kill a character and hope\n// it all works out. You can instead use the rule invocation stack\n// to do sophisticated error recovery if you are in a fragment rule.\n// /\nLexer.prototype.recover = function(re) {\n\tif (this._input.LA(1) !== Token.EOF) {\n\t\tif (re instanceof LexerNoViableAltException) {\n\t\t\t// skip a char and try again\n\t\t\tthis._interp.consume(this._input);\n\t\t} else {\n\t\t\t// TODO: Do we lose character or line position information?\n\t\t\tthis._input.consume();\n\t\t}\n\t}\n};\n\nexports.Lexer = Lexer;\n\n\n//# sourceURL=webpack:///./antlr4/Lexer.js?");

/***/ }),

/***/ "./antlr4/Parser.js":
/*!**************************!*\
  !*** ./antlr4/Parser.js ***!
  \**************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nvar Token = __webpack_require__(/*! ./Token */ \"./antlr4/Token.js\").Token;\nvar ParseTreeListener = __webpack_require__(/*! ./tree/Tree */ \"./antlr4/tree/Tree.js\").ParseTreeListener;\nvar Recognizer = __webpack_require__(/*! ./Recognizer */ \"./antlr4/Recognizer.js\").Recognizer;\nvar DefaultErrorStrategy = __webpack_require__(/*! ./error/ErrorStrategy */ \"./antlr4/error/ErrorStrategy.js\").DefaultErrorStrategy;\nvar ATNDeserializer = __webpack_require__(/*! ./atn/ATNDeserializer */ \"./antlr4/atn/ATNDeserializer.js\").ATNDeserializer;\nvar ATNDeserializationOptions = __webpack_require__(/*! ./atn/ATNDeserializationOptions */ \"./antlr4/atn/ATNDeserializationOptions.js\").ATNDeserializationOptions;\nvar TerminalNode = __webpack_require__(/*! ./tree/Tree */ \"./antlr4/tree/Tree.js\").TerminalNode;\nvar ErrorNode = __webpack_require__(/*! ./tree/Tree */ \"./antlr4/tree/Tree.js\").ErrorNode;\n\nfunction TraceListener(parser) {\n\tParseTreeListener.call(this);\n    this.parser = parser;\n\treturn this;\n}\n\nTraceListener.prototype = Object.create(ParseTreeListener.prototype);\nTraceListener.prototype.constructor = TraceListener;\n\nTraceListener.prototype.enterEveryRule = function(ctx) {\n\tconsole.log(\"enter   \" + this.parser.ruleNames[ctx.ruleIndex] + \", LT(1)=\" + this.parser._input.LT(1).text);\n};\n\nTraceListener.prototype.visitTerminal = function( node) {\n\tconsole.log(\"consume \" + node.symbol + \" rule \" + this.parser.ruleNames[this.parser._ctx.ruleIndex]);\n};\n\nTraceListener.prototype.exitEveryRule = function(ctx) {\n\tconsole.log(\"exit    \" + this.parser.ruleNames[ctx.ruleIndex] + \", LT(1)=\" + this.parser._input.LT(1).text);\n};\n\n// this is all the parsing support code essentially; most of it is error\n// recovery stuff.//\nfunction Parser(input) {\n\tRecognizer.call(this);\n\t// The input stream.\n\tthis._input = null;\n\t// The error handling strategy for the parser. The default value is a new\n\t// instance of {@link DefaultErrorStrategy}.\n\tthis._errHandler = new DefaultErrorStrategy();\n\tthis._precedenceStack = [];\n\tthis._precedenceStack.push(0);\n\t// The {@link ParserRuleContext} object for the currently executing rule.\n\t// this is always non-null during the parsing process.\n\tthis._ctx = null;\n\t// Specifies whether or not the parser should construct a parse tree during\n\t// the parsing process. The default value is {@code true}.\n\tthis.buildParseTrees = true;\n\t// When {@link //setTrace}{@code (true)} is called, a reference to the\n\t// {@link TraceListener} is stored here so it can be easily removed in a\n\t// later call to {@link //setTrace}{@code (false)}. The listener itself is\n\t// implemented as a parser listener so this field is not directly used by\n\t// other parser methods.\n\tthis._tracer = null;\n\t// The list of {@link ParseTreeListener} listeners registered to receive\n\t// events during the parse.\n\tthis._parseListeners = null;\n\t// The number of syntax errors reported during parsing. this value is\n\t// incremented each time {@link //notifyErrorListeners} is called.\n\tthis._syntaxErrors = 0;\n\tthis.setInputStream(input);\n\treturn this;\n}\n\nParser.prototype = Object.create(Recognizer.prototype);\nParser.prototype.contructor = Parser;\n\n// this field maps from the serialized ATN string to the deserialized {@link\n// ATN} with\n// bypass alternatives.\n//\n// @see ATNDeserializationOptions//isGenerateRuleBypassTransitions()\n//\nParser.bypassAltsAtnCache = {};\n\n// reset the parser's state//\nParser.prototype.reset = function() {\n\tif (this._input !== null) {\n\t\tthis._input.seek(0);\n\t}\n\tthis._errHandler.reset(this);\n\tthis._ctx = null;\n\tthis._syntaxErrors = 0;\n\tthis.setTrace(false);\n\tthis._precedenceStack = [];\n\tthis._precedenceStack.push(0);\n\tif (this._interp !== null) {\n\t\tthis._interp.reset();\n\t}\n};\n\n// Match current input symbol against {@code ttype}. If the symbol type\n// matches, {@link ANTLRErrorStrategy//reportMatch} and {@link //consume} are\n// called to complete the match process.\n//\n// <p>If the symbol type does not match,\n// {@link ANTLRErrorStrategy//recoverInline} is called on the current error\n// strategy to attempt recovery. If {@link //getBuildParseTree} is\n// {@code true} and the token index of the symbol returned by\n// {@link ANTLRErrorStrategy//recoverInline} is -1, the symbol is added to\n// the parse tree by calling {@link ParserRuleContext//addErrorNode}.</p>\n//\n// @param ttype the token type to match\n// @return the matched symbol\n// @throws RecognitionException if the current input symbol did not match\n// {@code ttype} and the error strategy could not recover from the\n// mismatched symbol\n\nParser.prototype.match = function(ttype) {\n\tvar t = this.getCurrentToken();\n\tif (t.type === ttype) {\n\t\tthis._errHandler.reportMatch(this);\n\t\tthis.consume();\n\t} else {\n\t\tt = this._errHandler.recoverInline(this);\n\t\tif (this.buildParseTrees && t.tokenIndex === -1) {\n\t\t\t// we must have conjured up a new token during single token\n\t\t\t// insertion\n\t\t\t// if it's not the current symbol\n\t\t\tthis._ctx.addErrorNode(t);\n\t\t}\n\t}\n\treturn t;\n};\n// Match current input symbol as a wildcard. If the symbol type matches\n// (i.e. has a value greater than 0), {@link ANTLRErrorStrategy//reportMatch}\n// and {@link //consume} are called to complete the match process.\n//\n// <p>If the symbol type does not match,\n// {@link ANTLRErrorStrategy//recoverInline} is called on the current error\n// strategy to attempt recovery. If {@link //getBuildParseTree} is\n// {@code true} and the token index of the symbol returned by\n// {@link ANTLRErrorStrategy//recoverInline} is -1, the symbol is added to\n// the parse tree by calling {@link ParserRuleContext//addErrorNode}.</p>\n//\n// @return the matched symbol\n// @throws RecognitionException if the current input symbol did not match\n// a wildcard and the error strategy could not recover from the mismatched\n// symbol\n\nParser.prototype.matchWildcard = function() {\n\tvar t = this.getCurrentToken();\n\tif (t.type > 0) {\n\t\tthis._errHandler.reportMatch(this);\n\t\tthis.consume();\n\t} else {\n\t\tt = this._errHandler.recoverInline(this);\n\t\tif (this._buildParseTrees && t.tokenIndex === -1) {\n\t\t\t// we must have conjured up a new token during single token\n\t\t\t// insertion\n\t\t\t// if it's not the current symbol\n\t\t\tthis._ctx.addErrorNode(t);\n\t\t}\n\t}\n\treturn t;\n};\n\nParser.prototype.getParseListeners = function() {\n\treturn this._parseListeners || [];\n};\n\n// Registers {@code listener} to receive events during the parsing process.\n//\n// <p>To support output-preserving grammar transformations (including but not\n// limited to left-recursion removal, automated left-factoring, and\n// optimized code generation), calls to listener methods during the parse\n// may differ substantially from calls made by\n// {@link ParseTreeWalker//DEFAULT} used after the parse is complete. In\n// particular, rule entry and exit events may occur in a different order\n// during the parse than after the parser. In addition, calls to certain\n// rule entry methods may be omitted.</p>\n//\n// <p>With the following specific exceptions, calls to listener events are\n// <em>deterministic</em>, i.e. for identical input the calls to listener\n// methods will be the same.</p>\n//\n// <ul>\n// <li>Alterations to the grammar used to generate code may change the\n// behavior of the listener calls.</li>\n// <li>Alterations to the command line options passed to ANTLR 4 when\n// generating the parser may change the behavior of the listener calls.</li>\n// <li>Changing the version of the ANTLR Tool used to generate the parser\n// may change the behavior of the listener calls.</li>\n// </ul>\n//\n// @param listener the listener to add\n//\n// @throws NullPointerException if {@code} listener is {@code null}\n//\nParser.prototype.addParseListener = function(listener) {\n\tif (listener === null) {\n\t\tthrow \"listener\";\n\t}\n\tif (this._parseListeners === null) {\n\t\tthis._parseListeners = [];\n\t}\n\tthis._parseListeners.push(listener);\n};\n\n//\n// Remove {@code listener} from the list of parse listeners.\n//\n// <p>If {@code listener} is {@code null} or has not been added as a parse\n// listener, this method does nothing.</p>\n// @param listener the listener to remove\n//\nParser.prototype.removeParseListener = function(listener) {\n\tif (this._parseListeners !== null) {\n\t\tvar idx = this._parseListeners.indexOf(listener);\n\t\tif (idx >= 0) {\n\t\t\tthis._parseListeners.splice(idx, 1);\n\t\t}\n\t\tif (this._parseListeners.length === 0) {\n\t\t\tthis._parseListeners = null;\n\t\t}\n\t}\n};\n\n// Remove all parse listeners.\nParser.prototype.removeParseListeners = function() {\n\tthis._parseListeners = null;\n};\n\n// Notify any parse listeners of an enter rule event.\nParser.prototype.triggerEnterRuleEvent = function() {\n\tif (this._parseListeners !== null) {\n        var ctx = this._ctx;\n\t\tthis._parseListeners.map(function(listener) {\n\t\t\tlistener.enterEveryRule(ctx);\n\t\t\tctx.enterRule(listener);\n\t\t});\n\t}\n};\n\n//\n// Notify any parse listeners of an exit rule event.\n//\n// @see //addParseListener\n//\nParser.prototype.triggerExitRuleEvent = function() {\n\tif (this._parseListeners !== null) {\n\t\t// reverse order walk of listeners\n        var ctx = this._ctx;\n\t\tthis._parseListeners.slice(0).reverse().map(function(listener) {\n\t\t\tctx.exitRule(listener);\n\t\t\tlistener.exitEveryRule(ctx);\n\t\t});\n\t}\n};\n\nParser.prototype.getTokenFactory = function() {\n\treturn this._input.tokenSource._factory;\n};\n\n// Tell our token source and error strategy about a new way to create tokens.//\nParser.prototype.setTokenFactory = function(factory) {\n\tthis._input.tokenSource._factory = factory;\n};\n\n// The ATN with bypass alternatives is expensive to create so we create it\n// lazily.\n//\n// @throws UnsupportedOperationException if the current parser does not\n// implement the {@link //getSerializedATN()} method.\n//\nParser.prototype.getATNWithBypassAlts = function() {\n\tvar serializedAtn = this.getSerializedATN();\n\tif (serializedAtn === null) {\n\t\tthrow \"The current parser does not support an ATN with bypass alternatives.\";\n\t}\n\tvar result = this.bypassAltsAtnCache[serializedAtn];\n\tif (result === null) {\n\t\tvar deserializationOptions = new ATNDeserializationOptions();\n\t\tdeserializationOptions.generateRuleBypassTransitions = true;\n\t\tresult = new ATNDeserializer(deserializationOptions)\n\t\t\t\t.deserialize(serializedAtn);\n\t\tthis.bypassAltsAtnCache[serializedAtn] = result;\n\t}\n\treturn result;\n};\n\n// The preferred method of getting a tree pattern. For example, here's a\n// sample use:\n//\n// <pre>\n// ParseTree t = parser.expr();\n// ParseTreePattern p = parser.compileParseTreePattern(\"&lt;ID&gt;+0\",\n// MyParser.RULE_expr);\n// ParseTreeMatch m = p.match(t);\n// String id = m.get(\"ID\");\n// </pre>\n\nvar Lexer = __webpack_require__(/*! ./Lexer */ \"./antlr4/Lexer.js\").Lexer;\n\nParser.prototype.compileParseTreePattern = function(pattern, patternRuleIndex, lexer) {\n\tlexer = lexer || null;\n\tif (lexer === null) {\n\t\tif (this.getTokenStream() !== null) {\n\t\t\tvar tokenSource = this.getTokenStream().tokenSource;\n\t\t\tif (tokenSource instanceof Lexer) {\n\t\t\t\tlexer = tokenSource;\n\t\t\t}\n\t\t}\n\t}\n\tif (lexer === null) {\n\t\tthrow \"Parser can't discover a lexer to use\";\n\t}\n\tvar m = new ParseTreePatternMatcher(lexer, this);\n\treturn m.compile(pattern, patternRuleIndex);\n};\n\nParser.prototype.getInputStream = function() {\n\treturn this.getTokenStream();\n};\n\nParser.prototype.setInputStream = function(input) {\n\tthis.setTokenStream(input);\n};\n\nParser.prototype.getTokenStream = function() {\n\treturn this._input;\n};\n\n// Set the token stream and reset the parser.//\nParser.prototype.setTokenStream = function(input) {\n\tthis._input = null;\n\tthis.reset();\n\tthis._input = input;\n};\n\n// Match needs to return the current input symbol, which gets put\n// into the label for the associated token ref; e.g., x=ID.\n//\nParser.prototype.getCurrentToken = function() {\n\treturn this._input.LT(1);\n};\n\nParser.prototype.notifyErrorListeners = function(msg, offendingToken, err) {\n\toffendingToken = offendingToken || null;\n\terr = err || null;\n\tif (offendingToken === null) {\n\t\toffendingToken = this.getCurrentToken();\n\t}\n\tthis._syntaxErrors += 1;\n\tvar line = offendingToken.line;\n\tvar column = offendingToken.column;\n\tvar listener = this.getErrorListenerDispatch();\n\tlistener.syntaxError(this, offendingToken, line, column, msg, err);\n};\n\n//\n// Consume and return the {@linkplain //getCurrentToken current symbol}.\n//\n// <p>E.g., given the following input with {@code A} being the current\n// lookahead symbol, this function moves the cursor to {@code B} and returns\n// {@code A}.</p>\n//\n// <pre>\n// A B\n// ^\n// </pre>\n//\n// If the parser is not in error recovery mode, the consumed symbol is added\n// to the parse tree using {@link ParserRuleContext//addChild(Token)}, and\n// {@link ParseTreeListener//visitTerminal} is called on any parse listeners.\n// If the parser <em>is</em> in error recovery mode, the consumed symbol is\n// added to the parse tree using\n// {@link ParserRuleContext//addErrorNode(Token)}, and\n// {@link ParseTreeListener//visitErrorNode} is called on any parse\n// listeners.\n//\nParser.prototype.consume = function() {\n\tvar o = this.getCurrentToken();\n\tif (o.type !== Token.EOF) {\n\t\tthis.getInputStream().consume();\n\t}\n\tvar hasListener = this._parseListeners !== null && this._parseListeners.length > 0;\n\tif (this.buildParseTrees || hasListener) {\n\t\tvar node;\n\t\tif (this._errHandler.inErrorRecoveryMode(this)) {\n\t\t\tnode = this._ctx.addErrorNode(o);\n\t\t} else {\n\t\t\tnode = this._ctx.addTokenNode(o);\n\t\t}\n        node.invokingState = this.state;\n\t\tif (hasListener) {\n\t\t\tthis._parseListeners.map(function(listener) {\n\t\t\t\tif (node instanceof ErrorNode || (node.isErrorNode !== undefined && node.isErrorNode())) {\n\t\t\t\t\tlistener.visitErrorNode(node);\n\t\t\t\t} else if (node instanceof TerminalNode) {\n\t\t\t\t\tlistener.visitTerminal(node);\n\t\t\t\t}\n\t\t\t});\n\t\t}\n\t}\n\treturn o;\n};\n\nParser.prototype.addContextToParseTree = function() {\n\t// add current context to parent if we have a parent\n\tif (this._ctx.parentCtx !== null) {\n\t\tthis._ctx.parentCtx.addChild(this._ctx);\n\t}\n};\n\n// Always called by generated parsers upon entry to a rule. Access field\n// {@link //_ctx} get the current context.\n\nParser.prototype.enterRule = function(localctx, state, ruleIndex) {\n\tthis.state = state;\n\tthis._ctx = localctx;\n\tthis._ctx.start = this._input.LT(1);\n\tif (this.buildParseTrees) {\n\t\tthis.addContextToParseTree();\n\t}\n\tif (this._parseListeners !== null) {\n\t\tthis.triggerEnterRuleEvent();\n\t}\n};\n\nParser.prototype.exitRule = function() {\n\tthis._ctx.stop = this._input.LT(-1);\n\t// trigger event on _ctx, before it reverts to parent\n\tif (this._parseListeners !== null) {\n\t\tthis.triggerExitRuleEvent();\n\t}\n\tthis.state = this._ctx.invokingState;\n\tthis._ctx = this._ctx.parentCtx;\n};\n\nParser.prototype.enterOuterAlt = function(localctx, altNum) {\n   \tlocalctx.setAltNumber(altNum);\n\t// if we have new localctx, make sure we replace existing ctx\n\t// that is previous child of parse tree\n\tif (this.buildParseTrees && this._ctx !== localctx) {\n\t\tif (this._ctx.parentCtx !== null) {\n\t\t\tthis._ctx.parentCtx.removeLastChild();\n\t\t\tthis._ctx.parentCtx.addChild(localctx);\n\t\t}\n\t}\n\tthis._ctx = localctx;\n};\n\n// Get the precedence level for the top-most precedence rule.\n//\n// @return The precedence level for the top-most precedence rule, or -1 if\n// the parser context is not nested within a precedence rule.\n\nParser.prototype.getPrecedence = function() {\n\tif (this._precedenceStack.length === 0) {\n\t\treturn -1;\n\t} else {\n\t\treturn this._precedenceStack[this._precedenceStack.length-1];\n\t}\n};\n\nParser.prototype.enterRecursionRule = function(localctx, state, ruleIndex,\n\t\tprecedence) {\n\tthis.state = state;\n\tthis._precedenceStack.push(precedence);\n\tthis._ctx = localctx;\n\tthis._ctx.start = this._input.LT(1);\n\tif (this._parseListeners !== null) {\n\t\tthis.triggerEnterRuleEvent(); // simulates rule entry for\n\t\t\t\t\t\t\t\t\t\t// left-recursive rules\n\t}\n};\n\n//\n// Like {@link //enterRule} but for recursive rules.\n\nParser.prototype.pushNewRecursionContext = function(localctx, state, ruleIndex) {\n\tvar previous = this._ctx;\n\tprevious.parentCtx = localctx;\n\tprevious.invokingState = state;\n\tprevious.stop = this._input.LT(-1);\n\n\tthis._ctx = localctx;\n\tthis._ctx.start = previous.start;\n\tif (this.buildParseTrees) {\n\t\tthis._ctx.addChild(previous);\n\t}\n\tif (this._parseListeners !== null) {\n\t\tthis.triggerEnterRuleEvent(); // simulates rule entry for\n\t\t\t\t\t\t\t\t\t\t// left-recursive rules\n\t}\n};\n\nParser.prototype.unrollRecursionContexts = function(parentCtx) {\n\tthis._precedenceStack.pop();\n\tthis._ctx.stop = this._input.LT(-1);\n\tvar retCtx = this._ctx; // save current ctx (return value)\n\t// unroll so _ctx is as it was before call to recursive method\n\tif (this._parseListeners !== null) {\n\t\twhile (this._ctx !== parentCtx) {\n\t\t\tthis.triggerExitRuleEvent();\n\t\t\tthis._ctx = this._ctx.parentCtx;\n\t\t}\n\t} else {\n\t\tthis._ctx = parentCtx;\n\t}\n\t// hook into tree\n\tretCtx.parentCtx = parentCtx;\n\tif (this.buildParseTrees && parentCtx !== null) {\n\t\t// add return ctx into invoking rule's tree\n\t\tparentCtx.addChild(retCtx);\n\t}\n};\n\nParser.prototype.getInvokingContext = function(ruleIndex) {\n\tvar ctx = this._ctx;\n\twhile (ctx !== null) {\n\t\tif (ctx.ruleIndex === ruleIndex) {\n\t\t\treturn ctx;\n\t\t}\n\t\tctx = ctx.parentCtx;\n\t}\n\treturn null;\n};\n\nParser.prototype.precpred = function(localctx, precedence) {\n\treturn precedence >= this._precedenceStack[this._precedenceStack.length-1];\n};\n\nParser.prototype.inContext = function(context) {\n\t// TODO: useful in parser?\n\treturn false;\n};\n\n//\n// Checks whether or not {@code symbol} can follow the current state in the\n// ATN. The behavior of this method is equivalent to the following, but is\n// implemented such that the complete context-sensitive follow set does not\n// need to be explicitly constructed.\n//\n// <pre>\n// return getExpectedTokens().contains(symbol);\n// </pre>\n//\n// @param symbol the symbol type to check\n// @return {@code true} if {@code symbol} can follow the current state in\n// the ATN, otherwise {@code false}.\n\nParser.prototype.isExpectedToken = function(symbol) {\n\tvar atn = this._interp.atn;\n\tvar ctx = this._ctx;\n\tvar s = atn.states[this.state];\n\tvar following = atn.nextTokens(s);\n\tif (following.contains(symbol)) {\n\t\treturn true;\n\t}\n\tif (!following.contains(Token.EPSILON)) {\n\t\treturn false;\n\t}\n\twhile (ctx !== null && ctx.invokingState >= 0 && following.contains(Token.EPSILON)) {\n\t\tvar invokingState = atn.states[ctx.invokingState];\n\t\tvar rt = invokingState.transitions[0];\n\t\tfollowing = atn.nextTokens(rt.followState);\n\t\tif (following.contains(symbol)) {\n\t\t\treturn true;\n\t\t}\n\t\tctx = ctx.parentCtx;\n\t}\n\tif (following.contains(Token.EPSILON) && symbol === Token.EOF) {\n\t\treturn true;\n\t} else {\n\t\treturn false;\n\t}\n};\n\n// Computes the set of input symbols which could follow the current parser\n// state and context, as given by {@link //getState} and {@link //getContext},\n// respectively.\n//\n// @see ATN//getExpectedTokens(int, RuleContext)\n//\nParser.prototype.getExpectedTokens = function() {\n\treturn this._interp.atn.getExpectedTokens(this.state, this._ctx);\n};\n\nParser.prototype.getExpectedTokensWithinCurrentRule = function() {\n\tvar atn = this._interp.atn;\n\tvar s = atn.states[this.state];\n\treturn atn.nextTokens(s);\n};\n\n// Get a rule's index (i.e., {@code RULE_ruleName} field) or -1 if not found.//\nParser.prototype.getRuleIndex = function(ruleName) {\n\tvar ruleIndex = this.getRuleIndexMap()[ruleName];\n\tif (ruleIndex !== null) {\n\t\treturn ruleIndex;\n\t} else {\n\t\treturn -1;\n\t}\n};\n\n// Return List&lt;String&gt; of the rule names in your parser instance\n// leading up to a call to the current rule. You could override if\n// you want more details such as the file/line info of where\n// in the ATN a rule is invoked.\n//\n// this is very useful for error messages.\n//\nParser.prototype.getRuleInvocationStack = function(p) {\n\tp = p || null;\n\tif (p === null) {\n\t\tp = this._ctx;\n\t}\n\tvar stack = [];\n\twhile (p !== null) {\n\t\t// compute what follows who invoked us\n\t\tvar ruleIndex = p.ruleIndex;\n\t\tif (ruleIndex < 0) {\n\t\t\tstack.push(\"n/a\");\n\t\t} else {\n\t\t\tstack.push(this.ruleNames[ruleIndex]);\n\t\t}\n\t\tp = p.parentCtx;\n\t}\n\treturn stack;\n};\n\n// For debugging and other purposes.//\nParser.prototype.getDFAStrings = function() {\n\treturn this._interp.decisionToDFA.toString();\n};\n// For debugging and other purposes.//\nParser.prototype.dumpDFA = function() {\n\tvar seenOne = false;\n\tfor (var i = 0; i < this._interp.decisionToDFA.length; i++) {\n\t\tvar dfa = this._interp.decisionToDFA[i];\n\t\tif (dfa.states.length > 0) {\n\t\t\tif (seenOne) {\n\t\t\t\tconsole.log();\n\t\t\t}\n\t\t\tthis.printer.println(\"Decision \" + dfa.decision + \":\");\n\t\t\tthis.printer.print(dfa.toString(this.literalNames, this.symbolicNames));\n\t\t\tseenOne = true;\n\t\t}\n\t}\n};\n\n/*\n\"\t\t\tprinter = function() {\\r\\n\" +\n\"\t\t\t\tthis.println = function(s) { document.getElementById('output') += s + '\\\\n'; }\\r\\n\" +\n\"\t\t\t\tthis.print = function(s) { document.getElementById('output') += s; }\\r\\n\" +\n\"\t\t\t};\\r\\n\" +\n*/\n\nParser.prototype.getSourceName = function() {\n\treturn this._input.sourceName;\n};\n\n// During a parse is sometimes useful to listen in on the rule entry and exit\n// events as well as token matches. this is for quick and dirty debugging.\n//\nParser.prototype.setTrace = function(trace) {\n\tif (!trace) {\n\t\tthis.removeParseListener(this._tracer);\n\t\tthis._tracer = null;\n\t} else {\n\t\tif (this._tracer !== null) {\n\t\t\tthis.removeParseListener(this._tracer);\n\t\t}\n\t\tthis._tracer = new TraceListener(this);\n\t\tthis.addParseListener(this._tracer);\n\t}\n};\n\nexports.Parser = Parser;\n\n//# sourceURL=webpack:///./antlr4/Parser.js?");

/***/ }),

/***/ "./antlr4/ParserRuleContext.js":
/*!*************************************!*\
  !*** ./antlr4/ParserRuleContext.js ***!
  \*************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\n//* A rule invocation record for parsing.\n//\n//  Contains all of the information about the current rule not stored in the\n//  RuleContext. It handles parse tree children list, Any ATN state\n//  tracing, and the default values available for rule indications:\n//  start, stop, rule index, current alt number, current\n//  ATN state.\n//\n//  Subclasses made for each rule and grammar track the parameters,\n//  return values, locals, and labels specific to that rule. These\n//  are the objects that are returned from rules.\n//\n//  Note text is not an actual field of a rule return value; it is computed\n//  from start and stop using the input stream's toString() method.  I\n//  could add a ctor to this so that we can pass in and store the input\n//  stream, but I'm not sure we want to do that.  It would seem to be undefined\n//  to get the .text property anyway if the rule matches tokens from multiple\n//  input streams.\n//\n//  I do not use getters for fields of objects that are used simply to\n//  group values such as this aggregate.  The getters/setters are there to\n//  satisfy the superclass interface.\n\nvar RuleContext = __webpack_require__(/*! ./RuleContext */ \"./antlr4/RuleContext.js\").RuleContext;\nvar Tree = __webpack_require__(/*! ./tree/Tree */ \"./antlr4/tree/Tree.js\");\nvar INVALID_INTERVAL = Tree.INVALID_INTERVAL;\nvar TerminalNode = Tree.TerminalNode;\nvar TerminalNodeImpl = Tree.TerminalNodeImpl;\nvar ErrorNodeImpl = Tree.ErrorNodeImpl;\nvar Interval = __webpack_require__(/*! ./IntervalSet */ \"./antlr4/IntervalSet.js\").Interval;\n\nfunction ParserRuleContext(parent, invokingStateNumber) {\n\tparent = parent || null;\n\tinvokingStateNumber = invokingStateNumber || null;\n\tRuleContext.call(this, parent, invokingStateNumber);\n\tthis.ruleIndex = -1;\n    // * If we are debugging or building a parse tree for a visitor,\n    // we need to track all of the tokens and rule invocations associated\n    // with this rule's context. This is empty for parsing w/o tree constr.\n    // operation because we don't the need to track the details about\n    // how we parse this rule.\n    // /\n    this.children = null;\n    this.start = null;\n    this.stop = null;\n    // The exception that forced this rule to return. If the rule successfully\n    // completed, this is {@code null}.\n    this.exception = null;\n}\n\nParserRuleContext.prototype = Object.create(RuleContext.prototype);\nParserRuleContext.prototype.constructor = ParserRuleContext;\n\n// * COPY a ctx (I'm deliberately not using copy constructor)///\nParserRuleContext.prototype.copyFrom = function(ctx) {\n    // from RuleContext\n    this.parentCtx = ctx.parentCtx;\n    this.invokingState = ctx.invokingState;\n    this.children = null;\n    this.start = ctx.start;\n    this.stop = ctx.stop;\n    // copy any error nodes to alt label node\n    if(ctx.children) {\n        this.children = [];\n        // reset parent pointer for any error nodes\n    \tctx.children.map(function(child) {\n    \t\tif (child instanceof ErrorNodeImpl) {\n                this.children.push(child);\n                child.parentCtx = this;\n            }\n\t\t}, this);\n\t}\n};\n\n// Double dispatch methods for listeners\nParserRuleContext.prototype.enterRule = function(listener) {\n};\n\nParserRuleContext.prototype.exitRule = function(listener) {\n};\n\n// * Does not set parent link; other add methods do that///\nParserRuleContext.prototype.addChild = function(child) {\n    if (this.children === null) {\n        this.children = [];\n    }\n    this.children.push(child);\n    return child;\n};\n\n// * Used by enterOuterAlt to toss out a RuleContext previously added as\n// we entered a rule. If we have // label, we will need to remove\n// generic ruleContext object.\n// /\nParserRuleContext.prototype.removeLastChild = function() {\n    if (this.children !== null) {\n        this.children.pop();\n    }\n};\n\nParserRuleContext.prototype.addTokenNode = function(token) {\n    var node = new TerminalNodeImpl(token);\n    this.addChild(node);\n    node.parentCtx = this;\n    return node;\n};\n\nParserRuleContext.prototype.addErrorNode = function(badToken) {\n    var node = new ErrorNodeImpl(badToken);\n    this.addChild(node);\n    node.parentCtx = this;\n    return node;\n};\n\nParserRuleContext.prototype.getChild = function(i, type) {\n\ttype = type || null;\n\tif (this.children === null || i < 0 || i >= this.children.length) {\n\t\treturn null;\n\t}\n\tif (type === null) {\n\t\treturn this.children[i];\n\t} else {\n\t\tfor(var j=0; j<this.children.length; j++) {\n\t\t\tvar child = this.children[j];\n\t\t\tif(child instanceof type) {\n\t\t\t\tif(i===0) {\n\t\t\t\t\treturn child;\n\t\t\t\t} else {\n\t\t\t\t\ti -= 1;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn null;\n    }\n};\n\n\nParserRuleContext.prototype.getToken = function(ttype, i) {\n\tif (this.children === null || i < 0 || i >= this.children.length) {\n\t\treturn null;\n\t}\n\tfor(var j=0; j<this.children.length; j++) {\n\t\tvar child = this.children[j];\n\t\tif (child instanceof TerminalNode) {\n\t\t\tif (child.symbol.type === ttype) {\n\t\t\t\tif(i===0) {\n\t\t\t\t\treturn child;\n\t\t\t\t} else {\n\t\t\t\t\ti -= 1;\n\t\t\t\t}\n\t\t\t}\n        }\n\t}\n    return null;\n};\n\nParserRuleContext.prototype.getTokens = function(ttype ) {\n    if (this.children=== null) {\n        return [];\n    } else {\n\t\tvar tokens = [];\n\t\tfor(var j=0; j<this.children.length; j++) {\n\t\t\tvar child = this.children[j];\n\t\t\tif (child instanceof TerminalNode) {\n\t\t\t\tif (child.symbol.type === ttype) {\n\t\t\t\t\ttokens.push(child);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn tokens;\n    }\n};\n\nParserRuleContext.prototype.getTypedRuleContext = function(ctxType, i) {\n    return this.getChild(i, ctxType);\n};\n\nParserRuleContext.prototype.getTypedRuleContexts = function(ctxType) {\n    if (this.children=== null) {\n        return [];\n    } else {\n\t\tvar contexts = [];\n\t\tfor(var j=0; j<this.children.length; j++) {\n\t\t\tvar child = this.children[j];\n\t\t\tif (child instanceof ctxType) {\n\t\t\t\tcontexts.push(child);\n\t\t\t}\n\t\t}\n\t\treturn contexts;\n\t}\n};\n\nParserRuleContext.prototype.getChildCount = function() {\n\tif (this.children=== null) {\n\t\treturn 0;\n\t} else {\n\t\treturn this.children.length;\n\t}\n};\n\nParserRuleContext.prototype.getSourceInterval = function() {\n    if( this.start === null || this.stop === null) {\n        return INVALID_INTERVAL;\n    } else {\n        return new Interval(this.start.tokenIndex, this.stop.tokenIndex);\n    }\n};\n\nRuleContext.EMPTY = new ParserRuleContext();\n\nfunction InterpreterRuleContext(parent, invokingStateNumber, ruleIndex) {\n\tParserRuleContext.call(parent, invokingStateNumber);\n    this.ruleIndex = ruleIndex;\n    return this;\n}\n\nInterpreterRuleContext.prototype = Object.create(ParserRuleContext.prototype);\nInterpreterRuleContext.prototype.constructor = InterpreterRuleContext;\n\nexports.ParserRuleContext = ParserRuleContext;\n\n//# sourceURL=webpack:///./antlr4/ParserRuleContext.js?");

/***/ }),

/***/ "./antlr4/PredictionContext.js":
/*!*************************************!*\
  !*** ./antlr4/PredictionContext.js ***!
  \*************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("//\n/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n///\n\nvar RuleContext = __webpack_require__(/*! ./RuleContext */ \"./antlr4/RuleContext.js\").RuleContext;\nvar Hash = __webpack_require__(/*! ./Utils */ \"./antlr4/Utils.js\").Hash;\n\nfunction PredictionContext(cachedHashCode) {\n\tthis.cachedHashCode = cachedHashCode;\n}\n\n// Represents {@code $} in local context prediction, which means wildcard.\n// {@code//+x =//}.\n// /\nPredictionContext.EMPTY = null;\n\n// Represents {@code $} in an array in full context mode, when {@code $}\n// doesn't mean wildcard: {@code $ + x = [$,x]}. Here,\n// {@code $} = {@link //EMPTY_RETURN_STATE}.\n// /\nPredictionContext.EMPTY_RETURN_STATE = 0x7FFFFFFF;\n\nPredictionContext.globalNodeCount = 1;\nPredictionContext.id = PredictionContext.globalNodeCount;\n\n// Stores the computed hash code of this {@link PredictionContext}. The hash\n// code is computed in parts to match the following reference algorithm.\n//\n// <pre>\n// private int referenceHashCode() {\n// int hash = {@link MurmurHash//initialize MurmurHash.initialize}({@link\n// //INITIAL_HASH});\n//\n// for (int i = 0; i &lt; {@link //size()}; i++) {\n// hash = {@link MurmurHash//update MurmurHash.update}(hash, {@link //getParent\n// getParent}(i));\n// }\n//\n// for (int i = 0; i &lt; {@link //size()}; i++) {\n// hash = {@link MurmurHash//update MurmurHash.update}(hash, {@link\n// //getReturnState getReturnState}(i));\n// }\n//\n// hash = {@link MurmurHash//finish MurmurHash.finish}(hash, 2// {@link\n// //size()});\n// return hash;\n// }\n// </pre>\n// /\n\n// This means only the {@link //EMPTY} context is in set.\nPredictionContext.prototype.isEmpty = function() {\n\treturn this === PredictionContext.EMPTY;\n};\n\nPredictionContext.prototype.hasEmptyPath = function() {\n\treturn this.getReturnState(this.length - 1) === PredictionContext.EMPTY_RETURN_STATE;\n};\n\nPredictionContext.prototype.hashCode = function() {\n\treturn this.cachedHashCode;\n};\n\n\nPredictionContext.prototype.updateHashCode = function(hash) {\n    hash.update(this.cachedHashCode);\n};\n/*\nfunction calculateHashString(parent, returnState) {\n\treturn \"\" + parent + returnState;\n}\n*/\n\n// Used to cache {@link PredictionContext} objects. Its used for the shared\n// context cash associated with contexts in DFA states. This cache\n// can be used for both lexers and parsers.\n\nfunction PredictionContextCache() {\n\tthis.cache = {};\n\treturn this;\n}\n\n// Add a context to the cache and return it. If the context already exists,\n// return that one instead and do not add a new context to the cache.\n// Protect shared cache from unsafe thread access.\n//\nPredictionContextCache.prototype.add = function(ctx) {\n\tif (ctx === PredictionContext.EMPTY) {\n\t\treturn PredictionContext.EMPTY;\n\t}\n\tvar existing = this.cache[ctx] || null;\n\tif (existing !== null) {\n\t\treturn existing;\n\t}\n\tthis.cache[ctx] = ctx;\n\treturn ctx;\n};\n\nPredictionContextCache.prototype.get = function(ctx) {\n\treturn this.cache[ctx] || null;\n};\n\nObject.defineProperty(PredictionContextCache.prototype, \"length\", {\n\tget : function() {\n\t\treturn this.cache.length;\n\t}\n});\n\nfunction SingletonPredictionContext(parent, returnState) {\n\tvar hashCode = 0;\n\tif(parent !== null) {\n\t\tvar hash = new Hash();\n\t\thash.update(parent, returnState);\n        hashCode = hash.finish();\n\t}\n\tPredictionContext.call(this, hashCode);\n\tthis.parentCtx = parent;\n\tthis.returnState = returnState;\n}\n\nSingletonPredictionContext.prototype = Object.create(PredictionContext.prototype);\nSingletonPredictionContext.prototype.contructor = SingletonPredictionContext;\n\nSingletonPredictionContext.create = function(parent, returnState) {\n\tif (returnState === PredictionContext.EMPTY_RETURN_STATE && parent === null) {\n\t\t// someone can pass in the bits of an array ctx that mean $\n\t\treturn PredictionContext.EMPTY;\n\t} else {\n\t\treturn new SingletonPredictionContext(parent, returnState);\n\t}\n};\n\nObject.defineProperty(SingletonPredictionContext.prototype, \"length\", {\n\tget : function() {\n\t\treturn 1;\n\t}\n});\n\nSingletonPredictionContext.prototype.getParent = function(index) {\n\treturn this.parentCtx;\n};\n\nSingletonPredictionContext.prototype.getReturnState = function(index) {\n\treturn this.returnState;\n};\n\nSingletonPredictionContext.prototype.equals = function(other) {\n\tif (this === other) {\n\t\treturn true;\n\t} else if (!(other instanceof SingletonPredictionContext)) {\n\t\treturn false;\n\t} else if (this.hashCode() !== other.hashCode()) {\n\t\treturn false; // can't be same if hash is different\n\t} else {\n\t\tif(this.returnState !== other.returnState)\n            return false;\n        else if(this.parentCtx==null)\n            return other.parentCtx==null\n\t\telse\n            return this.parentCtx.equals(other.parentCtx);\n\t}\n};\n\nSingletonPredictionContext.prototype.toString = function() {\n\tvar up = this.parentCtx === null ? \"\" : this.parentCtx.toString();\n\tif (up.length === 0) {\n\t\tif (this.returnState === PredictionContext.EMPTY_RETURN_STATE) {\n\t\t\treturn \"$\";\n\t\t} else {\n\t\t\treturn \"\" + this.returnState;\n\t\t}\n\t} else {\n\t\treturn \"\" + this.returnState + \" \" + up;\n\t}\n};\n\nfunction EmptyPredictionContext() {\n\tSingletonPredictionContext.call(this, null, PredictionContext.EMPTY_RETURN_STATE);\n\treturn this;\n}\n\nEmptyPredictionContext.prototype = Object.create(SingletonPredictionContext.prototype);\nEmptyPredictionContext.prototype.constructor = EmptyPredictionContext;\n\nEmptyPredictionContext.prototype.isEmpty = function() {\n\treturn true;\n};\n\nEmptyPredictionContext.prototype.getParent = function(index) {\n\treturn null;\n};\n\nEmptyPredictionContext.prototype.getReturnState = function(index) {\n\treturn this.returnState;\n};\n\nEmptyPredictionContext.prototype.equals = function(other) {\n\treturn this === other;\n};\n\nEmptyPredictionContext.prototype.toString = function() {\n\treturn \"$\";\n};\n\nPredictionContext.EMPTY = new EmptyPredictionContext();\n\nfunction ArrayPredictionContext(parents, returnStates) {\n\t// Parent can be null only if full ctx mode and we make an array\n\t// from {@link //EMPTY} and non-empty. We merge {@link //EMPTY} by using\n\t// null parent and\n\t// returnState == {@link //EMPTY_RETURN_STATE}.\n\tvar h = new Hash();\n\th.update(parents, returnStates);\n\tvar hashCode = h.finish();\n\tPredictionContext.call(this, hashCode);\n\tthis.parents = parents;\n\tthis.returnStates = returnStates;\n\treturn this;\n}\n\nArrayPredictionContext.prototype = Object.create(PredictionContext.prototype);\nArrayPredictionContext.prototype.constructor = ArrayPredictionContext;\n\nArrayPredictionContext.prototype.isEmpty = function() {\n\t// since EMPTY_RETURN_STATE can only appear in the last position, we\n\t// don't need to verify that size==1\n\treturn this.returnStates[0] === PredictionContext.EMPTY_RETURN_STATE;\n};\n\nObject.defineProperty(ArrayPredictionContext.prototype, \"length\", {\n\tget : function() {\n\t\treturn this.returnStates.length;\n\t}\n});\n\nArrayPredictionContext.prototype.getParent = function(index) {\n\treturn this.parents[index];\n};\n\nArrayPredictionContext.prototype.getReturnState = function(index) {\n\treturn this.returnStates[index];\n};\n\nArrayPredictionContext.prototype.equals = function(other) {\n\tif (this === other) {\n\t\treturn true;\n\t} else if (!(other instanceof ArrayPredictionContext)) {\n\t\treturn false;\n\t} else if (this.hashCode() !== other.hashCode()) {\n\t\treturn false; // can't be same if hash is different\n\t} else {\n\t\treturn this.returnStates === other.returnStates &&\n\t\t\t\tthis.parents === other.parents;\n\t}\n};\n\nArrayPredictionContext.prototype.toString = function() {\n\tif (this.isEmpty()) {\n\t\treturn \"[]\";\n\t} else {\n\t\tvar s = \"[\";\n\t\tfor (var i = 0; i < this.returnStates.length; i++) {\n\t\t\tif (i > 0) {\n\t\t\t\ts = s + \", \";\n\t\t\t}\n\t\t\tif (this.returnStates[i] === PredictionContext.EMPTY_RETURN_STATE) {\n\t\t\t\ts = s + \"$\";\n\t\t\t\tcontinue;\n\t\t\t}\n\t\t\ts = s + this.returnStates[i];\n\t\t\tif (this.parents[i] !== null) {\n\t\t\t\ts = s + \" \" + this.parents[i];\n\t\t\t} else {\n\t\t\t\ts = s + \"null\";\n\t\t\t}\n\t\t}\n\t\treturn s + \"]\";\n\t}\n};\n\n// Convert a {@link RuleContext} tree to a {@link PredictionContext} graph.\n// Return {@link //EMPTY} if {@code outerContext} is empty or null.\n// /\nfunction predictionContextFromRuleContext(atn, outerContext) {\n\tif (outerContext === undefined || outerContext === null) {\n\t\touterContext = RuleContext.EMPTY;\n\t}\n\t// if we are in RuleContext of start rule, s, then PredictionContext\n\t// is EMPTY. Nobody called us. (if we are empty, return empty)\n\tif (outerContext.parentCtx === null || outerContext === RuleContext.EMPTY) {\n\t\treturn PredictionContext.EMPTY;\n\t}\n\t// If we have a parent, convert it to a PredictionContext graph\n\tvar parent = predictionContextFromRuleContext(atn, outerContext.parentCtx);\n\tvar state = atn.states[outerContext.invokingState];\n\tvar transition = state.transitions[0];\n\treturn SingletonPredictionContext.create(parent, transition.followState.stateNumber);\n}\n/*\nfunction calculateListsHashString(parents, returnStates) {\n\tvar s = \"\";\n\tparents.map(function(p) {\n\t\ts = s + p;\n\t});\n\treturnStates.map(function(r) {\n\t\ts = s + r;\n\t});\n\treturn s;\n}\n*/\nfunction merge(a, b, rootIsWildcard, mergeCache) {\n\t// share same graph if both same\n\tif (a === b) {\n\t\treturn a;\n\t}\n\tif (a instanceof SingletonPredictionContext && b instanceof SingletonPredictionContext) {\n\t\treturn mergeSingletons(a, b, rootIsWildcard, mergeCache);\n\t}\n\t// At least one of a or b is array\n\t// If one is $ and rootIsWildcard, return $ as// wildcard\n\tif (rootIsWildcard) {\n\t\tif (a instanceof EmptyPredictionContext) {\n\t\t\treturn a;\n\t\t}\n\t\tif (b instanceof EmptyPredictionContext) {\n\t\t\treturn b;\n\t\t}\n\t}\n\t// convert singleton so both are arrays to normalize\n\tif (a instanceof SingletonPredictionContext) {\n\t\ta = new ArrayPredictionContext([a.getParent()], [a.returnState]);\n\t}\n\tif (b instanceof SingletonPredictionContext) {\n\t\tb = new ArrayPredictionContext([b.getParent()], [b.returnState]);\n\t}\n\treturn mergeArrays(a, b, rootIsWildcard, mergeCache);\n}\n\n//\n// Merge two {@link SingletonPredictionContext} instances.\n//\n// <p>Stack tops equal, parents merge is same; return left graph.<br>\n// <embed src=\"images/SingletonMerge_SameRootSamePar.svg\"\n// type=\"image/svg+xml\"/></p>\n//\n// <p>Same stack top, parents differ; merge parents giving array node, then\n// remainders of those graphs. A new root node is created to point to the\n// merged parents.<br>\n// <embed src=\"images/SingletonMerge_SameRootDiffPar.svg\"\n// type=\"image/svg+xml\"/></p>\n//\n// <p>Different stack tops pointing to same parent. Make array node for the\n// root where both element in the root point to the same (original)\n// parent.<br>\n// <embed src=\"images/SingletonMerge_DiffRootSamePar.svg\"\n// type=\"image/svg+xml\"/></p>\n//\n// <p>Different stack tops pointing to different parents. Make array node for\n// the root where each element points to the corresponding original\n// parent.<br>\n// <embed src=\"images/SingletonMerge_DiffRootDiffPar.svg\"\n// type=\"image/svg+xml\"/></p>\n//\n// @param a the first {@link SingletonPredictionContext}\n// @param b the second {@link SingletonPredictionContext}\n// @param rootIsWildcard {@code true} if this is a local-context merge,\n// otherwise false to indicate a full-context merge\n// @param mergeCache\n// /\nfunction mergeSingletons(a, b, rootIsWildcard, mergeCache) {\n\tif (mergeCache !== null) {\n\t\tvar previous = mergeCache.get(a, b);\n\t\tif (previous !== null) {\n\t\t\treturn previous;\n\t\t}\n\t\tprevious = mergeCache.get(b, a);\n\t\tif (previous !== null) {\n\t\t\treturn previous;\n\t\t}\n\t}\n\n\tvar rootMerge = mergeRoot(a, b, rootIsWildcard);\n\tif (rootMerge !== null) {\n\t\tif (mergeCache !== null) {\n\t\t\tmergeCache.set(a, b, rootMerge);\n\t\t}\n\t\treturn rootMerge;\n\t}\n\tif (a.returnState === b.returnState) {\n\t\tvar parent = merge(a.parentCtx, b.parentCtx, rootIsWildcard, mergeCache);\n\t\t// if parent is same as existing a or b parent or reduced to a parent,\n\t\t// return it\n\t\tif (parent === a.parentCtx) {\n\t\t\treturn a; // ax + bx = ax, if a=b\n\t\t}\n\t\tif (parent === b.parentCtx) {\n\t\t\treturn b; // ax + bx = bx, if a=b\n\t\t}\n\t\t// else: ax + ay = a'[x,y]\n\t\t// merge parents x and y, giving array node with x,y then remainders\n\t\t// of those graphs. dup a, a' points at merged array\n\t\t// new joined parent so create new singleton pointing to it, a'\n\t\tvar spc = SingletonPredictionContext.create(parent, a.returnState);\n\t\tif (mergeCache !== null) {\n\t\t\tmergeCache.set(a, b, spc);\n\t\t}\n\t\treturn spc;\n\t} else { // a != b payloads differ\n\t\t// see if we can collapse parents due to $+x parents if local ctx\n\t\tvar singleParent = null;\n\t\tif (a === b || (a.parentCtx !== null && a.parentCtx === b.parentCtx)) { // ax +\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t// bx =\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t// [a,b]x\n\t\t\tsingleParent = a.parentCtx;\n\t\t}\n\t\tif (singleParent !== null) { // parents are same\n\t\t\t// sort payloads and use same parent\n\t\t\tvar payloads = [ a.returnState, b.returnState ];\n\t\t\tif (a.returnState > b.returnState) {\n\t\t\t\tpayloads[0] = b.returnState;\n\t\t\t\tpayloads[1] = a.returnState;\n\t\t\t}\n\t\t\tvar parents = [ singleParent, singleParent ];\n\t\t\tvar apc = new ArrayPredictionContext(parents, payloads);\n\t\t\tif (mergeCache !== null) {\n\t\t\t\tmergeCache.set(a, b, apc);\n\t\t\t}\n\t\t\treturn apc;\n\t\t}\n\t\t// parents differ and can't merge them. Just pack together\n\t\t// into array; can't merge.\n\t\t// ax + by = [ax,by]\n\t\tvar payloads = [ a.returnState, b.returnState ];\n\t\tvar parents = [ a.parentCtx, b.parentCtx ];\n\t\tif (a.returnState > b.returnState) { // sort by payload\n\t\t\tpayloads[0] = b.returnState;\n\t\t\tpayloads[1] = a.returnState;\n\t\t\tparents = [ b.parentCtx, a.parentCtx ];\n\t\t}\n\t\tvar a_ = new ArrayPredictionContext(parents, payloads);\n\t\tif (mergeCache !== null) {\n\t\t\tmergeCache.set(a, b, a_);\n\t\t}\n\t\treturn a_;\n\t}\n}\n\n//\n// Handle case where at least one of {@code a} or {@code b} is\n// {@link //EMPTY}. In the following diagrams, the symbol {@code $} is used\n// to represent {@link //EMPTY}.\n//\n// <h2>Local-Context Merges</h2>\n//\n// <p>These local-context merge operations are used when {@code rootIsWildcard}\n// is true.</p>\n//\n// <p>{@link //EMPTY} is superset of any graph; return {@link //EMPTY}.<br>\n// <embed src=\"images/LocalMerge_EmptyRoot.svg\" type=\"image/svg+xml\"/></p>\n//\n// <p>{@link //EMPTY} and anything is {@code //EMPTY}, so merged parent is\n// {@code //EMPTY}; return left graph.<br>\n// <embed src=\"images/LocalMerge_EmptyParent.svg\" type=\"image/svg+xml\"/></p>\n//\n// <p>Special case of last merge if local context.<br>\n// <embed src=\"images/LocalMerge_DiffRoots.svg\" type=\"image/svg+xml\"/></p>\n//\n// <h2>Full-Context Merges</h2>\n//\n// <p>These full-context merge operations are used when {@code rootIsWildcard}\n// is false.</p>\n//\n// <p><embed src=\"images/FullMerge_EmptyRoots.svg\" type=\"image/svg+xml\"/></p>\n//\n// <p>Must keep all contexts; {@link //EMPTY} in array is a special value (and\n// null parent).<br>\n// <embed src=\"images/FullMerge_EmptyRoot.svg\" type=\"image/svg+xml\"/></p>\n//\n// <p><embed src=\"images/FullMerge_SameRoot.svg\" type=\"image/svg+xml\"/></p>\n//\n// @param a the first {@link SingletonPredictionContext}\n// @param b the second {@link SingletonPredictionContext}\n// @param rootIsWildcard {@code true} if this is a local-context merge,\n// otherwise false to indicate a full-context merge\n// /\nfunction mergeRoot(a, b, rootIsWildcard) {\n\tif (rootIsWildcard) {\n\t\tif (a === PredictionContext.EMPTY) {\n\t\t\treturn PredictionContext.EMPTY; // // + b =//\n\t\t}\n\t\tif (b === PredictionContext.EMPTY) {\n\t\t\treturn PredictionContext.EMPTY; // a +// =//\n\t\t}\n\t} else {\n\t\tif (a === PredictionContext.EMPTY && b === PredictionContext.EMPTY) {\n\t\t\treturn PredictionContext.EMPTY; // $ + $ = $\n\t\t} else if (a === PredictionContext.EMPTY) { // $ + x = [$,x]\n\t\t\tvar payloads = [ b.returnState,\n\t\t\t\t\tPredictionContext.EMPTY_RETURN_STATE ];\n\t\t\tvar parents = [ b.parentCtx, null ];\n\t\t\treturn new ArrayPredictionContext(parents, payloads);\n\t\t} else if (b === PredictionContext.EMPTY) { // x + $ = [$,x] ($ is always first if present)\n\t\t\tvar payloads = [ a.returnState, PredictionContext.EMPTY_RETURN_STATE ];\n\t\t\tvar parents = [ a.parentCtx, null ];\n\t\t\treturn new ArrayPredictionContext(parents, payloads);\n\t\t}\n\t}\n\treturn null;\n}\n\n//\n// Merge two {@link ArrayPredictionContext} instances.\n//\n// <p>Different tops, different parents.<br>\n// <embed src=\"images/ArrayMerge_DiffTopDiffPar.svg\" type=\"image/svg+xml\"/></p>\n//\n// <p>Shared top, same parents.<br>\n// <embed src=\"images/ArrayMerge_ShareTopSamePar.svg\" type=\"image/svg+xml\"/></p>\n//\n// <p>Shared top, different parents.<br>\n// <embed src=\"images/ArrayMerge_ShareTopDiffPar.svg\" type=\"image/svg+xml\"/></p>\n//\n// <p>Shared top, all shared parents.<br>\n// <embed src=\"images/ArrayMerge_ShareTopSharePar.svg\"\n// type=\"image/svg+xml\"/></p>\n//\n// <p>Equal tops, merge parents and reduce top to\n// {@link SingletonPredictionContext}.<br>\n// <embed src=\"images/ArrayMerge_EqualTop.svg\" type=\"image/svg+xml\"/></p>\n// /\nfunction mergeArrays(a, b, rootIsWildcard, mergeCache) {\n\tif (mergeCache !== null) {\n\t\tvar previous = mergeCache.get(a, b);\n\t\tif (previous !== null) {\n\t\t\treturn previous;\n\t\t}\n\t\tprevious = mergeCache.get(b, a);\n\t\tif (previous !== null) {\n\t\t\treturn previous;\n\t\t}\n\t}\n\t// merge sorted payloads a + b => M\n\tvar i = 0; // walks a\n\tvar j = 0; // walks b\n\tvar k = 0; // walks target M array\n\n\tvar mergedReturnStates = [];\n\tvar mergedParents = [];\n\t// walk and merge to yield mergedParents, mergedReturnStates\n\twhile (i < a.returnStates.length && j < b.returnStates.length) {\n\t\tvar a_parent = a.parents[i];\n\t\tvar b_parent = b.parents[j];\n\t\tif (a.returnStates[i] === b.returnStates[j]) {\n\t\t\t// same payload (stack tops are equal), must yield merged singleton\n\t\t\tvar payload = a.returnStates[i];\n\t\t\t// $+$ = $\n\t\t\tvar bothDollars = payload === PredictionContext.EMPTY_RETURN_STATE &&\n\t\t\t\t\ta_parent === null && b_parent === null;\n\t\t\tvar ax_ax = (a_parent !== null && b_parent !== null && a_parent === b_parent); // ax+ax\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t// ->\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t// ax\n\t\t\tif (bothDollars || ax_ax) {\n\t\t\t\tmergedParents[k] = a_parent; // choose left\n\t\t\t\tmergedReturnStates[k] = payload;\n\t\t\t} else { // ax+ay -> a'[x,y]\n\t\t\t\tvar mergedParent = merge(a_parent, b_parent, rootIsWildcard, mergeCache);\n\t\t\t\tmergedParents[k] = mergedParent;\n\t\t\t\tmergedReturnStates[k] = payload;\n\t\t\t}\n\t\t\ti += 1; // hop over left one as usual\n\t\t\tj += 1; // but also skip one in right side since we merge\n\t\t} else if (a.returnStates[i] < b.returnStates[j]) { // copy a[i] to M\n\t\t\tmergedParents[k] = a_parent;\n\t\t\tmergedReturnStates[k] = a.returnStates[i];\n\t\t\ti += 1;\n\t\t} else { // b > a, copy b[j] to M\n\t\t\tmergedParents[k] = b_parent;\n\t\t\tmergedReturnStates[k] = b.returnStates[j];\n\t\t\tj += 1;\n\t\t}\n\t\tk += 1;\n\t}\n\t// copy over any payloads remaining in either array\n\tif (i < a.returnStates.length) {\n\t\tfor (var p = i; p < a.returnStates.length; p++) {\n\t\t\tmergedParents[k] = a.parents[p];\n\t\t\tmergedReturnStates[k] = a.returnStates[p];\n\t\t\tk += 1;\n\t\t}\n\t} else {\n\t\tfor (var p = j; p < b.returnStates.length; p++) {\n\t\t\tmergedParents[k] = b.parents[p];\n\t\t\tmergedReturnStates[k] = b.returnStates[p];\n\t\t\tk += 1;\n\t\t}\n\t}\n\t// trim merged if we combined a few that had same stack tops\n\tif (k < mergedParents.length) { // write index < last position; trim\n\t\tif (k === 1) { // for just one merged element, return singleton top\n\t\t\tvar a_ = SingletonPredictionContext.create(mergedParents[0],\n\t\t\t\t\tmergedReturnStates[0]);\n\t\t\tif (mergeCache !== null) {\n\t\t\t\tmergeCache.set(a, b, a_);\n\t\t\t}\n\t\t\treturn a_;\n\t\t}\n\t\tmergedParents = mergedParents.slice(0, k);\n\t\tmergedReturnStates = mergedReturnStates.slice(0, k);\n\t}\n\n\tvar M = new ArrayPredictionContext(mergedParents, mergedReturnStates);\n\n\t// if we created same array as a or b, return that instead\n\t// TODO: track whether this is possible above during merge sort for speed\n\tif (M === a) {\n\t\tif (mergeCache !== null) {\n\t\t\tmergeCache.set(a, b, a);\n\t\t}\n\t\treturn a;\n\t}\n\tif (M === b) {\n\t\tif (mergeCache !== null) {\n\t\t\tmergeCache.set(a, b, b);\n\t\t}\n\t\treturn b;\n\t}\n\tcombineCommonParents(mergedParents);\n\n\tif (mergeCache !== null) {\n\t\tmergeCache.set(a, b, M);\n\t}\n\treturn M;\n}\n\n//\n// Make pass over all <em>M</em> {@code parents}; merge any {@code equals()}\n// ones.\n// /\nfunction combineCommonParents(parents) {\n\tvar uniqueParents = {};\n\n\tfor (var p = 0; p < parents.length; p++) {\n\t\tvar parent = parents[p];\n\t\tif (!(parent in uniqueParents)) {\n\t\t\tuniqueParents[parent] = parent;\n\t\t}\n\t}\n\tfor (var q = 0; q < parents.length; q++) {\n\t\tparents[q] = uniqueParents[parents[q]];\n\t}\n}\n\nfunction getCachedPredictionContext(context, contextCache, visited) {\n\tif (context.isEmpty()) {\n\t\treturn context;\n\t}\n\tvar existing = visited[context] || null;\n\tif (existing !== null) {\n\t\treturn existing;\n\t}\n\texisting = contextCache.get(context);\n\tif (existing !== null) {\n\t\tvisited[context] = existing;\n\t\treturn existing;\n\t}\n\tvar changed = false;\n\tvar parents = [];\n\tfor (var i = 0; i < parents.length; i++) {\n\t\tvar parent = getCachedPredictionContext(context.getParent(i), contextCache, visited);\n\t\tif (changed || parent !== context.getParent(i)) {\n\t\t\tif (!changed) {\n\t\t\t\tparents = [];\n\t\t\t\tfor (var j = 0; j < context.length; j++) {\n\t\t\t\t\tparents[j] = context.getParent(j);\n\t\t\t\t}\n\t\t\t\tchanged = true;\n\t\t\t}\n\t\t\tparents[i] = parent;\n\t\t}\n\t}\n\tif (!changed) {\n\t\tcontextCache.add(context);\n\t\tvisited[context] = context;\n\t\treturn context;\n\t}\n\tvar updated = null;\n\tif (parents.length === 0) {\n\t\tupdated = PredictionContext.EMPTY;\n\t} else if (parents.length === 1) {\n\t\tupdated = SingletonPredictionContext.create(parents[0], context\n\t\t\t\t.getReturnState(0));\n\t} else {\n\t\tupdated = new ArrayPredictionContext(parents, context.returnStates);\n\t}\n\tcontextCache.add(updated);\n\tvisited[updated] = updated;\n\tvisited[context] = updated;\n\n\treturn updated;\n}\n\n// ter's recursive version of Sam's getAllNodes()\nfunction getAllContextNodes(context, nodes, visited) {\n\tif (nodes === null) {\n\t\tnodes = [];\n\t\treturn getAllContextNodes(context, nodes, visited);\n\t} else if (visited === null) {\n\t\tvisited = {};\n\t\treturn getAllContextNodes(context, nodes, visited);\n\t} else {\n\t\tif (context === null || visited[context] !== null) {\n\t\t\treturn nodes;\n\t\t}\n\t\tvisited[context] = context;\n\t\tnodes.push(context);\n\t\tfor (var i = 0; i < context.length; i++) {\n\t\t\tgetAllContextNodes(context.getParent(i), nodes, visited);\n\t\t}\n\t\treturn nodes;\n\t}\n}\n\nexports.merge = merge;\nexports.PredictionContext = PredictionContext;\nexports.PredictionContextCache = PredictionContextCache;\nexports.SingletonPredictionContext = SingletonPredictionContext;\nexports.predictionContextFromRuleContext = predictionContextFromRuleContext;\nexports.getCachedPredictionContext = getCachedPredictionContext;\n\n\n//# sourceURL=webpack:///./antlr4/PredictionContext.js?");

/***/ }),

/***/ "./antlr4/Recognizer.js":
/*!******************************!*\
  !*** ./antlr4/Recognizer.js ***!
  \******************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("//\n/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n//\n\nvar Token = __webpack_require__(/*! ./Token */ \"./antlr4/Token.js\").Token;\nvar ConsoleErrorListener = __webpack_require__(/*! ./error/ErrorListener */ \"./antlr4/error/ErrorListener.js\").ConsoleErrorListener;\nvar ProxyErrorListener = __webpack_require__(/*! ./error/ErrorListener */ \"./antlr4/error/ErrorListener.js\").ProxyErrorListener;\n\nfunction Recognizer() {\n    this._listeners = [ ConsoleErrorListener.INSTANCE ];\n    this._interp = null;\n    this._stateNumber = -1;\n    return this;\n}\n\nRecognizer.tokenTypeMapCache = {};\nRecognizer.ruleIndexMapCache = {};\n\n\nRecognizer.prototype.checkVersion = function(toolVersion) {\n    var runtimeVersion = \"4.7.1\";\n    if (runtimeVersion!==toolVersion) {\n        console.log(\"ANTLR runtime and generated code versions disagree: \"+runtimeVersion+\"!=\"+toolVersion);\n    }\n};\n\nRecognizer.prototype.addErrorListener = function(listener) {\n    this._listeners.push(listener);\n};\n\nRecognizer.prototype.removeErrorListeners = function() {\n    this._listeners = [];\n};\n\nRecognizer.prototype.getTokenTypeMap = function() {\n    var tokenNames = this.getTokenNames();\n    if (tokenNames===null) {\n        throw(\"The current recognizer does not provide a list of token names.\");\n    }\n    var result = this.tokenTypeMapCache[tokenNames];\n    if(result===undefined) {\n        result = tokenNames.reduce(function(o, k, i) { o[k] = i; });\n        result.EOF = Token.EOF;\n        this.tokenTypeMapCache[tokenNames] = result;\n    }\n    return result;\n};\n\n// Get a map from rule names to rule indexes.\n//\n// <p>Used for XPath and tree pattern compilation.</p>\n//\nRecognizer.prototype.getRuleIndexMap = function() {\n    var ruleNames = this.ruleNames;\n    if (ruleNames===null) {\n        throw(\"The current recognizer does not provide a list of rule names.\");\n    }\n    var result = this.ruleIndexMapCache[ruleNames];\n    if(result===undefined) {\n        result = ruleNames.reduce(function(o, k, i) { o[k] = i; });\n        this.ruleIndexMapCache[ruleNames] = result;\n    }\n    return result;\n};\n\nRecognizer.prototype.getTokenType = function(tokenName) {\n    var ttype = this.getTokenTypeMap()[tokenName];\n    if (ttype !==undefined) {\n        return ttype;\n    } else {\n        return Token.INVALID_TYPE;\n    }\n};\n\n\n// What is the error header, normally line/character position information?//\nRecognizer.prototype.getErrorHeader = function(e) {\n    var line = e.getOffendingToken().line;\n    var column = e.getOffendingToken().column;\n    return \"line \" + line + \":\" + column;\n};\n\n\n// How should a token be displayed in an error message? The default\n//  is to display just the text, but during development you might\n//  want to have a lot of information spit out.  Override in that case\n//  to use t.toString() (which, for CommonToken, dumps everything about\n//  the token). This is better than forcing you to override a method in\n//  your token objects because you don't have to go modify your lexer\n//  so that it creates a new Java type.\n//\n// @deprecated This method is not called by the ANTLR 4 Runtime. Specific\n// implementations of {@link ANTLRErrorStrategy} may provide a similar\n// feature when necessary. For example, see\n// {@link DefaultErrorStrategy//getTokenErrorDisplay}.\n//\nRecognizer.prototype.getTokenErrorDisplay = function(t) {\n    if (t===null) {\n        return \"<no token>\";\n    }\n    var s = t.text;\n    if (s===null) {\n        if (t.type===Token.EOF) {\n            s = \"<EOF>\";\n        } else {\n            s = \"<\" + t.type + \">\";\n        }\n    }\n    s = s.replace(\"\\n\",\"\\\\n\").replace(\"\\r\",\"\\\\r\").replace(\"\\t\",\"\\\\t\");\n    return \"'\" + s + \"'\";\n};\n\nRecognizer.prototype.getErrorListenerDispatch = function() {\n    return new ProxyErrorListener(this._listeners);\n};\n\n// subclass needs to override these if there are sempreds or actions\n// that the ATN interp needs to execute\nRecognizer.prototype.sempred = function(localctx, ruleIndex, actionIndex) {\n    return true;\n};\n\nRecognizer.prototype.precpred = function(localctx , precedence) {\n    return true;\n};\n\n//Indicate that the recognizer has changed internal state that is\n//consistent with the ATN state passed in.  This way we always know\n//where we are in the ATN as the parser goes along. The rule\n//context objects form a stack that lets us see the stack of\n//invoking rules. Combine this and we have complete ATN\n//configuration information.\n\nObject.defineProperty(Recognizer.prototype, \"state\", {\n\tget : function() {\n\t\treturn this._stateNumber;\n\t},\n\tset : function(state) {\n\t\tthis._stateNumber = state;\n\t}\n});\n\n\nexports.Recognizer = Recognizer;\n\n\n//# sourceURL=webpack:///./antlr4/Recognizer.js?");

/***/ }),

/***/ "./antlr4/RuleContext.js":
/*!*******************************!*\
  !*** ./antlr4/RuleContext.js ***!
  \*******************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n///\n\n//  A rule context is a record of a single rule invocation. It knows\n//  which context invoked it, if any. If there is no parent context, then\n//  naturally the invoking state is not valid.  The parent link\n//  provides a chain upwards from the current rule invocation to the root\n//  of the invocation tree, forming a stack. We actually carry no\n//  information about the rule associated with this context (except\n//  when parsing). We keep only the state number of the invoking state from\n//  the ATN submachine that invoked this. Contrast this with the s\n//  pointer inside ParserRuleContext that tracks the current state\n//  being \"executed\" for the current rule.\n//\n//  The parent contexts are useful for computing lookahead sets and\n//  getting error information.\n//\n//  These objects are used during parsing and prediction.\n//  For the special case of parsers, we use the subclass\n//  ParserRuleContext.\n//\n//  @see ParserRuleContext\n///\n\nvar RuleNode = __webpack_require__(/*! ./tree/Tree */ \"./antlr4/tree/Tree.js\").RuleNode;\nvar INVALID_INTERVAL = __webpack_require__(/*! ./tree/Tree */ \"./antlr4/tree/Tree.js\").INVALID_INTERVAL;\nvar INVALID_ALT_NUMBER = __webpack_require__(/*! ./atn/ATN */ \"./antlr4/atn/ATN.js\").INVALID_ALT_NUMBER;\n\nfunction RuleContext(parent, invokingState) {\n\tRuleNode.call(this);\n\t// What context invoked this rule?\n\tthis.parentCtx = parent || null;\n\t// What state invoked the rule associated with this context?\n\t// The \"return address\" is the followState of invokingState\n\t// If parent is null, this should be -1.\n\tthis.invokingState = invokingState || -1;\n\treturn this;\n}\n\nRuleContext.prototype = Object.create(RuleNode.prototype);\nRuleContext.prototype.constructor = RuleContext;\n\nRuleContext.prototype.depth = function() {\n\tvar n = 0;\n\tvar p = this;\n\twhile (p !== null) {\n\t\tp = p.parentCtx;\n\t\tn += 1;\n\t}\n\treturn n;\n};\n\n// A context is empty if there is no invoking state; meaning nobody call\n// current context.\nRuleContext.prototype.isEmpty = function() {\n\treturn this.invokingState === -1;\n};\n\n// satisfy the ParseTree / SyntaxTree interface\n\nRuleContext.prototype.getSourceInterval = function() {\n\treturn INVALID_INTERVAL;\n};\n\nRuleContext.prototype.getRuleContext = function() {\n\treturn this;\n};\n\nRuleContext.prototype.getPayload = function() {\n\treturn this;\n};\n\n// Return the combined text of all child nodes. This method only considers\n// tokens which have been added to the parse tree.\n// <p>\n// Since tokens on hidden channels (e.g. whitespace or comments) are not\n// added to the parse trees, they will not appear in the output of this\n// method.\n// /\nRuleContext.prototype.getText = function() {\n\tif (this.getChildCount() === 0) {\n\t\treturn \"\";\n\t} else {\n\t\treturn this.children.map(function(child) {\n\t\t\treturn child.getText();\n\t\t}).join(\"\");\n\t}\n};\n\n// For rule associated with this parse tree internal node, return\n// the outer alternative number used to match the input. Default\n// implementation does not compute nor store this alt num. Create\n// a subclass of ParserRuleContext with backing field and set\n// option contextSuperClass.\n// to set it.\nRuleContext.prototype.getAltNumber = function() { return INVALID_ALT_NUMBER; }\n\n// Set the outer alternative number for this context node. Default\n// implementation does nothing to avoid backing field overhead for\n// trees that don't need it.  Create\n// a subclass of ParserRuleContext with backing field and set\n// option contextSuperClass.\nRuleContext.prototype.setAltNumber = function(altNumber) { }\n\nRuleContext.prototype.getChild = function(i) {\n\treturn null;\n};\n\nRuleContext.prototype.getChildCount = function() {\n\treturn 0;\n};\n\nRuleContext.prototype.accept = function(visitor) {\n\treturn visitor.visitChildren(this);\n};\n\n//need to manage circular dependencies, so export now\nexports.RuleContext = RuleContext;\nvar Trees = __webpack_require__(/*! ./tree/Trees */ \"./antlr4/tree/Trees.js\").Trees;\n\n\n// Print out a whole tree, not just a node, in LISP format\n// (root child1 .. childN). Print just a node if this is a leaf.\n//\n\nRuleContext.prototype.toStringTree = function(ruleNames, recog) {\n\treturn Trees.toStringTree(this, ruleNames, recog);\n};\n\nRuleContext.prototype.toString = function(ruleNames, stop) {\n\truleNames = ruleNames || null;\n\tstop = stop || null;\n\tvar p = this;\n\tvar s = \"[\";\n\twhile (p !== null && p !== stop) {\n\t\tif (ruleNames === null) {\n\t\t\tif (!p.isEmpty()) {\n\t\t\t\ts += p.invokingState;\n\t\t\t}\n\t\t} else {\n\t\t\tvar ri = p.ruleIndex;\n\t\t\tvar ruleName = (ri >= 0 && ri < ruleNames.length) ? ruleNames[ri]\n\t\t\t\t\t: \"\" + ri;\n\t\t\ts += ruleName;\n\t\t}\n\t\tif (p.parentCtx !== null && (ruleNames !== null || !p.parentCtx.isEmpty())) {\n\t\t\ts += \" \";\n\t\t}\n\t\tp = p.parentCtx;\n\t}\n\ts += \"]\";\n\treturn s;\n};\n\n\n\n//# sourceURL=webpack:///./antlr4/RuleContext.js?");

/***/ }),

/***/ "./antlr4/Token.js":
/*!*************************!*\
  !*** ./antlr4/Token.js ***!
  \*************************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n//\n\n// A token has properties: text, type, line, character position in the line\n// (so we can ignore tabs), token channel, index, and source from which\n// we obtained this token.\n\nfunction Token() {\n\tthis.source = null;\n\tthis.type = null; // token type of the token\n\tthis.channel = null; // The parser ignores everything not on DEFAULT_CHANNEL\n\tthis.start = null; // optional; return -1 if not implemented.\n\tthis.stop = null; // optional; return -1 if not implemented.\n\tthis.tokenIndex = null; // from 0..n-1 of the token object in the input stream\n\tthis.line = null; // line=1..n of the 1st character\n\tthis.column = null; // beginning of the line at which it occurs, 0..n-1\n\tthis._text = null; // text of the token.\n\treturn this;\n}\n\nToken.INVALID_TYPE = 0;\n\n// During lookahead operations, this \"token\" signifies we hit rule end ATN state\n// and did not follow it despite needing to.\nToken.EPSILON = -2;\n\nToken.MIN_USER_TOKEN_TYPE = 1;\n\nToken.EOF = -1;\n\n// All tokens go to the parser (unless skip() is called in that rule)\n// on a particular \"channel\". The parser tunes to a particular channel\n// so that whitespace etc... can go to the parser on a \"hidden\" channel.\n\nToken.DEFAULT_CHANNEL = 0;\n\n// Anything on different channel than DEFAULT_CHANNEL is not parsed\n// by parser.\n\nToken.HIDDEN_CHANNEL = 1;\n\n// Explicitly set the text for this token. If {code text} is not\n// {@code null}, then {@link //getText} will return this value rather than\n// extracting the text from the input.\n//\n// @param text The explicit text of the token, or {@code null} if the text\n// should be obtained from the input along with the start and stop indexes\n// of the token.\n\nObject.defineProperty(Token.prototype, \"text\", {\n\tget : function() {\n\t\treturn this._text;\n\t},\n\tset : function(text) {\n\t\tthis._text = text;\n\t}\n});\n\nToken.prototype.getTokenSource = function() {\n\treturn this.source[0];\n};\n\nToken.prototype.getInputStream = function() {\n\treturn this.source[1];\n};\n\nfunction CommonToken(source, type, channel, start, stop) {\n\tToken.call(this);\n\tthis.source = source !== undefined ? source : CommonToken.EMPTY_SOURCE;\n\tthis.type = type !== undefined ? type : null;\n\tthis.channel = channel !== undefined ? channel : Token.DEFAULT_CHANNEL;\n\tthis.start = start !== undefined ? start : -1;\n\tthis.stop = stop !== undefined ? stop : -1;\n\tthis.tokenIndex = -1;\n\tif (this.source[0] !== null) {\n\t\tthis.line = source[0].line;\n\t\tthis.column = source[0].column;\n\t} else {\n\t\tthis.column = -1;\n\t}\n\treturn this;\n}\n\nCommonToken.prototype = Object.create(Token.prototype);\nCommonToken.prototype.constructor = CommonToken;\n\n// An empty {@link Pair} which is used as the default value of\n// {@link //source} for tokens that do not have a source.\nCommonToken.EMPTY_SOURCE = [ null, null ];\n\n// Constructs a new {@link CommonToken} as a copy of another {@link Token}.\n//\n// <p>\n// If {@code oldToken} is also a {@link CommonToken} instance, the newly\n// constructed token will share a reference to the {@link //text} field and\n// the {@link Pair} stored in {@link //source}. Otherwise, {@link //text} will\n// be assigned the result of calling {@link //getText}, and {@link //source}\n// will be constructed from the result of {@link Token//getTokenSource} and\n// {@link Token//getInputStream}.</p>\n//\n// @param oldToken The token to copy.\n//\nCommonToken.prototype.clone = function() {\n\tvar t = new CommonToken(this.source, this.type, this.channel, this.start,\n\t\t\tthis.stop);\n\tt.tokenIndex = this.tokenIndex;\n\tt.line = this.line;\n\tt.column = this.column;\n\tt.text = this.text;\n\treturn t;\n};\n\nObject.defineProperty(CommonToken.prototype, \"text\", {\n\tget : function() {\n\t\tif (this._text !== null) {\n\t\t\treturn this._text;\n\t\t}\n\t\tvar input = this.getInputStream();\n\t\tif (input === null) {\n\t\t\treturn null;\n\t\t}\n\t\tvar n = input.size;\n\t\tif (this.start < n && this.stop < n) {\n\t\t\treturn input.getText(this.start, this.stop);\n\t\t} else {\n\t\t\treturn \"<EOF>\";\n\t\t}\n\t},\n\tset : function(text) {\n\t\tthis._text = text;\n\t}\n});\n\nCommonToken.prototype.toString = function() {\n\tvar txt = this.text;\n\tif (txt !== null) {\n\t\ttxt = txt.replace(/\\n/g, \"\\\\n\").replace(/\\r/g, \"\\\\r\").replace(/\\t/g, \"\\\\t\");\n\t} else {\n\t\ttxt = \"<no text>\";\n\t}\n\treturn \"[@\" + this.tokenIndex + \",\" + this.start + \":\" + this.stop + \"='\" +\n\t\t\ttxt + \"',<\" + this.type + \">\" +\n\t\t\t(this.channel > 0 ? \",channel=\" + this.channel : \"\") + \",\" +\n\t\t\tthis.line + \":\" + this.column + \"]\";\n};\n\nexports.Token = Token;\nexports.CommonToken = CommonToken;\n\n\n//# sourceURL=webpack:///./antlr4/Token.js?");

/***/ }),

/***/ "./antlr4/Utils.js":
/*!*************************!*\
  !*** ./antlr4/Utils.js ***!
  \*************************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nfunction arrayToString(a) {\n    return \"[\" + a.join(\", \") + \"]\";\n}\n\nString.prototype.seed = String.prototype.seed || Math.round(Math.random() * Math.pow(2, 32));\n\nString.prototype.hashCode = function () {\n    var remainder, bytes, h1, h1b, c1, c1b, c2, c2b, k1, i,\n        key = this.toString();\n\n    remainder = key.length & 3; // key.length % 4\n    bytes = key.length - remainder;\n    h1 = String.prototype.seed;\n    c1 = 0xcc9e2d51;\n    c2 = 0x1b873593;\n    i = 0;\n\n    while (i < bytes) {\n        k1 =\n            ((key.charCodeAt(i) & 0xff)) |\n            ((key.charCodeAt(++i) & 0xff) << 8) |\n            ((key.charCodeAt(++i) & 0xff) << 16) |\n            ((key.charCodeAt(++i) & 0xff) << 24);\n        ++i;\n\n        k1 = ((((k1 & 0xffff) * c1) + ((((k1 >>> 16) * c1) & 0xffff) << 16))) & 0xffffffff;\n        k1 = (k1 << 15) | (k1 >>> 17);\n        k1 = ((((k1 & 0xffff) * c2) + ((((k1 >>> 16) * c2) & 0xffff) << 16))) & 0xffffffff;\n\n        h1 ^= k1;\n        h1 = (h1 << 13) | (h1 >>> 19);\n        h1b = ((((h1 & 0xffff) * 5) + ((((h1 >>> 16) * 5) & 0xffff) << 16))) & 0xffffffff;\n        h1 = (((h1b & 0xffff) + 0x6b64) + ((((h1b >>> 16) + 0xe654) & 0xffff) << 16));\n    }\n\n    k1 = 0;\n\n    switch (remainder) {\n        case 3:\n            k1 ^= (key.charCodeAt(i + 2) & 0xff) << 16;\n        case 2:\n            k1 ^= (key.charCodeAt(i + 1) & 0xff) << 8;\n        case 1:\n            k1 ^= (key.charCodeAt(i) & 0xff);\n\n            k1 = (((k1 & 0xffff) * c1) + ((((k1 >>> 16) * c1) & 0xffff) << 16)) & 0xffffffff;\n            k1 = (k1 << 15) | (k1 >>> 17);\n            k1 = (((k1 & 0xffff) * c2) + ((((k1 >>> 16) * c2) & 0xffff) << 16)) & 0xffffffff;\n            h1 ^= k1;\n    }\n\n    h1 ^= key.length;\n\n    h1 ^= h1 >>> 16;\n    h1 = (((h1 & 0xffff) * 0x85ebca6b) + ((((h1 >>> 16) * 0x85ebca6b) & 0xffff) << 16)) & 0xffffffff;\n    h1 ^= h1 >>> 13;\n    h1 = ((((h1 & 0xffff) * 0xc2b2ae35) + ((((h1 >>> 16) * 0xc2b2ae35) & 0xffff) << 16))) & 0xffffffff;\n    h1 ^= h1 >>> 16;\n\n    return h1 >>> 0;\n};\n\nfunction standardEqualsFunction(a, b) {\n    return a.equals(b);\n}\n\nfunction standardHashCodeFunction(a) {\n    return a.hashCode();\n}\n\nfunction Set(hashFunction, equalsFunction) {\n    this.data = {};\n    this.hashFunction = hashFunction || standardHashCodeFunction;\n    this.equalsFunction = equalsFunction || standardEqualsFunction;\n    return this;\n}\n\nObject.defineProperty(Set.prototype, \"length\", {\n    get: function () {\n        var l = 0;\n        for (var key in this.data) {\n            if (key.indexOf(\"hash_\") === 0) {\n                l = l + this.data[key].length;\n            }\n        }\n        return l;\n    }\n});\n\nSet.prototype.add = function (value) {\n    var hash = this.hashFunction(value);\n    var key = \"hash_\" + hash;\n    if (key in this.data) {\n        var values = this.data[key];\n        for (var i = 0; i < values.length; i++) {\n            if (this.equalsFunction(value, values[i])) {\n                return values[i];\n            }\n        }\n        values.push(value);\n        return value;\n    } else {\n        this.data[key] = [value];\n        return value;\n    }\n};\n\nSet.prototype.contains = function (value) {\n    return this.get(value) != null;\n};\n\nSet.prototype.get = function (value) {\n    var hash = this.hashFunction(value);\n    var key = \"hash_\" + hash;\n    if (key in this.data) {\n        var values = this.data[key];\n        for (var i = 0; i < values.length; i++) {\n            if (this.equalsFunction(value, values[i])) {\n                return values[i];\n            }\n        }\n    }\n    return null;\n};\n\nSet.prototype.values = function () {\n    var l = [];\n    for (var key in this.data) {\n        if (key.indexOf(\"hash_\") === 0) {\n            l = l.concat(this.data[key]);\n        }\n    }\n    return l;\n};\n\nSet.prototype.toString = function () {\n    return arrayToString(this.values());\n};\n\nfunction BitSet() {\n    this.data = [];\n    return this;\n}\n\nBitSet.prototype.add = function (value) {\n    this.data[value] = true;\n};\n\nBitSet.prototype.or = function (set) {\n    var bits = this;\n    Object.keys(set.data).map(function (alt) {\n        bits.add(alt);\n    });\n};\n\nBitSet.prototype.remove = function (value) {\n    delete this.data[value];\n};\n\nBitSet.prototype.contains = function (value) {\n    return this.data[value] === true;\n};\n\nBitSet.prototype.values = function () {\n    return Object.keys(this.data);\n};\n\nBitSet.prototype.minValue = function () {\n    return Math.min.apply(null, this.values());\n};\n\nBitSet.prototype.hashCode = function () {\n    var hash = new Hash();\n    hash.update(this.values());\n    return hash.finish();\n};\n\nBitSet.prototype.equals = function (other) {\n    if (!(other instanceof BitSet)) {\n        return false;\n    }\n    return this.hashCode() === other.hashCode();\n};\n\nObject.defineProperty(BitSet.prototype, \"length\", {\n    get: function () {\n        return this.values().length;\n    }\n});\n\nBitSet.prototype.toString = function () {\n    return \"{\" + this.values().join(\", \") + \"}\";\n};\n\nfunction Map(hashFunction, equalsFunction) {\n    this.data = {};\n    this.hashFunction = hashFunction || standardHashCodeFunction;\n    this.equalsFunction = equalsFunction || standardEqualsFunction;\n    return this;\n}\n\nObject.defineProperty(Map.prototype, \"length\", {\n    get: function () {\n        var l = 0;\n        for (var hashKey in this.data) {\n            if (hashKey.indexOf(\"hash_\") === 0) {\n                l = l + this.data[hashKey].length;\n            }\n        }\n        return l;\n    }\n});\n\nMap.prototype.put = function (key, value) {\n    var hashKey = \"hash_\" + this.hashFunction(key);\n    if (hashKey in this.data) {\n        var entries = this.data[hashKey];\n        for (var i = 0; i < entries.length; i++) {\n            var entry = entries[i];\n            if (this.equalsFunction(key, entry.key)) {\n                var oldValue = entry.value;\n                entry.value = value;\n                return oldValue;\n            }\n        }\n        entries.push({key:key, value:value});\n        return value;\n    } else {\n        this.data[hashKey] = [{key:key, value:value}];\n        return value;\n    }\n};\n\nMap.prototype.containsKey = function (key) {\n    var hashKey = \"hash_\" + this.hashFunction(key);\n    if(hashKey in this.data) {\n        var entries = this.data[hashKey];\n        for (var i = 0; i < entries.length; i++) {\n            var entry = entries[i];\n            if (this.equalsFunction(key, entry.key))\n                return true;\n        }\n    }\n    return false;\n};\n\nMap.prototype.get = function (key) {\n    var hashKey = \"hash_\" + this.hashFunction(key);\n    if(hashKey in this.data) {\n        var entries = this.data[hashKey];\n        for (var i = 0; i < entries.length; i++) {\n            var entry = entries[i];\n            if (this.equalsFunction(key, entry.key))\n                return entry.value;\n        }\n    }\n    return null;\n};\n\nMap.prototype.entries = function () {\n    var l = [];\n    for (var key in this.data) {\n        if (key.indexOf(\"hash_\") === 0) {\n            l = l.concat(this.data[key]);\n        }\n    }\n    return l;\n};\n\n\nMap.prototype.getKeys = function () {\n    return this.entries().map(function(e) {\n        return e.key;\n    });\n};\n\n\nMap.prototype.getValues = function () {\n    return this.entries().map(function(e) {\n            return e.value;\n    });\n};\n\n\nMap.prototype.toString = function () {\n    var ss = this.entries().map(function(entry) {\n        return '{' + entry.key + ':' + entry.value + '}';\n    });\n    return '[' + ss.join(\", \") + ']';\n};\n\n\nfunction AltDict() {\n    this.data = {};\n    return this;\n}\n\n\nAltDict.prototype.get = function (key) {\n    key = \"k-\" + key;\n    if (key in this.data) {\n        return this.data[key];\n    } else {\n        return null;\n    }\n};\n\nAltDict.prototype.put = function (key, value) {\n    key = \"k-\" + key;\n    this.data[key] = value;\n};\n\nAltDict.prototype.values = function () {\n    var data = this.data;\n    var keys = Object.keys(this.data);\n    return keys.map(function (key) {\n        return data[key];\n    });\n};\n\nfunction DoubleDict() {\n    return this;\n}\n\nfunction Hash() {\n    this.count = 0;\n    this.hash = 0;\n    return this;\n}\n\nHash.prototype.update = function () {\n    for(var i=0;i<arguments.length;i++) {\n        var value = arguments[i];\n        if (value == null)\n            continue;\n        if(Array.isArray(value))\n            this.update.apply(value);\n        else {\n            var k = 0;\n            switch (typeof(value)) {\n                case 'undefined':\n                case 'function':\n                    continue;\n                case 'number':\n                case 'boolean':\n                    k = value;\n                    break;\n                case 'string':\n                    k = value.hashCode();\n                    break;\n                default:\n                    value.updateHashCode(this);\n                    continue;\n            }\n            k = k * 0xCC9E2D51;\n            k = (k << 15) | (k >>> (32 - 15));\n            k = k * 0x1B873593;\n            this.count = this.count + 1;\n            var hash = this.hash ^ k;\n            hash = (hash << 13) | (hash >>> (32 - 13));\n            hash = hash * 5 + 0xE6546B64;\n            this.hash = hash;\n        }\n    }\n}\n\nHash.prototype.finish = function () {\n    var hash = this.hash ^ (this.count * 4);\n    hash = hash ^ (hash >>> 16);\n    hash = hash * 0x85EBCA6B;\n    hash = hash ^ (hash >>> 13);\n    hash = hash * 0xC2B2AE35;\n    hash = hash ^ (hash >>> 16);\n    return hash;\n}\n\nfunction hashStuff() {\n    var hash = new Hash();\n    hash.update.apply(arguments);\n    return hash.finish();\n}\n\nDoubleDict.prototype.get = function (a, b) {\n    var d = this[a] || null;\n    return d === null ? null : (d[b] || null);\n};\n\nDoubleDict.prototype.set = function (a, b, o) {\n    var d = this[a] || null;\n    if (d === null) {\n        d = {};\n        this[a] = d;\n    }\n    d[b] = o;\n};\n\n\nfunction escapeWhitespace(s, escapeSpaces) {\n    s = s.replace(/\\t/g, \"\\\\t\")\n         .replace(/\\n/g, \"\\\\n\")\n         .replace(/\\r/g, \"\\\\r\");\n    if (escapeSpaces) {\n        s = s.replace(/ /g, \"\\u00B7\");\n    }\n    return s;\n}\n\nfunction titleCase(str) {\n    return str.replace(/\\w\\S*/g, function (txt) {\n        return txt.charAt(0).toUpperCase() + txt.substr(1);\n    });\n};\n\nfunction equalArrays(a, b)\n{\n    if (!Array.isArray(a) || !Array.isArray(b))\n        return false;\n    if (a == b)\n        return true;\n    if (a.length != b.length)\n        return false;\n    for (var i = 0; i < a.length; i++) {\n        if (a[i] == b[i])\n            continue;\n        if (!a[i].equals(b[i]))\n            return false;\n    }\n    return true;\n};\n\nexports.Hash = Hash;\nexports.Set = Set;\nexports.Map = Map;\nexports.BitSet = BitSet;\nexports.AltDict = AltDict;\nexports.DoubleDict = DoubleDict;\nexports.hashStuff = hashStuff;\nexports.escapeWhitespace = escapeWhitespace;\nexports.arrayToString = arrayToString;\nexports.titleCase = titleCase;\nexports.equalArrays = equalArrays;\n\n\n//# sourceURL=webpack:///./antlr4/Utils.js?");

/***/ }),

/***/ "./antlr4/atn/ATN.js":
/*!***************************!*\
  !*** ./antlr4/atn/ATN.js ***!
  \***************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nvar LL1Analyzer = __webpack_require__(/*! ./../LL1Analyzer */ \"./antlr4/LL1Analyzer.js\").LL1Analyzer;\nvar IntervalSet = __webpack_require__(/*! ./../IntervalSet */ \"./antlr4/IntervalSet.js\").IntervalSet;\n\nfunction ATN(grammarType , maxTokenType) {\n\n    // Used for runtime deserialization of ATNs from strings///\n    // The type of the ATN.\n    this.grammarType = grammarType;\n    // The maximum value for any symbol recognized by a transition in the ATN.\n    this.maxTokenType = maxTokenType;\n    this.states = [];\n    // Each subrule/rule is a decision point and we must track them so we\n    //  can go back later and build DFA predictors for them.  This includes\n    //  all the rules, subrules, optional blocks, ()+, ()* etc...\n    this.decisionToState = [];\n    // Maps from rule index to starting state number.\n    this.ruleToStartState = [];\n    // Maps from rule index to stop state number.\n    this.ruleToStopState = null;\n    this.modeNameToStartState = {};\n    // For lexer ATNs, this maps the rule index to the resulting token type.\n    // For parser ATNs, this maps the rule index to the generated bypass token\n    // type if the\n    // {@link ATNDeserializationOptions//isGenerateRuleBypassTransitions}\n    // deserialization option was specified; otherwise, this is {@code null}.\n    this.ruleToTokenType = null;\n    // For lexer ATNs, this is an array of {@link LexerAction} objects which may\n    // be referenced by action transitions in the ATN.\n    this.lexerActions = null;\n    this.modeToStartState = [];\n\n    return this;\n}\n\n// Compute the set of valid tokens that can occur starting in state {@code s}.\n//  If {@code ctx} is null, the set of tokens will not include what can follow\n//  the rule surrounding {@code s}. In other words, the set will be\n//  restricted to tokens reachable staying within {@code s}'s rule.\nATN.prototype.nextTokensInContext = function(s, ctx) {\n    var anal = new LL1Analyzer(this);\n    return anal.LOOK(s, null, ctx);\n};\n\n// Compute the set of valid tokens that can occur starting in {@code s} and\n// staying in same rule. {@link Token//EPSILON} is in set if we reach end of\n// rule.\nATN.prototype.nextTokensNoContext = function(s) {\n    if (s.nextTokenWithinRule !== null ) {\n        return s.nextTokenWithinRule;\n    }\n    s.nextTokenWithinRule = this.nextTokensInContext(s, null);\n    s.nextTokenWithinRule.readOnly = true;\n    return s.nextTokenWithinRule;\n};\n\nATN.prototype.nextTokens = function(s, ctx) {\n    if ( ctx===undefined ) {\n        return this.nextTokensNoContext(s);\n    } else {\n        return this.nextTokensInContext(s, ctx);\n    }\n};\n\nATN.prototype.addState = function( state) {\n    if ( state !== null ) {\n        state.atn = this;\n        state.stateNumber = this.states.length;\n    }\n    this.states.push(state);\n};\n\nATN.prototype.removeState = function( state) {\n    this.states[state.stateNumber] = null; // just free mem, don't shift states in list\n};\n\nATN.prototype.defineDecisionState = function( s) {\n    this.decisionToState.push(s);\n    s.decision = this.decisionToState.length-1;\n    return s.decision;\n};\n\nATN.prototype.getDecisionState = function( decision) {\n    if (this.decisionToState.length===0) {\n        return null;\n    } else {\n        return this.decisionToState[decision];\n    }\n};\n\n// Computes the set of input symbols which could follow ATN state number\n// {@code stateNumber} in the specified full {@code context}. This method\n// considers the complete parser context, but does not evaluate semantic\n// predicates (i.e. all predicates encountered during the calculation are\n// assumed true). If a path in the ATN exists from the starting state to the\n// {@link RuleStopState} of the outermost context without matching any\n// symbols, {@link Token//EOF} is added to the returned set.\n//\n// <p>If {@code context} is {@code null}, it is treated as\n// {@link ParserRuleContext//EMPTY}.</p>\n//\n// @param stateNumber the ATN state number\n// @param context the full parse context\n// @return The set of potentially valid input symbols which could follow the\n// specified state in the specified context.\n// @throws IllegalArgumentException if the ATN does not contain a state with\n// number {@code stateNumber}\nvar Token = __webpack_require__(/*! ./../Token */ \"./antlr4/Token.js\").Token;\n\nATN.prototype.getExpectedTokens = function( stateNumber, ctx ) {\n    if ( stateNumber < 0 || stateNumber >= this.states.length ) {\n        throw(\"Invalid state number.\");\n    }\n    var s = this.states[stateNumber];\n    var following = this.nextTokens(s);\n    if (!following.contains(Token.EPSILON)) {\n        return following;\n    }\n    var expected = new IntervalSet();\n    expected.addSet(following);\n    expected.removeOne(Token.EPSILON);\n    while (ctx !== null && ctx.invokingState >= 0 && following.contains(Token.EPSILON)) {\n        var invokingState = this.states[ctx.invokingState];\n        var rt = invokingState.transitions[0];\n        following = this.nextTokens(rt.followState);\n        expected.addSet(following);\n        expected.removeOne(Token.EPSILON);\n        ctx = ctx.parentCtx;\n    }\n    if (following.contains(Token.EPSILON)) {\n        expected.addOne(Token.EOF);\n    }\n    return expected;\n};\n\nATN.INVALID_ALT_NUMBER = 0;\n\nexports.ATN = ATN;\n\n//# sourceURL=webpack:///./antlr4/atn/ATN.js?");

/***/ }),

/***/ "./antlr4/atn/ATNConfig.js":
/*!*********************************!*\
  !*** ./antlr4/atn/ATNConfig.js ***!
  \*********************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("//\n/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n///\n\n// A tuple: (ATN state, predicted alt, syntactic, semantic context).\n//  The syntactic context is a graph-structured stack node whose\n//  path(s) to the root is the rule invocation(s)\n//  chain used to arrive at the state.  The semantic context is\n//  the tree of semantic predicates encountered before reaching\n//  an ATN state.\n///\n\nvar DecisionState = __webpack_require__(/*! ./ATNState */ \"./antlr4/atn/ATNState.js\").DecisionState;\nvar SemanticContext = __webpack_require__(/*! ./SemanticContext */ \"./antlr4/atn/SemanticContext.js\").SemanticContext;\nvar Hash = __webpack_require__(/*! ../Utils */ \"./antlr4/Utils.js\").Hash;\n\n\nfunction checkParams(params, isCfg) {\n\tif(params===null) {\n\t\tvar result = { state:null, alt:null, context:null, semanticContext:null };\n\t\tif(isCfg) {\n\t\t\tresult.reachesIntoOuterContext = 0;\n\t\t}\n\t\treturn result;\n\t} else {\n\t\tvar props = {};\n\t\tprops.state = params.state || null;\n\t\tprops.alt = (params.alt === undefined) ? null : params.alt;\n\t\tprops.context = params.context || null;\n\t\tprops.semanticContext = params.semanticContext || null;\n\t\tif(isCfg) {\n\t\t\tprops.reachesIntoOuterContext = params.reachesIntoOuterContext || 0;\n\t\t\tprops.precedenceFilterSuppressed = params.precedenceFilterSuppressed || false;\n\t\t}\n\t\treturn props;\n\t}\n}\n\nfunction ATNConfig(params, config) {\n\tthis.checkContext(params, config);\n\tparams = checkParams(params);\n\tconfig = checkParams(config, true);\n    // The ATN state associated with this configuration///\n    this.state = params.state!==null ? params.state : config.state;\n    // What alt (or lexer rule) is predicted by this configuration///\n    this.alt = params.alt!==null ? params.alt : config.alt;\n    // The stack of invoking states leading to the rule/states associated\n    //  with this config.  We track only those contexts pushed during\n    //  execution of the ATN simulator.\n    this.context = params.context!==null ? params.context : config.context;\n    this.semanticContext = params.semanticContext!==null ? params.semanticContext :\n        (config.semanticContext!==null ? config.semanticContext : SemanticContext.NONE);\n    // We cannot execute predicates dependent upon local context unless\n    // we know for sure we are in the correct context. Because there is\n    // no way to do this efficiently, we simply cannot evaluate\n    // dependent predicates unless we are in the rule that initially\n    // invokes the ATN simulator.\n    //\n    // closure() tracks the depth of how far we dip into the\n    // outer context: depth &gt; 0.  Note that it may not be totally\n    // accurate depth since I don't ever decrement. TODO: make it a boolean then\n    this.reachesIntoOuterContext = config.reachesIntoOuterContext;\n    this.precedenceFilterSuppressed = config.precedenceFilterSuppressed;\n    return this;\n}\n\nATNConfig.prototype.checkContext = function(params, config) {\n\tif((params.context===null || params.context===undefined) &&\n\t\t\t(config===null || config.context===null || config.context===undefined)) {\n\t\tthis.context = null;\n\t}\n};\n\n\nATNConfig.prototype.hashCode = function() {\n    var hash = new Hash();\n    this.updateHashCode(hash);\n    return hash.finish();\n};\n\n\nATNConfig.prototype.updateHashCode = function(hash) {\n    hash.update(this.state.stateNumber, this.alt, this.context, this.semanticContext);\n};\n\n// An ATN configuration is equal to another if both have\n//  the same state, they predict the same alternative, and\n//  syntactic/semantic contexts are the same.\n\nATNConfig.prototype.equals = function(other) {\n    if (this === other) {\n        return true;\n    } else if (! (other instanceof ATNConfig)) {\n        return false;\n    } else {\n        return this.state.stateNumber===other.state.stateNumber &&\n            this.alt===other.alt &&\n            (this.context===null ? other.context===null : this.context.equals(other.context)) &&\n            this.semanticContext.equals(other.semanticContext) &&\n            this.precedenceFilterSuppressed===other.precedenceFilterSuppressed;\n    }\n};\n\n\nATNConfig.prototype.hashCodeForConfigSet = function() {\n    var hash = new Hash();\n    hash.update(this.state.stateNumber, this.alt, this.semanticContext);\n    return hash.finish();\n};\n\n\nATNConfig.prototype.equalsForConfigSet = function(other) {\n    if (this === other) {\n        return true;\n    } else if (! (other instanceof ATNConfig)) {\n        return false;\n    } else {\n        return this.state.stateNumber===other.state.stateNumber &&\n            this.alt===other.alt &&\n            this.semanticContext.equals(other.semanticContext);\n    }\n};\n\n\nATNConfig.prototype.toString = function() {\n    return \"(\" + this.state + \",\" + this.alt +\n        (this.context!==null ? \",[\" + this.context.toString() + \"]\" : \"\") +\n        (this.semanticContext !== SemanticContext.NONE ?\n                (\",\" + this.semanticContext.toString())\n                : \"\") +\n        (this.reachesIntoOuterContext>0 ?\n                (\",up=\" + this.reachesIntoOuterContext)\n                : \"\") + \")\";\n};\n\n\nfunction LexerATNConfig(params, config) {\n\tATNConfig.call(this, params, config);\n\n    // This is the backing field for {@link //getLexerActionExecutor}.\n\tvar lexerActionExecutor = params.lexerActionExecutor || null;\n    this.lexerActionExecutor = lexerActionExecutor || (config!==null ? config.lexerActionExecutor : null);\n    this.passedThroughNonGreedyDecision = config!==null ? this.checkNonGreedyDecision(config, this.state) : false;\n    return this;\n}\n\nLexerATNConfig.prototype = Object.create(ATNConfig.prototype);\nLexerATNConfig.prototype.constructor = LexerATNConfig;\n\nLexerATNConfig.prototype.updateHashCode = function(hash) {\n    hash.update(this.state.stateNumber, this.alt, this.context, this.semanticContext, this.passedThroughNonGreedyDecision, this.lexerActionExecutor);\n};\n\nLexerATNConfig.prototype.equals = function(other) {\n    return this === other ||\n            (other instanceof LexerATNConfig &&\n            this.passedThroughNonGreedyDecision == other.passedThroughNonGreedyDecision &&\n            (this.lexerActionExecutor ? this.lexerActionExecutor.equals(other.lexerActionExecutor) : !other.lexerActionExecutor) &&\n            ATNConfig.prototype.equals.call(this, other));\n};\n\nLexerATNConfig.prototype.hashCodeForConfigSet = LexerATNConfig.prototype.hashCode;\n\nLexerATNConfig.prototype.equalsForConfigSet = LexerATNConfig.prototype.equals;\n\n\nLexerATNConfig.prototype.checkNonGreedyDecision = function(source, target) {\n    return source.passedThroughNonGreedyDecision ||\n        (target instanceof DecisionState) && target.nonGreedy;\n};\n\nexports.ATNConfig = ATNConfig;\nexports.LexerATNConfig = LexerATNConfig;\n\n//# sourceURL=webpack:///./antlr4/atn/ATNConfig.js?");

/***/ }),

/***/ "./antlr4/atn/ATNConfigSet.js":
/*!************************************!*\
  !*** ./antlr4/atn/ATNConfigSet.js ***!
  \************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("//\n/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\n//\n// Specialized {@link Set}{@code <}{@link ATNConfig}{@code >} that can track\n// info about the set, with support for combining similar configurations using a\n// graph-structured stack.\n///\n\nvar ATN = __webpack_require__(/*! ./ATN */ \"./antlr4/atn/ATN.js\").ATN;\nvar Utils = __webpack_require__(/*! ./../Utils */ \"./antlr4/Utils.js\");\nvar Hash = Utils.Hash;\nvar Set = Utils.Set;\nvar SemanticContext = __webpack_require__(/*! ./SemanticContext */ \"./antlr4/atn/SemanticContext.js\").SemanticContext;\nvar merge = __webpack_require__(/*! ./../PredictionContext */ \"./antlr4/PredictionContext.js\").merge;\n\nfunction hashATNConfig(c) {\n\treturn c.hashCodeForConfigSet();\n}\n\nfunction equalATNConfigs(a, b) {\n\tif ( a===b ) {\n\t\treturn true;\n\t} else if ( a===null || b===null ) {\n\t\treturn false;\n\t} else\n       return a.equalsForConfigSet(b);\n }\n\n\nfunction ATNConfigSet(fullCtx) {\n\t//\n\t// The reason that we need this is because we don't want the hash map to use\n\t// the standard hash code and equals. We need all configurations with the\n\t// same\n\t// {@code (s,i,_,semctx)} to be equal. Unfortunately, this key effectively\n\t// doubles\n\t// the number of objects associated with ATNConfigs. The other solution is\n\t// to\n\t// use a hash table that lets us specify the equals/hashcode operation.\n\t// All configs but hashed by (s, i, _, pi) not including context. Wiped out\n\t// when we go readonly as this set becomes a DFA state.\n\tthis.configLookup = new Set(hashATNConfig, equalATNConfigs);\n\t// Indicates that this configuration set is part of a full context\n\t// LL prediction. It will be used to determine how to merge $. With SLL\n\t// it's a wildcard whereas it is not for LL context merge.\n\tthis.fullCtx = fullCtx === undefined ? true : fullCtx;\n\t// Indicates that the set of configurations is read-only. Do not\n\t// allow any code to manipulate the set; DFA states will point at\n\t// the sets and they must not change. This does not protect the other\n\t// fields; in particular, conflictingAlts is set after\n\t// we've made this readonly.\n\tthis.readOnly = false;\n\t// Track the elements as they are added to the set; supports get(i)///\n\tthis.configs = [];\n\n\t// TODO: these fields make me pretty uncomfortable but nice to pack up info\n\t// together, saves recomputation\n\t// TODO: can we track conflicts as they are added to save scanning configs\n\t// later?\n\tthis.uniqueAlt = 0;\n\tthis.conflictingAlts = null;\n\n\t// Used in parser and lexer. In lexer, it indicates we hit a pred\n\t// while computing a closure operation. Don't make a DFA state from this.\n\tthis.hasSemanticContext = false;\n\tthis.dipsIntoOuterContext = false;\n\n\tthis.cachedHashCode = -1;\n\n\treturn this;\n}\n\n// Adding a new config means merging contexts with existing configs for\n// {@code (s, i, pi, _)}, where {@code s} is the\n// {@link ATNConfig//state}, {@code i} is the {@link ATNConfig//alt}, and\n// {@code pi} is the {@link ATNConfig//semanticContext}. We use\n// {@code (s,i,pi)} as key.\n//\n// <p>This method updates {@link //dipsIntoOuterContext} and\n// {@link //hasSemanticContext} when necessary.</p>\n// /\nATNConfigSet.prototype.add = function(config, mergeCache) {\n\tif (mergeCache === undefined) {\n\t\tmergeCache = null;\n\t}\n\tif (this.readOnly) {\n\t\tthrow \"This set is readonly\";\n\t}\n\tif (config.semanticContext !== SemanticContext.NONE) {\n\t\tthis.hasSemanticContext = true;\n\t}\n\tif (config.reachesIntoOuterContext > 0) {\n\t\tthis.dipsIntoOuterContext = true;\n\t}\n\tvar existing = this.configLookup.add(config);\n\tif (existing === config) {\n\t\tthis.cachedHashCode = -1;\n\t\tthis.configs.push(config); // track order here\n\t\treturn true;\n\t}\n\t// a previous (s,i,pi,_), merge with it and save result\n\tvar rootIsWildcard = !this.fullCtx;\n\tvar merged = merge(existing.context, config.context, rootIsWildcard, mergeCache);\n\t// no need to check for existing.context, config.context in cache\n\t// since only way to create new graphs is \"call rule\" and here. We\n\t// cache at both places.\n\texisting.reachesIntoOuterContext = Math.max( existing.reachesIntoOuterContext, config.reachesIntoOuterContext);\n\t// make sure to preserve the precedence filter suppression during the merge\n\tif (config.precedenceFilterSuppressed) {\n\t\texisting.precedenceFilterSuppressed = true;\n\t}\n\texisting.context = merged; // replace context; no need to alt mapping\n\treturn true;\n};\n\nATNConfigSet.prototype.getStates = function() {\n\tvar states = new Set();\n\tfor (var i = 0; i < this.configs.length; i++) {\n\t\tstates.add(this.configs[i].state);\n\t}\n\treturn states;\n};\n\nATNConfigSet.prototype.getPredicates = function() {\n\tvar preds = [];\n\tfor (var i = 0; i < this.configs.length; i++) {\n\t\tvar c = this.configs[i].semanticContext;\n\t\tif (c !== SemanticContext.NONE) {\n\t\t\tpreds.push(c.semanticContext);\n\t\t}\n\t}\n\treturn preds;\n};\n\nObject.defineProperty(ATNConfigSet.prototype, \"items\", {\n\tget : function() {\n\t\treturn this.configs;\n\t}\n});\n\nATNConfigSet.prototype.optimizeConfigs = function(interpreter) {\n\tif (this.readOnly) {\n\t\tthrow \"This set is readonly\";\n\t}\n\tif (this.configLookup.length === 0) {\n\t\treturn;\n\t}\n\tfor (var i = 0; i < this.configs.length; i++) {\n\t\tvar config = this.configs[i];\n\t\tconfig.context = interpreter.getCachedContext(config.context);\n\t}\n};\n\nATNConfigSet.prototype.addAll = function(coll) {\n\tfor (var i = 0; i < coll.length; i++) {\n\t\tthis.add(coll[i]);\n\t}\n\treturn false;\n};\n\nATNConfigSet.prototype.equals = function(other) {\n\treturn this === other ||\n\t\t(other instanceof ATNConfigSet &&\n\t\tUtils.equalArrays(this.configs, other.configs) &&\n\t\tthis.fullCtx === other.fullCtx &&\n\t\tthis.uniqueAlt === other.uniqueAlt &&\n\t\tthis.conflictingAlts === other.conflictingAlts &&\n\t\tthis.hasSemanticContext === other.hasSemanticContext &&\n\t\tthis.dipsIntoOuterContext === other.dipsIntoOuterContext);\n};\n\nATNConfigSet.prototype.hashCode = function() {\n    var hash = new Hash();\n    this.updateHashCode(hash);\n    return hash.finish();\n};\n\n\nATNConfigSet.prototype.updateHashCode = function(hash) {\n\tif (this.readOnly) {\n\t\tif (this.cachedHashCode === -1) {\n            var hash = new Hash();\n            hash.update(this.configs);\n\t\t\tthis.cachedHashCode = hash.finish();\n\t\t}\n        hash.update(this.cachedHashCode);\n\t} else {\n        hash.update(this.configs);\n\t}\n};\n\n\nObject.defineProperty(ATNConfigSet.prototype, \"length\", {\n\tget : function() {\n\t\treturn this.configs.length;\n\t}\n});\n\nATNConfigSet.prototype.isEmpty = function() {\n\treturn this.configs.length === 0;\n};\n\nATNConfigSet.prototype.contains = function(item) {\n\tif (this.configLookup === null) {\n\t\tthrow \"This method is not implemented for readonly sets.\";\n\t}\n\treturn this.configLookup.contains(item);\n};\n\nATNConfigSet.prototype.containsFast = function(item) {\n\tif (this.configLookup === null) {\n\t\tthrow \"This method is not implemented for readonly sets.\";\n\t}\n\treturn this.configLookup.containsFast(item);\n};\n\nATNConfigSet.prototype.clear = function() {\n\tif (this.readOnly) {\n\t\tthrow \"This set is readonly\";\n\t}\n\tthis.configs = [];\n\tthis.cachedHashCode = -1;\n\tthis.configLookup = new Set();\n};\n\nATNConfigSet.prototype.setReadonly = function(readOnly) {\n\tthis.readOnly = readOnly;\n\tif (readOnly) {\n\t\tthis.configLookup = null; // can't mod, no need for lookup cache\n\t}\n};\n\nATNConfigSet.prototype.toString = function() {\n\treturn Utils.arrayToString(this.configs) +\n\t\t(this.hasSemanticContext ? \",hasSemanticContext=\" + this.hasSemanticContext : \"\") +\n\t\t(this.uniqueAlt !== ATN.INVALID_ALT_NUMBER ? \",uniqueAlt=\" + this.uniqueAlt : \"\") +\n\t\t(this.conflictingAlts !== null ? \",conflictingAlts=\" + this.conflictingAlts : \"\") +\n\t\t(this.dipsIntoOuterContext ? \",dipsIntoOuterContext\" : \"\");\n};\n\nfunction OrderedATNConfigSet() {\n\tATNConfigSet.call(this);\n\tthis.configLookup = new Set();\n\treturn this;\n}\n\nOrderedATNConfigSet.prototype = Object.create(ATNConfigSet.prototype);\nOrderedATNConfigSet.prototype.constructor = OrderedATNConfigSet;\n\nexports.ATNConfigSet = ATNConfigSet;\nexports.OrderedATNConfigSet = OrderedATNConfigSet;\n\n\n//# sourceURL=webpack:///./antlr4/atn/ATNConfigSet.js?");

/***/ }),

/***/ "./antlr4/atn/ATNDeserializationOptions.js":
/*!*************************************************!*\
  !*** ./antlr4/atn/ATNDeserializationOptions.js ***!
  \*************************************************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nfunction ATNDeserializationOptions(copyFrom) {\n\tif(copyFrom===undefined) {\n\t\tcopyFrom = null;\n\t}\n\tthis.readOnly = false;\n    this.verifyATN = copyFrom===null ? true : copyFrom.verifyATN;\n    this.generateRuleBypassTransitions = copyFrom===null ? false : copyFrom.generateRuleBypassTransitions;\n\n    return this;\n}\n\nATNDeserializationOptions.defaultOptions = new ATNDeserializationOptions();\nATNDeserializationOptions.defaultOptions.readOnly = true;\n\n//    def __setattr__(self, key, value):\n//        if key!=\"readOnly\" and self.readOnly:\n//            raise Exception(\"The object is read only.\")\n//        super(type(self), self).__setattr__(key,value)\n\nexports.ATNDeserializationOptions = ATNDeserializationOptions;\n\n\n//# sourceURL=webpack:///./antlr4/atn/ATNDeserializationOptions.js?");

/***/ }),

/***/ "./antlr4/atn/ATNDeserializer.js":
/*!***************************************!*\
  !*** ./antlr4/atn/ATNDeserializer.js ***!
  \***************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nvar Token = __webpack_require__(/*! ./../Token */ \"./antlr4/Token.js\").Token;\nvar ATN = __webpack_require__(/*! ./ATN */ \"./antlr4/atn/ATN.js\").ATN;\nvar ATNType = __webpack_require__(/*! ./ATNType */ \"./antlr4/atn/ATNType.js\").ATNType;\nvar ATNStates = __webpack_require__(/*! ./ATNState */ \"./antlr4/atn/ATNState.js\");\nvar ATNState = ATNStates.ATNState;\nvar BasicState = ATNStates.BasicState;\nvar DecisionState = ATNStates.DecisionState;\nvar BlockStartState = ATNStates.BlockStartState;\nvar BlockEndState = ATNStates.BlockEndState;\nvar LoopEndState = ATNStates.LoopEndState;\nvar RuleStartState = ATNStates.RuleStartState;\nvar RuleStopState = ATNStates.RuleStopState;\nvar TokensStartState = ATNStates.TokensStartState;\nvar PlusLoopbackState = ATNStates.PlusLoopbackState;\nvar StarLoopbackState = ATNStates.StarLoopbackState;\nvar StarLoopEntryState = ATNStates.StarLoopEntryState;\nvar PlusBlockStartState = ATNStates.PlusBlockStartState;\nvar StarBlockStartState = ATNStates.StarBlockStartState;\nvar BasicBlockStartState = ATNStates.BasicBlockStartState;\nvar Transitions = __webpack_require__(/*! ./Transition */ \"./antlr4/atn/Transition.js\");\nvar Transition = Transitions.Transition;\nvar AtomTransition = Transitions.AtomTransition;\nvar SetTransition = Transitions.SetTransition;\nvar NotSetTransition = Transitions.NotSetTransition;\nvar RuleTransition = Transitions.RuleTransition;\nvar RangeTransition = Transitions.RangeTransition;\nvar ActionTransition = Transitions.ActionTransition;\nvar EpsilonTransition = Transitions.EpsilonTransition;\nvar WildcardTransition = Transitions.WildcardTransition;\nvar PredicateTransition = Transitions.PredicateTransition;\nvar PrecedencePredicateTransition = Transitions.PrecedencePredicateTransition;\nvar IntervalSet = __webpack_require__(/*! ./../IntervalSet */ \"./antlr4/IntervalSet.js\").IntervalSet;\nvar Interval = __webpack_require__(/*! ./../IntervalSet */ \"./antlr4/IntervalSet.js\").Interval;\nvar ATNDeserializationOptions = __webpack_require__(/*! ./ATNDeserializationOptions */ \"./antlr4/atn/ATNDeserializationOptions.js\").ATNDeserializationOptions;\nvar LexerActions = __webpack_require__(/*! ./LexerAction */ \"./antlr4/atn/LexerAction.js\");\nvar LexerActionType = LexerActions.LexerActionType;\nvar LexerSkipAction = LexerActions.LexerSkipAction;\nvar LexerChannelAction = LexerActions.LexerChannelAction;\nvar LexerCustomAction = LexerActions.LexerCustomAction;\nvar LexerMoreAction = LexerActions.LexerMoreAction;\nvar LexerTypeAction = LexerActions.LexerTypeAction;\nvar LexerPushModeAction = LexerActions.LexerPushModeAction;\nvar LexerPopModeAction = LexerActions.LexerPopModeAction;\nvar LexerModeAction = LexerActions.LexerModeAction;\n// This is the earliest supported serialized UUID.\n// stick to serialized version for now, we don't need a UUID instance\nvar BASE_SERIALIZED_UUID = \"AADB8D7E-AEEF-4415-AD2B-8204D6CF042E\";\n\n//\n// This UUID indicates the serialized ATN contains two sets of\n// IntervalSets, where the second set's values are encoded as\n// 32-bit integers to support the full Unicode SMP range up to U+10FFFF.\n//\nvar ADDED_UNICODE_SMP = \"59627784-3BE5-417A-B9EB-8131A7286089\";\n\n// This list contains all of the currently supported UUIDs, ordered by when\n// the feature first appeared in this branch.\nvar SUPPORTED_UUIDS = [ BASE_SERIALIZED_UUID, ADDED_UNICODE_SMP ];\n\nvar SERIALIZED_VERSION = 3;\n\n// This is the current serialized UUID.\nvar SERIALIZED_UUID = ADDED_UNICODE_SMP;\n\nfunction initArray( length, value) {\n\tvar tmp = [];\n\ttmp[length-1] = value;\n\treturn tmp.map(function(i) {return value;});\n}\n\nfunction ATNDeserializer (options) {\n\n    if ( options=== undefined || options === null ) {\n        options = ATNDeserializationOptions.defaultOptions;\n    }\n    this.deserializationOptions = options;\n    this.stateFactories = null;\n    this.actionFactories = null;\n\n    return this;\n}\n\n// Determines if a particular serialized representation of an ATN supports\n// a particular feature, identified by the {@link UUID} used for serializing\n// the ATN at the time the feature was first introduced.\n//\n// @param feature The {@link UUID} marking the first time the feature was\n// supported in the serialized ATN.\n// @param actualUuid The {@link UUID} of the actual serialized ATN which is\n// currently being deserialized.\n// @return {@code true} if the {@code actualUuid} value represents a\n// serialized ATN at or after the feature identified by {@code feature} was\n// introduced; otherwise, {@code false}.\n\nATNDeserializer.prototype.isFeatureSupported = function(feature, actualUuid) {\n    var idx1 = SUPPORTED_UUIDS.indexOf(feature);\n    if (idx1<0) {\n        return false;\n    }\n    var idx2 = SUPPORTED_UUIDS.indexOf(actualUuid);\n    return idx2 >= idx1;\n};\n\nATNDeserializer.prototype.deserialize = function(data) {\n    this.reset(data);\n    this.checkVersion();\n    this.checkUUID();\n    var atn = this.readATN();\n    this.readStates(atn);\n    this.readRules(atn);\n    this.readModes(atn);\n    var sets = [];\n    // First, deserialize sets with 16-bit arguments <= U+FFFF.\n    this.readSets(atn, sets, this.readInt.bind(this));\n    // Next, if the ATN was serialized with the Unicode SMP feature,\n    // deserialize sets with 32-bit arguments <= U+10FFFF.\n    if (this.isFeatureSupported(ADDED_UNICODE_SMP, this.uuid)) {\n        this.readSets(atn, sets, this.readInt32.bind(this));\n    }\n    this.readEdges(atn, sets);\n    this.readDecisions(atn);\n    this.readLexerActions(atn);\n    this.markPrecedenceDecisions(atn);\n    this.verifyATN(atn);\n    if (this.deserializationOptions.generateRuleBypassTransitions && atn.grammarType === ATNType.PARSER ) {\n        this.generateRuleBypassTransitions(atn);\n        // re-verify after modification\n        this.verifyATN(atn);\n    }\n    return atn;\n};\n\nATNDeserializer.prototype.reset = function(data) {\n\tvar adjust = function(c) {\n        var v = c.charCodeAt(0);\n        return v>1  ? v-2 : v + 65533;\n\t};\n    var temp = data.split(\"\").map(adjust);\n    // don't adjust the first value since that's the version number\n    temp[0] = data.charCodeAt(0);\n    this.data = temp;\n    this.pos = 0;\n};\n\nATNDeserializer.prototype.checkVersion = function() {\n    var version = this.readInt();\n    if ( version !== SERIALIZED_VERSION ) {\n        throw (\"Could not deserialize ATN with version \" + version + \" (expected \" + SERIALIZED_VERSION + \").\");\n    }\n};\n\nATNDeserializer.prototype.checkUUID = function() {\n    var uuid = this.readUUID();\n    if (SUPPORTED_UUIDS.indexOf(uuid)<0) {\n        throw (\"Could not deserialize ATN with UUID: \" + uuid +\n                        \" (expected \" + SERIALIZED_UUID + \" or a legacy UUID).\", uuid, SERIALIZED_UUID);\n    }\n    this.uuid = uuid;\n};\n\nATNDeserializer.prototype.readATN = function() {\n    var grammarType = this.readInt();\n    var maxTokenType = this.readInt();\n    return new ATN(grammarType, maxTokenType);\n};\n\nATNDeserializer.prototype.readStates = function(atn) {\n\tvar j, pair, stateNumber;\n    var loopBackStateNumbers = [];\n    var endStateNumbers = [];\n    var nstates = this.readInt();\n    for(var i=0; i<nstates; i++) {\n        var stype = this.readInt();\n        // ignore bad type of states\n        if (stype===ATNState.INVALID_TYPE) {\n            atn.addState(null);\n            continue;\n        }\n        var ruleIndex = this.readInt();\n        if (ruleIndex === 0xFFFF) {\n            ruleIndex = -1;\n        }\n        var s = this.stateFactory(stype, ruleIndex);\n        if (stype === ATNState.LOOP_END) { // special case\n            var loopBackStateNumber = this.readInt();\n            loopBackStateNumbers.push([s, loopBackStateNumber]);\n        } else if(s instanceof BlockStartState) {\n            var endStateNumber = this.readInt();\n            endStateNumbers.push([s, endStateNumber]);\n        }\n        atn.addState(s);\n    }\n    // delay the assignment of loop back and end states until we know all the\n\t// state instances have been initialized\n    for (j=0; j<loopBackStateNumbers.length; j++) {\n        pair = loopBackStateNumbers[j];\n        pair[0].loopBackState = atn.states[pair[1]];\n    }\n\n    for (j=0; j<endStateNumbers.length; j++) {\n        pair = endStateNumbers[j];\n        pair[0].endState = atn.states[pair[1]];\n    }\n\n    var numNonGreedyStates = this.readInt();\n    for (j=0; j<numNonGreedyStates; j++) {\n        stateNumber = this.readInt();\n        atn.states[stateNumber].nonGreedy = true;\n    }\n\n    var numPrecedenceStates = this.readInt();\n    for (j=0; j<numPrecedenceStates; j++) {\n        stateNumber = this.readInt();\n        atn.states[stateNumber].isPrecedenceRule = true;\n    }\n};\n\nATNDeserializer.prototype.readRules = function(atn) {\n    var i;\n    var nrules = this.readInt();\n    if (atn.grammarType === ATNType.LEXER ) {\n        atn.ruleToTokenType = initArray(nrules, 0);\n    }\n    atn.ruleToStartState = initArray(nrules, 0);\n    for (i=0; i<nrules; i++) {\n        var s = this.readInt();\n        var startState = atn.states[s];\n        atn.ruleToStartState[i] = startState;\n        if ( atn.grammarType === ATNType.LEXER ) {\n            var tokenType = this.readInt();\n            if (tokenType === 0xFFFF) {\n                tokenType = Token.EOF;\n            }\n            atn.ruleToTokenType[i] = tokenType;\n        }\n    }\n    atn.ruleToStopState = initArray(nrules, 0);\n    for (i=0; i<atn.states.length; i++) {\n        var state = atn.states[i];\n        if (!(state instanceof RuleStopState)) {\n            continue;\n        }\n        atn.ruleToStopState[state.ruleIndex] = state;\n        atn.ruleToStartState[state.ruleIndex].stopState = state;\n    }\n};\n\nATNDeserializer.prototype.readModes = function(atn) {\n    var nmodes = this.readInt();\n    for (var i=0; i<nmodes; i++) {\n        var s = this.readInt();\n        atn.modeToStartState.push(atn.states[s]);\n    }\n};\n\nATNDeserializer.prototype.readSets = function(atn, sets, readUnicode) {\n    var m = this.readInt();\n    for (var i=0; i<m; i++) {\n        var iset = new IntervalSet();\n        sets.push(iset);\n        var n = this.readInt();\n        var containsEof = this.readInt();\n        if (containsEof!==0) {\n            iset.addOne(-1);\n        }\n        for (var j=0; j<n; j++) {\n            var i1 = readUnicode();\n            var i2 = readUnicode();\n            iset.addRange(i1, i2);\n        }\n    }\n};\n\nATNDeserializer.prototype.readEdges = function(atn, sets) {\n\tvar i, j, state, trans, target;\n    var nedges = this.readInt();\n    for (i=0; i<nedges; i++) {\n        var src = this.readInt();\n        var trg = this.readInt();\n        var ttype = this.readInt();\n        var arg1 = this.readInt();\n        var arg2 = this.readInt();\n        var arg3 = this.readInt();\n        trans = this.edgeFactory(atn, ttype, src, trg, arg1, arg2, arg3, sets);\n        var srcState = atn.states[src];\n        srcState.addTransition(trans);\n    }\n    // edges for rule stop states can be derived, so they aren't serialized\n    for (i=0; i<atn.states.length; i++) {\n        state = atn.states[i];\n        for (j=0; j<state.transitions.length; j++) {\n            var t = state.transitions[j];\n            if (!(t instanceof RuleTransition)) {\n                continue;\n            }\n\t\t\tvar outermostPrecedenceReturn = -1;\n\t\t\tif (atn.ruleToStartState[t.target.ruleIndex].isPrecedenceRule) {\n\t\t\t\tif (t.precedence === 0) {\n\t\t\t\t\toutermostPrecedenceReturn = t.target.ruleIndex;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\ttrans = new EpsilonTransition(t.followState, outermostPrecedenceReturn);\n            atn.ruleToStopState[t.target.ruleIndex].addTransition(trans);\n        }\n    }\n\n    for (i=0; i<atn.states.length; i++) {\n        state = atn.states[i];\n        if (state instanceof BlockStartState) {\n            // we need to know the end state to set its start state\n            if (state.endState === null) {\n                throw (\"IllegalState\");\n            }\n            // block end states can only be associated to a single block start\n\t\t\t// state\n            if ( state.endState.startState !== null) {\n                throw (\"IllegalState\");\n            }\n            state.endState.startState = state;\n        }\n        if (state instanceof PlusLoopbackState) {\n            for (j=0; j<state.transitions.length; j++) {\n                target = state.transitions[j].target;\n                if (target instanceof PlusBlockStartState) {\n                    target.loopBackState = state;\n                }\n            }\n        } else if (state instanceof StarLoopbackState) {\n            for (j=0; j<state.transitions.length; j++) {\n                target = state.transitions[j].target;\n                if (target instanceof StarLoopEntryState) {\n                    target.loopBackState = state;\n                }\n            }\n        }\n    }\n};\n\nATNDeserializer.prototype.readDecisions = function(atn) {\n    var ndecisions = this.readInt();\n    for (var i=0; i<ndecisions; i++) {\n        var s = this.readInt();\n        var decState = atn.states[s];\n        atn.decisionToState.push(decState);\n        decState.decision = i;\n    }\n};\n\nATNDeserializer.prototype.readLexerActions = function(atn) {\n    if (atn.grammarType === ATNType.LEXER) {\n        var count = this.readInt();\n        atn.lexerActions = initArray(count, null);\n        for (var i=0; i<count; i++) {\n            var actionType = this.readInt();\n            var data1 = this.readInt();\n            if (data1 === 0xFFFF) {\n                data1 = -1;\n            }\n            var data2 = this.readInt();\n            if (data2 === 0xFFFF) {\n                data2 = -1;\n            }\n            var lexerAction = this.lexerActionFactory(actionType, data1, data2);\n            atn.lexerActions[i] = lexerAction;\n        }\n    }\n};\n\nATNDeserializer.prototype.generateRuleBypassTransitions = function(atn) {\n\tvar i;\n    var count = atn.ruleToStartState.length;\n    for(i=0; i<count; i++) {\n        atn.ruleToTokenType[i] = atn.maxTokenType + i + 1;\n    }\n    for(i=0; i<count; i++) {\n        this.generateRuleBypassTransition(atn, i);\n    }\n};\n\nATNDeserializer.prototype.generateRuleBypassTransition = function(atn, idx) {\n\tvar i, state;\n    var bypassStart = new BasicBlockStartState();\n    bypassStart.ruleIndex = idx;\n    atn.addState(bypassStart);\n\n    var bypassStop = new BlockEndState();\n    bypassStop.ruleIndex = idx;\n    atn.addState(bypassStop);\n\n    bypassStart.endState = bypassStop;\n    atn.defineDecisionState(bypassStart);\n\n    bypassStop.startState = bypassStart;\n\n    var excludeTransition = null;\n    var endState = null;\n\n    if (atn.ruleToStartState[idx].isPrecedenceRule) {\n        // wrap from the beginning of the rule to the StarLoopEntryState\n        endState = null;\n        for(i=0; i<atn.states.length; i++) {\n            state = atn.states[i];\n            if (this.stateIsEndStateFor(state, idx)) {\n                endState = state;\n                excludeTransition = state.loopBackState.transitions[0];\n                break;\n            }\n        }\n        if (excludeTransition === null) {\n            throw (\"Couldn't identify final state of the precedence rule prefix section.\");\n        }\n    } else {\n        endState = atn.ruleToStopState[idx];\n    }\n\n    // all non-excluded transitions that currently target end state need to\n\t// target blockEnd instead\n    for(i=0; i<atn.states.length; i++) {\n        state = atn.states[i];\n        for(var j=0; j<state.transitions.length; j++) {\n            var transition = state.transitions[j];\n            if (transition === excludeTransition) {\n                continue;\n            }\n            if (transition.target === endState) {\n                transition.target = bypassStop;\n            }\n        }\n    }\n\n    // all transitions leaving the rule start state need to leave blockStart\n\t// instead\n    var ruleToStartState = atn.ruleToStartState[idx];\n    var count = ruleToStartState.transitions.length;\n    while ( count > 0) {\n        bypassStart.addTransition(ruleToStartState.transitions[count-1]);\n        ruleToStartState.transitions = ruleToStartState.transitions.slice(-1);\n    }\n    // link the new states\n    atn.ruleToStartState[idx].addTransition(new EpsilonTransition(bypassStart));\n    bypassStop.addTransition(new EpsilonTransition(endState));\n\n    var matchState = new BasicState();\n    atn.addState(matchState);\n    matchState.addTransition(new AtomTransition(bypassStop, atn.ruleToTokenType[idx]));\n    bypassStart.addTransition(new EpsilonTransition(matchState));\n};\n\nATNDeserializer.prototype.stateIsEndStateFor = function(state, idx) {\n    if ( state.ruleIndex !== idx) {\n        return null;\n    }\n    if (!( state instanceof StarLoopEntryState)) {\n        return null;\n    }\n    var maybeLoopEndState = state.transitions[state.transitions.length - 1].target;\n    if (!( maybeLoopEndState instanceof LoopEndState)) {\n        return null;\n    }\n    if (maybeLoopEndState.epsilonOnlyTransitions &&\n        (maybeLoopEndState.transitions[0].target instanceof RuleStopState)) {\n        return state;\n    } else {\n        return null;\n    }\n};\n\n//\n// Analyze the {@link StarLoopEntryState} states in the specified ATN to set\n// the {@link StarLoopEntryState//isPrecedenceDecision} field to the\n// correct value.\n//\n// @param atn The ATN.\n//\nATNDeserializer.prototype.markPrecedenceDecisions = function(atn) {\n\tfor(var i=0; i<atn.states.length; i++) {\n\t\tvar state = atn.states[i];\n\t\tif (!( state instanceof StarLoopEntryState)) {\n            continue;\n        }\n        // We analyze the ATN to determine if this ATN decision state is the\n        // decision for the closure block that determines whether a\n        // precedence rule should continue or complete.\n        //\n        if ( atn.ruleToStartState[state.ruleIndex].isPrecedenceRule) {\n            var maybeLoopEndState = state.transitions[state.transitions.length - 1].target;\n            if (maybeLoopEndState instanceof LoopEndState) {\n                if ( maybeLoopEndState.epsilonOnlyTransitions &&\n                        (maybeLoopEndState.transitions[0].target instanceof RuleStopState)) {\n                    state.isPrecedenceDecision = true;\n                }\n            }\n        }\n\t}\n};\n\nATNDeserializer.prototype.verifyATN = function(atn) {\n    if (!this.deserializationOptions.verifyATN) {\n        return;\n    }\n    // verify assumptions\n\tfor(var i=0; i<atn.states.length; i++) {\n        var state = atn.states[i];\n        if (state === null) {\n            continue;\n        }\n        this.checkCondition(state.epsilonOnlyTransitions || state.transitions.length <= 1);\n        if (state instanceof PlusBlockStartState) {\n            this.checkCondition(state.loopBackState !== null);\n        } else  if (state instanceof StarLoopEntryState) {\n            this.checkCondition(state.loopBackState !== null);\n            this.checkCondition(state.transitions.length === 2);\n            if (state.transitions[0].target instanceof StarBlockStartState) {\n                this.checkCondition(state.transitions[1].target instanceof LoopEndState);\n                this.checkCondition(!state.nonGreedy);\n            } else if (state.transitions[0].target instanceof LoopEndState) {\n                this.checkCondition(state.transitions[1].target instanceof StarBlockStartState);\n                this.checkCondition(state.nonGreedy);\n            } else {\n                throw(\"IllegalState\");\n            }\n        } else if (state instanceof StarLoopbackState) {\n            this.checkCondition(state.transitions.length === 1);\n            this.checkCondition(state.transitions[0].target instanceof StarLoopEntryState);\n        } else if (state instanceof LoopEndState) {\n            this.checkCondition(state.loopBackState !== null);\n        } else if (state instanceof RuleStartState) {\n            this.checkCondition(state.stopState !== null);\n        } else if (state instanceof BlockStartState) {\n            this.checkCondition(state.endState !== null);\n        } else if (state instanceof BlockEndState) {\n            this.checkCondition(state.startState !== null);\n        } else if (state instanceof DecisionState) {\n            this.checkCondition(state.transitions.length <= 1 || state.decision >= 0);\n        } else {\n            this.checkCondition(state.transitions.length <= 1 || (state instanceof RuleStopState));\n        }\n\t}\n};\n\nATNDeserializer.prototype.checkCondition = function(condition, message) {\n    if (!condition) {\n        if (message === undefined || message===null) {\n            message = \"IllegalState\";\n        }\n        throw (message);\n    }\n};\n\nATNDeserializer.prototype.readInt = function() {\n    return this.data[this.pos++];\n};\n\nATNDeserializer.prototype.readInt32 = function() {\n    var low = this.readInt();\n    var high = this.readInt();\n    return low | (high << 16);\n};\n\nATNDeserializer.prototype.readLong = function() {\n    var low = this.readInt32();\n    var high = this.readInt32();\n    return (low & 0x00000000FFFFFFFF) | (high << 32);\n};\n\nfunction createByteToHex() {\n\tvar bth = [];\n\tfor (var i = 0; i < 256; i++) {\n\t\tbth[i] = (i + 0x100).toString(16).substr(1).toUpperCase();\n\t}\n\treturn bth;\n}\n\nvar byteToHex = createByteToHex();\n\nATNDeserializer.prototype.readUUID = function() {\n\tvar bb = [];\n\tfor(var i=7;i>=0;i--) {\n\t\tvar int = this.readInt();\n\t\t/* jshint bitwise: false */\n\t\tbb[(2*i)+1] = int & 0xFF;\n\t\tbb[2*i] = (int >> 8) & 0xFF;\n\t}\n    return byteToHex[bb[0]] + byteToHex[bb[1]] +\n    byteToHex[bb[2]] + byteToHex[bb[3]] + '-' +\n    byteToHex[bb[4]] + byteToHex[bb[5]] + '-' +\n    byteToHex[bb[6]] + byteToHex[bb[7]] + '-' +\n    byteToHex[bb[8]] + byteToHex[bb[9]] + '-' +\n    byteToHex[bb[10]] + byteToHex[bb[11]] +\n    byteToHex[bb[12]] + byteToHex[bb[13]] +\n    byteToHex[bb[14]] + byteToHex[bb[15]];\n};\n\nATNDeserializer.prototype.edgeFactory = function(atn, type, src, trg, arg1, arg2, arg3, sets) {\n    var target = atn.states[trg];\n    switch(type) {\n    case Transition.EPSILON:\n        return new EpsilonTransition(target);\n    case Transition.RANGE:\n        return arg3 !== 0 ? new RangeTransition(target, Token.EOF, arg2) : new RangeTransition(target, arg1, arg2);\n    case Transition.RULE:\n        return new RuleTransition(atn.states[arg1], arg2, arg3, target);\n    case Transition.PREDICATE:\n        return new PredicateTransition(target, arg1, arg2, arg3 !== 0);\n    case Transition.PRECEDENCE:\n        return new PrecedencePredicateTransition(target, arg1);\n    case Transition.ATOM:\n        return arg3 !== 0 ? new AtomTransition(target, Token.EOF) : new AtomTransition(target, arg1);\n    case Transition.ACTION:\n        return new ActionTransition(target, arg1, arg2, arg3 !== 0);\n    case Transition.SET:\n        return new SetTransition(target, sets[arg1]);\n    case Transition.NOT_SET:\n        return new NotSetTransition(target, sets[arg1]);\n    case Transition.WILDCARD:\n        return new WildcardTransition(target);\n    default:\n        throw \"The specified transition type: \" + type + \" is not valid.\";\n    }\n};\n\nATNDeserializer.prototype.stateFactory = function(type, ruleIndex) {\n    if (this.stateFactories === null) {\n        var sf = [];\n        sf[ATNState.INVALID_TYPE] = null;\n        sf[ATNState.BASIC] = function() { return new BasicState(); };\n        sf[ATNState.RULE_START] = function() { return new RuleStartState(); };\n        sf[ATNState.BLOCK_START] = function() { return new BasicBlockStartState(); };\n        sf[ATNState.PLUS_BLOCK_START] = function() { return new PlusBlockStartState(); };\n        sf[ATNState.STAR_BLOCK_START] = function() { return new StarBlockStartState(); };\n        sf[ATNState.TOKEN_START] = function() { return new TokensStartState(); };\n        sf[ATNState.RULE_STOP] = function() { return new RuleStopState(); };\n        sf[ATNState.BLOCK_END] = function() { return new BlockEndState(); };\n        sf[ATNState.STAR_LOOP_BACK] = function() { return new StarLoopbackState(); };\n        sf[ATNState.STAR_LOOP_ENTRY] = function() { return new StarLoopEntryState(); };\n        sf[ATNState.PLUS_LOOP_BACK] = function() { return new PlusLoopbackState(); };\n        sf[ATNState.LOOP_END] = function() { return new LoopEndState(); };\n        this.stateFactories = sf;\n    }\n    if (type>this.stateFactories.length || this.stateFactories[type] === null) {\n        throw(\"The specified state type \" + type + \" is not valid.\");\n    } else {\n        var s = this.stateFactories[type]();\n        if (s!==null) {\n            s.ruleIndex = ruleIndex;\n            return s;\n        }\n    }\n};\n\nATNDeserializer.prototype.lexerActionFactory = function(type, data1, data2) {\n    if (this.actionFactories === null) {\n        var af = [];\n        af[LexerActionType.CHANNEL] = function(data1, data2) { return new LexerChannelAction(data1); };\n        af[LexerActionType.CUSTOM] = function(data1, data2) { return new LexerCustomAction(data1, data2); };\n        af[LexerActionType.MODE] = function(data1, data2) { return new LexerModeAction(data1); };\n        af[LexerActionType.MORE] = function(data1, data2) { return LexerMoreAction.INSTANCE; };\n        af[LexerActionType.POP_MODE] = function(data1, data2) { return LexerPopModeAction.INSTANCE; };\n        af[LexerActionType.PUSH_MODE] = function(data1, data2) { return new LexerPushModeAction(data1); };\n        af[LexerActionType.SKIP] = function(data1, data2) { return LexerSkipAction.INSTANCE; };\n        af[LexerActionType.TYPE] = function(data1, data2) { return new LexerTypeAction(data1); };\n        this.actionFactories = af;\n    }\n    if (type>this.actionFactories.length || this.actionFactories[type] === null) {\n        throw(\"The specified lexer action type \" + type + \" is not valid.\");\n    } else {\n        return this.actionFactories[type](data1, data2);\n    }\n};\n\n\nexports.ATNDeserializer = ATNDeserializer;\n\n//# sourceURL=webpack:///./antlr4/atn/ATNDeserializer.js?");

/***/ }),

/***/ "./antlr4/atn/ATNSimulator.js":
/*!************************************!*\
  !*** ./antlr4/atn/ATNSimulator.js ***!
  \************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("//\n/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n///\n\nvar DFAState = __webpack_require__(/*! ./../dfa/DFAState */ \"./antlr4/dfa/DFAState.js\").DFAState;\nvar ATNConfigSet = __webpack_require__(/*! ./ATNConfigSet */ \"./antlr4/atn/ATNConfigSet.js\").ATNConfigSet;\nvar getCachedPredictionContext = __webpack_require__(/*! ./../PredictionContext */ \"./antlr4/PredictionContext.js\").getCachedPredictionContext;\n\nfunction ATNSimulator(atn, sharedContextCache) {\n\n    // The context cache maps all PredictionContext objects that are ==\n    //  to a single cached copy. This cache is shared across all contexts\n    //  in all ATNConfigs in all DFA states.  We rebuild each ATNConfigSet\n    //  to use only cached nodes/graphs in addDFAState(). We don't want to\n    //  fill this during closure() since there are lots of contexts that\n    //  pop up but are not used ever again. It also greatly slows down closure().\n    //\n    //  <p>This cache makes a huge difference in memory and a little bit in speed.\n    //  For the Java grammar on java.*, it dropped the memory requirements\n    //  at the end from 25M to 16M. We don't store any of the full context\n    //  graphs in the DFA because they are limited to local context only,\n    //  but apparently there's a lot of repetition there as well. We optimize\n    //  the config contexts before storing the config set in the DFA states\n    //  by literally rebuilding them with cached subgraphs only.</p>\n    //\n    //  <p>I tried a cache for use during closure operations, that was\n    //  whacked after each adaptivePredict(). It cost a little bit\n    //  more time I think and doesn't save on the overall footprint\n    //  so it's not worth the complexity.</p>\n    ///\n    this.atn = atn;\n    this.sharedContextCache = sharedContextCache;\n    return this;\n}\n\n// Must distinguish between missing edge and edge we know leads nowhere///\nATNSimulator.ERROR = new DFAState(0x7FFFFFFF, new ATNConfigSet());\n\n\nATNSimulator.prototype.getCachedContext = function(context) {\n    if (this.sharedContextCache ===null) {\n        return context;\n    }\n    var visited = {};\n    return getCachedPredictionContext(context, this.sharedContextCache, visited);\n};\n\nexports.ATNSimulator = ATNSimulator;\n\n\n//# sourceURL=webpack:///./antlr4/atn/ATNSimulator.js?");

/***/ }),

/***/ "./antlr4/atn/ATNState.js":
/*!********************************!*\
  !*** ./antlr4/atn/ATNState.js ***!
  \********************************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("//\n/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n//\n\n// The following images show the relation of states and\n// {@link ATNState//transitions} for various grammar constructs.\n//\n// <ul>\n//\n// <li>Solid edges marked with an &//0949; indicate a required\n// {@link EpsilonTransition}.</li>\n//\n// <li>Dashed edges indicate locations where any transition derived from\n// {@link Transition} might appear.</li>\n//\n// <li>Dashed nodes are place holders for either a sequence of linked\n// {@link BasicState} states or the inclusion of a block representing a nested\n// construct in one of the forms below.</li>\n//\n// <li>Nodes showing multiple outgoing alternatives with a {@code ...} support\n// any number of alternatives (one or more). Nodes without the {@code ...} only\n// support the exact number of alternatives shown in the diagram.</li>\n//\n// </ul>\n//\n// <h2>Basic Blocks</h2>\n//\n// <h3>Rule</h3>\n//\n// <embed src=\"images/Rule.svg\" type=\"image/svg+xml\"/>\n//\n// <h3>Block of 1 or more alternatives</h3>\n//\n// <embed src=\"images/Block.svg\" type=\"image/svg+xml\"/>\n//\n// <h2>Greedy Loops</h2>\n//\n// <h3>Greedy Closure: {@code (...)*}</h3>\n//\n// <embed src=\"images/ClosureGreedy.svg\" type=\"image/svg+xml\"/>\n//\n// <h3>Greedy Positive Closure: {@code (...)+}</h3>\n//\n// <embed src=\"images/PositiveClosureGreedy.svg\" type=\"image/svg+xml\"/>\n//\n// <h3>Greedy Optional: {@code (...)?}</h3>\n//\n// <embed src=\"images/OptionalGreedy.svg\" type=\"image/svg+xml\"/>\n//\n// <h2>Non-Greedy Loops</h2>\n//\n// <h3>Non-Greedy Closure: {@code (...)*?}</h3>\n//\n// <embed src=\"images/ClosureNonGreedy.svg\" type=\"image/svg+xml\"/>\n//\n// <h3>Non-Greedy Positive Closure: {@code (...)+?}</h3>\n//\n// <embed src=\"images/PositiveClosureNonGreedy.svg\" type=\"image/svg+xml\"/>\n//\n// <h3>Non-Greedy Optional: {@code (...)??}</h3>\n//\n// <embed src=\"images/OptionalNonGreedy.svg\" type=\"image/svg+xml\"/>\n//\n\nvar INITIAL_NUM_TRANSITIONS = 4;\n\nfunction ATNState() {\n    // Which ATN are we in?\n    this.atn = null;\n    this.stateNumber = ATNState.INVALID_STATE_NUMBER;\n    this.stateType = null;\n    this.ruleIndex = 0; // at runtime, we don't have Rule objects\n    this.epsilonOnlyTransitions = false;\n    // Track the transitions emanating from this ATN state.\n    this.transitions = [];\n    // Used to cache lookahead during parsing, not used during construction\n    this.nextTokenWithinRule = null;\n    return this;\n}\n\n// constants for serialization\nATNState.INVALID_TYPE = 0;\nATNState.BASIC = 1;\nATNState.RULE_START = 2;\nATNState.BLOCK_START = 3;\nATNState.PLUS_BLOCK_START = 4;\nATNState.STAR_BLOCK_START = 5;\nATNState.TOKEN_START = 6;\nATNState.RULE_STOP = 7;\nATNState.BLOCK_END = 8;\nATNState.STAR_LOOP_BACK = 9;\nATNState.STAR_LOOP_ENTRY = 10;\nATNState.PLUS_LOOP_BACK = 11;\nATNState.LOOP_END = 12;\n\nATNState.serializationNames = [\n            \"INVALID\",\n            \"BASIC\",\n            \"RULE_START\",\n            \"BLOCK_START\",\n            \"PLUS_BLOCK_START\",\n            \"STAR_BLOCK_START\",\n            \"TOKEN_START\",\n            \"RULE_STOP\",\n            \"BLOCK_END\",\n            \"STAR_LOOP_BACK\",\n            \"STAR_LOOP_ENTRY\",\n            \"PLUS_LOOP_BACK\",\n            \"LOOP_END\" ];\n\nATNState.INVALID_STATE_NUMBER = -1;\n\nATNState.prototype.toString = function() {\n\treturn this.stateNumber;\n};\n\nATNState.prototype.equals = function(other) {\n    if (other instanceof ATNState) {\n        return this.stateNumber===other.stateNumber;\n    } else {\n        return false;\n    }\n};\n\nATNState.prototype.isNonGreedyExitState = function() {\n    return false;\n};\n\n\nATNState.prototype.addTransition = function(trans, index) {\n\tif(index===undefined) {\n\t\tindex = -1;\n\t}\n    if (this.transitions.length===0) {\n        this.epsilonOnlyTransitions = trans.isEpsilon;\n    } else if(this.epsilonOnlyTransitions !== trans.isEpsilon) {\n        this.epsilonOnlyTransitions = false;\n    }\n    if (index===-1) {\n        this.transitions.push(trans);\n    } else {\n        this.transitions.splice(index, 1, trans);\n    }\n};\n\nfunction BasicState() {\n\tATNState.call(this);\n    this.stateType = ATNState.BASIC;\n    return this;\n}\n\nBasicState.prototype = Object.create(ATNState.prototype);\nBasicState.prototype.constructor = BasicState;\n\n\nfunction DecisionState() {\n\tATNState.call(this);\n    this.decision = -1;\n    this.nonGreedy = false;\n    return this;\n}\n\nDecisionState.prototype = Object.create(ATNState.prototype);\nDecisionState.prototype.constructor = DecisionState;\n\n\n//  The start of a regular {@code (...)} block.\nfunction BlockStartState() {\n\tDecisionState.call(this);\n\tthis.endState = null;\n\treturn this;\n}\n\nBlockStartState.prototype = Object.create(DecisionState.prototype);\nBlockStartState.prototype.constructor = BlockStartState;\n\n\nfunction BasicBlockStartState() {\n\tBlockStartState.call(this);\n\tthis.stateType = ATNState.BLOCK_START;\n\treturn this;\n}\n\nBasicBlockStartState.prototype = Object.create(BlockStartState.prototype);\nBasicBlockStartState.prototype.constructor = BasicBlockStartState;\n\n\n// Terminal node of a simple {@code (a|b|c)} block.\nfunction BlockEndState() {\n\tATNState.call(this);\n\tthis.stateType = ATNState.BLOCK_END;\n    this.startState = null;\n    return this;\n}\n\nBlockEndState.prototype = Object.create(ATNState.prototype);\nBlockEndState.prototype.constructor = BlockEndState;\n\n\n// The last node in the ATN for a rule, unless that rule is the start symbol.\n//  In that case, there is one transition to EOF. Later, we might encode\n//  references to all calls to this rule to compute FOLLOW sets for\n//  error handling.\n//\nfunction RuleStopState() {\n\tATNState.call(this);\n    this.stateType = ATNState.RULE_STOP;\n    return this;\n}\n\nRuleStopState.prototype = Object.create(ATNState.prototype);\nRuleStopState.prototype.constructor = RuleStopState;\n\nfunction RuleStartState() {\n\tATNState.call(this);\n\tthis.stateType = ATNState.RULE_START;\n\tthis.stopState = null;\n\tthis.isPrecedenceRule = false;\n\treturn this;\n}\n\nRuleStartState.prototype = Object.create(ATNState.prototype);\nRuleStartState.prototype.constructor = RuleStartState;\n\n// Decision state for {@code A+} and {@code (A|B)+}.  It has two transitions:\n//  one to the loop back to start of the block and one to exit.\n//\nfunction PlusLoopbackState() {\n\tDecisionState.call(this);\n\tthis.stateType = ATNState.PLUS_LOOP_BACK;\n\treturn this;\n}\n\nPlusLoopbackState.prototype = Object.create(DecisionState.prototype);\nPlusLoopbackState.prototype.constructor = PlusLoopbackState;\n\n\n// Start of {@code (A|B|...)+} loop. Technically a decision state, but\n//  we don't use for code generation; somebody might need it, so I'm defining\n//  it for completeness. In reality, the {@link PlusLoopbackState} node is the\n//  real decision-making note for {@code A+}.\n//\nfunction PlusBlockStartState() {\n\tBlockStartState.call(this);\n\tthis.stateType = ATNState.PLUS_BLOCK_START;\n    this.loopBackState = null;\n    return this;\n}\n\nPlusBlockStartState.prototype = Object.create(BlockStartState.prototype);\nPlusBlockStartState.prototype.constructor = PlusBlockStartState;\n\n// The block that begins a closure loop.\nfunction StarBlockStartState() {\n\tBlockStartState.call(this);\n\tthis.stateType = ATNState.STAR_BLOCK_START;\n\treturn this;\n}\n\nStarBlockStartState.prototype = Object.create(BlockStartState.prototype);\nStarBlockStartState.prototype.constructor = StarBlockStartState;\n\n\nfunction StarLoopbackState() {\n\tATNState.call(this);\n\tthis.stateType = ATNState.STAR_LOOP_BACK;\n\treturn this;\n}\n\nStarLoopbackState.prototype = Object.create(ATNState.prototype);\nStarLoopbackState.prototype.constructor = StarLoopbackState;\n\n\nfunction StarLoopEntryState() {\n\tDecisionState.call(this);\n\tthis.stateType = ATNState.STAR_LOOP_ENTRY;\n    this.loopBackState = null;\n    // Indicates whether this state can benefit from a precedence DFA during SLL decision making.\n    this.isPrecedenceDecision = null;\n    return this;\n}\n\nStarLoopEntryState.prototype = Object.create(DecisionState.prototype);\nStarLoopEntryState.prototype.constructor = StarLoopEntryState;\n\n\n// Mark the end of a * or + loop.\nfunction LoopEndState() {\n\tATNState.call(this);\n\tthis.stateType = ATNState.LOOP_END;\n\tthis.loopBackState = null;\n\treturn this;\n}\n\nLoopEndState.prototype = Object.create(ATNState.prototype);\nLoopEndState.prototype.constructor = LoopEndState;\n\n\n// The Tokens rule start state linking to each lexer rule start state */\nfunction TokensStartState() {\n\tDecisionState.call(this);\n\tthis.stateType = ATNState.TOKEN_START;\n\treturn this;\n}\n\nTokensStartState.prototype = Object.create(DecisionState.prototype);\nTokensStartState.prototype.constructor = TokensStartState;\n\nexports.ATNState = ATNState;\nexports.BasicState = BasicState;\nexports.DecisionState = DecisionState;\nexports.BlockStartState = BlockStartState;\nexports.BlockEndState = BlockEndState;\nexports.LoopEndState = LoopEndState;\nexports.RuleStartState = RuleStartState;\nexports.RuleStopState = RuleStopState;\nexports.TokensStartState = TokensStartState;\nexports.PlusLoopbackState = PlusLoopbackState;\nexports.StarLoopbackState = StarLoopbackState;\nexports.StarLoopEntryState = StarLoopEntryState;\nexports.PlusBlockStartState = PlusBlockStartState;\nexports.StarBlockStartState = StarBlockStartState;\nexports.BasicBlockStartState = BasicBlockStartState;\n\n\n//# sourceURL=webpack:///./antlr4/atn/ATNState.js?");

/***/ }),

/***/ "./antlr4/atn/ATNType.js":
/*!*******************************!*\
  !*** ./antlr4/atn/ATNType.js ***!
  \*******************************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n///\n\n// Represents the type of recognizer an ATN applies to.\n\nfunction ATNType() {\n\n}\n\nATNType.LEXER = 0;\nATNType.PARSER = 1;\n\nexports.ATNType = ATNType;\n\n\n\n//# sourceURL=webpack:///./antlr4/atn/ATNType.js?");

/***/ }),

/***/ "./antlr4/atn/LexerATNSimulator.js":
/*!*****************************************!*\
  !*** ./antlr4/atn/LexerATNSimulator.js ***!
  \*****************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("//\n/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n///\n\n// When we hit an accept state in either the DFA or the ATN, we\n//  have to notify the character stream to start buffering characters\n//  via {@link IntStream//mark} and record the current state. The current sim state\n//  includes the current index into the input, the current line,\n//  and current character position in that line. Note that the Lexer is\n//  tracking the starting line and characterization of the token. These\n//  variables track the \"state\" of the simulator when it hits an accept state.\n//\n//  <p>We track these variables separately for the DFA and ATN simulation\n//  because the DFA simulation often has to fail over to the ATN\n//  simulation. If the ATN simulation fails, we need the DFA to fall\n//  back to its previously accepted state, if any. If the ATN succeeds,\n//  then the ATN does the accept and the DFA simulator that invoked it\n//  can simply return the predicted token type.</p>\n///\n\nvar Token = __webpack_require__(/*! ./../Token */ \"./antlr4/Token.js\").Token;\nvar Lexer = __webpack_require__(/*! ./../Lexer */ \"./antlr4/Lexer.js\").Lexer;\nvar ATN = __webpack_require__(/*! ./ATN */ \"./antlr4/atn/ATN.js\").ATN;\nvar ATNSimulator = __webpack_require__(/*! ./ATNSimulator */ \"./antlr4/atn/ATNSimulator.js\").ATNSimulator;\nvar DFAState = __webpack_require__(/*! ./../dfa/DFAState */ \"./antlr4/dfa/DFAState.js\").DFAState;\nvar ATNConfigSet = __webpack_require__(/*! ./ATNConfigSet */ \"./antlr4/atn/ATNConfigSet.js\").ATNConfigSet;\nvar OrderedATNConfigSet = __webpack_require__(/*! ./ATNConfigSet */ \"./antlr4/atn/ATNConfigSet.js\").OrderedATNConfigSet;\nvar PredictionContext = __webpack_require__(/*! ./../PredictionContext */ \"./antlr4/PredictionContext.js\").PredictionContext;\nvar SingletonPredictionContext = __webpack_require__(/*! ./../PredictionContext */ \"./antlr4/PredictionContext.js\").SingletonPredictionContext;\nvar RuleStopState = __webpack_require__(/*! ./ATNState */ \"./antlr4/atn/ATNState.js\").RuleStopState;\nvar LexerATNConfig = __webpack_require__(/*! ./ATNConfig */ \"./antlr4/atn/ATNConfig.js\").LexerATNConfig;\nvar Transition = __webpack_require__(/*! ./Transition */ \"./antlr4/atn/Transition.js\").Transition;\nvar LexerActionExecutor = __webpack_require__(/*! ./LexerActionExecutor */ \"./antlr4/atn/LexerActionExecutor.js\").LexerActionExecutor;\nvar LexerNoViableAltException = __webpack_require__(/*! ./../error/Errors */ \"./antlr4/error/Errors.js\").LexerNoViableAltException;\n\nfunction resetSimState(sim) {\n\tsim.index = -1;\n\tsim.line = 0;\n\tsim.column = -1;\n\tsim.dfaState = null;\n}\n\nfunction SimState() {\n\tresetSimState(this);\n\treturn this;\n}\n\nSimState.prototype.reset = function() {\n\tresetSimState(this);\n};\n\nfunction LexerATNSimulator(recog, atn, decisionToDFA, sharedContextCache) {\n\tATNSimulator.call(this, atn, sharedContextCache);\n\tthis.decisionToDFA = decisionToDFA;\n\tthis.recog = recog;\n\t// The current token's starting index into the character stream.\n\t// Shared across DFA to ATN simulation in case the ATN fails and the\n\t// DFA did not have a previous accept state. In this case, we use the\n\t// ATN-generated exception object.\n\tthis.startIndex = -1;\n\t// line number 1..n within the input///\n\tthis.line = 1;\n\t// The index of the character relative to the beginning of the line\n\t// 0..n-1///\n\tthis.column = 0;\n\tthis.mode = Lexer.DEFAULT_MODE;\n\t// Used during DFA/ATN exec to record the most recent accept configuration\n\t// info\n\tthis.prevAccept = new SimState();\n\t// done\n\treturn this;\n}\n\nLexerATNSimulator.prototype = Object.create(ATNSimulator.prototype);\nLexerATNSimulator.prototype.constructor = LexerATNSimulator;\n\nLexerATNSimulator.debug = false;\nLexerATNSimulator.dfa_debug = false;\n\nLexerATNSimulator.MIN_DFA_EDGE = 0;\nLexerATNSimulator.MAX_DFA_EDGE = 127; // forces unicode to stay in ATN\n\nLexerATNSimulator.match_calls = 0;\n\nLexerATNSimulator.prototype.copyState = function(simulator) {\n\tthis.column = simulator.column;\n\tthis.line = simulator.line;\n\tthis.mode = simulator.mode;\n\tthis.startIndex = simulator.startIndex;\n};\n\nLexerATNSimulator.prototype.match = function(input, mode) {\n\tthis.match_calls += 1;\n\tthis.mode = mode;\n\tvar mark = input.mark();\n\ttry {\n\t\tthis.startIndex = input.index;\n\t\tthis.prevAccept.reset();\n\t\tvar dfa = this.decisionToDFA[mode];\n\t\tif (dfa.s0 === null) {\n\t\t\treturn this.matchATN(input);\n\t\t} else {\n\t\t\treturn this.execATN(input, dfa.s0);\n\t\t}\n\t} finally {\n\t\tinput.release(mark);\n\t}\n};\n\nLexerATNSimulator.prototype.reset = function() {\n\tthis.prevAccept.reset();\n\tthis.startIndex = -1;\n\tthis.line = 1;\n\tthis.column = 0;\n\tthis.mode = Lexer.DEFAULT_MODE;\n};\n\nLexerATNSimulator.prototype.matchATN = function(input) {\n\tvar startState = this.atn.modeToStartState[this.mode];\n\n\tif (LexerATNSimulator.debug) {\n\t\tconsole.log(\"matchATN mode \" + this.mode + \" start: \" + startState);\n\t}\n\tvar old_mode = this.mode;\n\tvar s0_closure = this.computeStartState(input, startState);\n\tvar suppressEdge = s0_closure.hasSemanticContext;\n\ts0_closure.hasSemanticContext = false;\n\n\tvar next = this.addDFAState(s0_closure);\n\tif (!suppressEdge) {\n\t\tthis.decisionToDFA[this.mode].s0 = next;\n\t}\n\n\tvar predict = this.execATN(input, next);\n\n\tif (LexerATNSimulator.debug) {\n\t\tconsole.log(\"DFA after matchATN: \" + this.decisionToDFA[old_mode].toLexerString());\n\t}\n\treturn predict;\n};\n\nLexerATNSimulator.prototype.execATN = function(input, ds0) {\n\tif (LexerATNSimulator.debug) {\n\t\tconsole.log(\"start state closure=\" + ds0.configs);\n\t}\n\tif (ds0.isAcceptState) {\n\t\t// allow zero-length tokens\n\t\tthis.captureSimState(this.prevAccept, input, ds0);\n\t}\n\tvar t = input.LA(1);\n\tvar s = ds0; // s is current/from DFA state\n\n\twhile (true) { // while more work\n\t\tif (LexerATNSimulator.debug) {\n\t\t\tconsole.log(\"execATN loop starting closure: \" + s.configs);\n\t\t}\n\n\t\t// As we move src->trg, src->trg, we keep track of the previous trg to\n\t\t// avoid looking up the DFA state again, which is expensive.\n\t\t// If the previous target was already part of the DFA, we might\n\t\t// be able to avoid doing a reach operation upon t. If s!=null,\n\t\t// it means that semantic predicates didn't prevent us from\n\t\t// creating a DFA state. Once we know s!=null, we check to see if\n\t\t// the DFA state has an edge already for t. If so, we can just reuse\n\t\t// it's configuration set; there's no point in re-computing it.\n\t\t// This is kind of like doing DFA simulation within the ATN\n\t\t// simulation because DFA simulation is really just a way to avoid\n\t\t// computing reach/closure sets. Technically, once we know that\n\t\t// we have a previously added DFA state, we could jump over to\n\t\t// the DFA simulator. But, that would mean popping back and forth\n\t\t// a lot and making things more complicated algorithmically.\n\t\t// This optimization makes a lot of sense for loops within DFA.\n\t\t// A character will take us back to an existing DFA state\n\t\t// that already has lots of edges out of it. e.g., .* in comments.\n\t\t// print(\"Target for:\" + str(s) + \" and:\" + str(t))\n\t\tvar target = this.getExistingTargetState(s, t);\n\t\t// print(\"Existing:\" + str(target))\n\t\tif (target === null) {\n\t\t\ttarget = this.computeTargetState(input, s, t);\n\t\t\t// print(\"Computed:\" + str(target))\n\t\t}\n\t\tif (target === ATNSimulator.ERROR) {\n\t\t\tbreak;\n\t\t}\n\t\t// If this is a consumable input element, make sure to consume before\n\t\t// capturing the accept state so the input index, line, and char\n\t\t// position accurately reflect the state of the interpreter at the\n\t\t// end of the token.\n\t\tif (t !== Token.EOF) {\n\t\t\tthis.consume(input);\n\t\t}\n\t\tif (target.isAcceptState) {\n\t\t\tthis.captureSimState(this.prevAccept, input, target);\n\t\t\tif (t === Token.EOF) {\n\t\t\t\tbreak;\n\t\t\t}\n\t\t}\n\t\tt = input.LA(1);\n\t\ts = target; // flip; current DFA target becomes new src/from state\n\t}\n\treturn this.failOrAccept(this.prevAccept, input, s.configs, t);\n};\n\n// Get an existing target state for an edge in the DFA. If the target state\n// for the edge has not yet been computed or is otherwise not available,\n// this method returns {@code null}.\n//\n// @param s The current DFA state\n// @param t The next input symbol\n// @return The existing target DFA state for the given input symbol\n// {@code t}, or {@code null} if the target state for this edge is not\n// already cached\nLexerATNSimulator.prototype.getExistingTargetState = function(s, t) {\n\tif (s.edges === null || t < LexerATNSimulator.MIN_DFA_EDGE || t > LexerATNSimulator.MAX_DFA_EDGE) {\n\t\treturn null;\n\t}\n\n\tvar target = s.edges[t - LexerATNSimulator.MIN_DFA_EDGE];\n\tif(target===undefined) {\n\t\ttarget = null;\n\t}\n\tif (LexerATNSimulator.debug && target !== null) {\n\t\tconsole.log(\"reuse state \" + s.stateNumber + \" edge to \" + target.stateNumber);\n\t}\n\treturn target;\n};\n\n// Compute a target state for an edge in the DFA, and attempt to add the\n// computed state and corresponding edge to the DFA.\n//\n// @param input The input stream\n// @param s The current DFA state\n// @param t The next input symbol\n//\n// @return The computed target DFA state for the given input symbol\n// {@code t}. If {@code t} does not lead to a valid DFA state, this method\n// returns {@link //ERROR}.\nLexerATNSimulator.prototype.computeTargetState = function(input, s, t) {\n\tvar reach = new OrderedATNConfigSet();\n\t// if we don't find an existing DFA state\n\t// Fill reach starting from closure, following t transitions\n\tthis.getReachableConfigSet(input, s.configs, reach, t);\n\n\tif (reach.items.length === 0) { // we got nowhere on t from s\n\t\tif (!reach.hasSemanticContext) {\n\t\t\t// we got nowhere on t, don't throw out this knowledge; it'd\n\t\t\t// cause a failover from DFA later.\n\t\t\tthis.addDFAEdge(s, t, ATNSimulator.ERROR);\n\t\t}\n\t\t// stop when we can't match any more char\n\t\treturn ATNSimulator.ERROR;\n\t}\n\t// Add an edge from s to target DFA found/created for reach\n\treturn this.addDFAEdge(s, t, null, reach);\n};\n\nLexerATNSimulator.prototype.failOrAccept = function(prevAccept, input, reach, t) {\n\tif (this.prevAccept.dfaState !== null) {\n\t\tvar lexerActionExecutor = prevAccept.dfaState.lexerActionExecutor;\n\t\tthis.accept(input, lexerActionExecutor, this.startIndex,\n\t\t\t\tprevAccept.index, prevAccept.line, prevAccept.column);\n\t\treturn prevAccept.dfaState.prediction;\n\t} else {\n\t\t// if no accept and EOF is first char, return EOF\n\t\tif (t === Token.EOF && input.index === this.startIndex) {\n\t\t\treturn Token.EOF;\n\t\t}\n\t\tthrow new LexerNoViableAltException(this.recog, input, this.startIndex, reach);\n\t}\n};\n\n// Given a starting configuration set, figure out all ATN configurations\n// we can reach upon input {@code t}. Parameter {@code reach} is a return\n// parameter.\nLexerATNSimulator.prototype.getReachableConfigSet = function(input, closure,\n\t\treach, t) {\n\t// this is used to skip processing for configs which have a lower priority\n\t// than a config that already reached an accept state for the same rule\n\tvar skipAlt = ATN.INVALID_ALT_NUMBER;\n\tfor (var i = 0; i < closure.items.length; i++) {\n\t\tvar cfg = closure.items[i];\n\t\tvar currentAltReachedAcceptState = (cfg.alt === skipAlt);\n\t\tif (currentAltReachedAcceptState && cfg.passedThroughNonGreedyDecision) {\n\t\t\tcontinue;\n\t\t}\n\t\tif (LexerATNSimulator.debug) {\n\t\t\tconsole.log(\"testing %s at %s\\n\", this.getTokenName(t), cfg\n\t\t\t\t\t.toString(this.recog, true));\n\t\t}\n\t\tfor (var j = 0; j < cfg.state.transitions.length; j++) {\n\t\t\tvar trans = cfg.state.transitions[j]; // for each transition\n\t\t\tvar target = this.getReachableTarget(trans, t);\n\t\t\tif (target !== null) {\n\t\t\t\tvar lexerActionExecutor = cfg.lexerActionExecutor;\n\t\t\t\tif (lexerActionExecutor !== null) {\n\t\t\t\t\tlexerActionExecutor = lexerActionExecutor.fixOffsetBeforeMatch(input.index - this.startIndex);\n\t\t\t\t}\n\t\t\t\tvar treatEofAsEpsilon = (t === Token.EOF);\n\t\t\t\tvar config = new LexerATNConfig({state:target, lexerActionExecutor:lexerActionExecutor}, cfg);\n\t\t\t\tif (this.closure(input, config, reach,\n\t\t\t\t\t\tcurrentAltReachedAcceptState, true, treatEofAsEpsilon)) {\n\t\t\t\t\t// any remaining configs for this alt have a lower priority\n\t\t\t\t\t// than the one that just reached an accept state.\n\t\t\t\t\tskipAlt = cfg.alt;\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n};\n\nLexerATNSimulator.prototype.accept = function(input, lexerActionExecutor,\n\t\tstartIndex, index, line, charPos) {\n\tif (LexerATNSimulator.debug) {\n\t\tconsole.log(\"ACTION %s\\n\", lexerActionExecutor);\n\t}\n\t// seek to after last char in token\n\tinput.seek(index);\n\tthis.line = line;\n\tthis.column = charPos;\n\tif (lexerActionExecutor !== null && this.recog !== null) {\n\t\tlexerActionExecutor.execute(this.recog, input, startIndex);\n\t}\n};\n\nLexerATNSimulator.prototype.getReachableTarget = function(trans, t) {\n\tif (trans.matches(t, 0, Lexer.MAX_CHAR_VALUE)) {\n\t\treturn trans.target;\n\t} else {\n\t\treturn null;\n\t}\n};\n\nLexerATNSimulator.prototype.computeStartState = function(input, p) {\n\tvar initialContext = PredictionContext.EMPTY;\n\tvar configs = new OrderedATNConfigSet();\n\tfor (var i = 0; i < p.transitions.length; i++) {\n\t\tvar target = p.transitions[i].target;\n        var cfg = new LexerATNConfig({state:target, alt:i+1, context:initialContext}, null);\n\t\tthis.closure(input, cfg, configs, false, false, false);\n\t}\n\treturn configs;\n};\n\n// Since the alternatives within any lexer decision are ordered by\n// preference, this method stops pursuing the closure as soon as an accept\n// state is reached. After the first accept state is reached by depth-first\n// search from {@code config}, all other (potentially reachable) states for\n// this rule would have a lower priority.\n//\n// @return {@code true} if an accept state is reached, otherwise\n// {@code false}.\nLexerATNSimulator.prototype.closure = function(input, config, configs,\n\t\tcurrentAltReachedAcceptState, speculative, treatEofAsEpsilon) {\n\tvar cfg = null;\n\tif (LexerATNSimulator.debug) {\n\t\tconsole.log(\"closure(\" + config.toString(this.recog, true) + \")\");\n\t}\n\tif (config.state instanceof RuleStopState) {\n\t\tif (LexerATNSimulator.debug) {\n\t\t\tif (this.recog !== null) {\n\t\t\t\tconsole.log(\"closure at %s rule stop %s\\n\", this.recog.ruleNames[config.state.ruleIndex], config);\n\t\t\t} else {\n\t\t\t\tconsole.log(\"closure at rule stop %s\\n\", config);\n\t\t\t}\n\t\t}\n\t\tif (config.context === null || config.context.hasEmptyPath()) {\n\t\t\tif (config.context === null || config.context.isEmpty()) {\n\t\t\t\tconfigs.add(config);\n\t\t\t\treturn true;\n\t\t\t} else {\n\t\t\t\tconfigs.add(new LexerATNConfig({ state:config.state, context:PredictionContext.EMPTY}, config));\n\t\t\t\tcurrentAltReachedAcceptState = true;\n\t\t\t}\n\t\t}\n\t\tif (config.context !== null && !config.context.isEmpty()) {\n\t\t\tfor (var i = 0; i < config.context.length; i++) {\n\t\t\t\tif (config.context.getReturnState(i) !== PredictionContext.EMPTY_RETURN_STATE) {\n\t\t\t\t\tvar newContext = config.context.getParent(i); // \"pop\" return state\n\t\t\t\t\tvar returnState = this.atn.states[config.context.getReturnState(i)];\n\t\t\t\t\tcfg = new LexerATNConfig({ state:returnState, context:newContext }, config);\n\t\t\t\t\tcurrentAltReachedAcceptState = this.closure(input, cfg,\n\t\t\t\t\t\t\tconfigs, currentAltReachedAcceptState, speculative,\n\t\t\t\t\t\t\ttreatEofAsEpsilon);\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\treturn currentAltReachedAcceptState;\n\t}\n\t// optimization\n\tif (!config.state.epsilonOnlyTransitions) {\n\t\tif (!currentAltReachedAcceptState || !config.passedThroughNonGreedyDecision) {\n\t\t\tconfigs.add(config);\n\t\t}\n\t}\n\tfor (var j = 0; j < config.state.transitions.length; j++) {\n\t\tvar trans = config.state.transitions[j];\n\t\tcfg = this.getEpsilonTarget(input, config, trans, configs, speculative, treatEofAsEpsilon);\n\t\tif (cfg !== null) {\n\t\t\tcurrentAltReachedAcceptState = this.closure(input, cfg, configs,\n\t\t\t\t\tcurrentAltReachedAcceptState, speculative, treatEofAsEpsilon);\n\t\t}\n\t}\n\treturn currentAltReachedAcceptState;\n};\n\n// side-effect: can alter configs.hasSemanticContext\nLexerATNSimulator.prototype.getEpsilonTarget = function(input, config, trans,\n\t\tconfigs, speculative, treatEofAsEpsilon) {\n\tvar cfg = null;\n\tif (trans.serializationType === Transition.RULE) {\n\t\tvar newContext = SingletonPredictionContext.create(config.context, trans.followState.stateNumber);\n\t\tcfg = new LexerATNConfig( { state:trans.target, context:newContext}, config);\n\t} else if (trans.serializationType === Transition.PRECEDENCE) {\n\t\tthrow \"Precedence predicates are not supported in lexers.\";\n\t} else if (trans.serializationType === Transition.PREDICATE) {\n\t\t// Track traversing semantic predicates. If we traverse,\n\t\t// we cannot add a DFA state for this \"reach\" computation\n\t\t// because the DFA would not test the predicate again in the\n\t\t// future. Rather than creating collections of semantic predicates\n\t\t// like v3 and testing them on prediction, v4 will test them on the\n\t\t// fly all the time using the ATN not the DFA. This is slower but\n\t\t// semantically it's not used that often. One of the key elements to\n\t\t// this predicate mechanism is not adding DFA states that see\n\t\t// predicates immediately afterwards in the ATN. For example,\n\n\t\t// a : ID {p1}? | ID {p2}? ;\n\n\t\t// should create the start state for rule 'a' (to save start state\n\t\t// competition), but should not create target of ID state. The\n\t\t// collection of ATN states the following ID references includes\n\t\t// states reached by traversing predicates. Since this is when we\n\t\t// test them, we cannot cash the DFA state target of ID.\n\n\t\tif (LexerATNSimulator.debug) {\n\t\t\tconsole.log(\"EVAL rule \" + trans.ruleIndex + \":\" + trans.predIndex);\n\t\t}\n\t\tconfigs.hasSemanticContext = true;\n\t\tif (this.evaluatePredicate(input, trans.ruleIndex, trans.predIndex, speculative)) {\n\t\t\tcfg = new LexerATNConfig({ state:trans.target}, config);\n\t\t}\n\t} else if (trans.serializationType === Transition.ACTION) {\n\t\tif (config.context === null || config.context.hasEmptyPath()) {\n\t\t\t// execute actions anywhere in the start rule for a token.\n\t\t\t//\n\t\t\t// TODO: if the entry rule is invoked recursively, some\n\t\t\t// actions may be executed during the recursive call. The\n\t\t\t// problem can appear when hasEmptyPath() is true but\n\t\t\t// isEmpty() is false. In this case, the config needs to be\n\t\t\t// split into two contexts - one with just the empty path\n\t\t\t// and another with everything but the empty path.\n\t\t\t// Unfortunately, the current algorithm does not allow\n\t\t\t// getEpsilonTarget to return two configurations, so\n\t\t\t// additional modifications are needed before we can support\n\t\t\t// the split operation.\n\t\t\tvar lexerActionExecutor = LexerActionExecutor.append(config.lexerActionExecutor,\n\t\t\t\t\tthis.atn.lexerActions[trans.actionIndex]);\n\t\t\tcfg = new LexerATNConfig({ state:trans.target, lexerActionExecutor:lexerActionExecutor }, config);\n\t\t} else {\n\t\t\t// ignore actions in referenced rules\n\t\t\tcfg = new LexerATNConfig( { state:trans.target}, config);\n\t\t}\n\t} else if (trans.serializationType === Transition.EPSILON) {\n\t\tcfg = new LexerATNConfig({ state:trans.target}, config);\n\t} else if (trans.serializationType === Transition.ATOM ||\n\t\t\t\ttrans.serializationType === Transition.RANGE ||\n\t\t\t\ttrans.serializationType === Transition.SET) {\n\t\tif (treatEofAsEpsilon) {\n\t\t\tif (trans.matches(Token.EOF, 0, Lexer.MAX_CHAR_VALUE)) {\n\t\t\t\tcfg = new LexerATNConfig( { state:trans.target }, config);\n\t\t\t}\n\t\t}\n\t}\n\treturn cfg;\n};\n\n// Evaluate a predicate specified in the lexer.\n//\n// <p>If {@code speculative} is {@code true}, this method was called before\n// {@link //consume} for the matched character. This method should call\n// {@link //consume} before evaluating the predicate to ensure position\n// sensitive values, including {@link Lexer//getText}, {@link Lexer//getLine},\n// and {@link Lexer//getcolumn}, properly reflect the current\n// lexer state. This method should restore {@code input} and the simulator\n// to the original state before returning (i.e. undo the actions made by the\n// call to {@link //consume}.</p>\n//\n// @param input The input stream.\n// @param ruleIndex The rule containing the predicate.\n// @param predIndex The index of the predicate within the rule.\n// @param speculative {@code true} if the current index in {@code input} is\n// one character before the predicate's location.\n//\n// @return {@code true} if the specified predicate evaluates to\n// {@code true}.\n// /\nLexerATNSimulator.prototype.evaluatePredicate = function(input, ruleIndex,\n\t\tpredIndex, speculative) {\n\t// assume true if no recognizer was provided\n\tif (this.recog === null) {\n\t\treturn true;\n\t}\n\tif (!speculative) {\n\t\treturn this.recog.sempred(null, ruleIndex, predIndex);\n\t}\n\tvar savedcolumn = this.column;\n\tvar savedLine = this.line;\n\tvar index = input.index;\n\tvar marker = input.mark();\n\ttry {\n\t\tthis.consume(input);\n\t\treturn this.recog.sempred(null, ruleIndex, predIndex);\n\t} finally {\n\t\tthis.column = savedcolumn;\n\t\tthis.line = savedLine;\n\t\tinput.seek(index);\n\t\tinput.release(marker);\n\t}\n};\n\nLexerATNSimulator.prototype.captureSimState = function(settings, input, dfaState) {\n\tsettings.index = input.index;\n\tsettings.line = this.line;\n\tsettings.column = this.column;\n\tsettings.dfaState = dfaState;\n};\n\nLexerATNSimulator.prototype.addDFAEdge = function(from_, tk, to, cfgs) {\n\tif (to === undefined) {\n\t\tto = null;\n\t}\n\tif (cfgs === undefined) {\n\t\tcfgs = null;\n\t}\n\tif (to === null && cfgs !== null) {\n\t\t// leading to this call, ATNConfigSet.hasSemanticContext is used as a\n\t\t// marker indicating dynamic predicate evaluation makes this edge\n\t\t// dependent on the specific input sequence, so the static edge in the\n\t\t// DFA should be omitted. The target DFAState is still created since\n\t\t// execATN has the ability to resynchronize with the DFA state cache\n\t\t// following the predicate evaluation step.\n\t\t//\n\t\t// TJP notes: next time through the DFA, we see a pred again and eval.\n\t\t// If that gets us to a previously created (but dangling) DFA\n\t\t// state, we can continue in pure DFA mode from there.\n\t\t// /\n\t\tvar suppressEdge = cfgs.hasSemanticContext;\n\t\tcfgs.hasSemanticContext = false;\n\n\t\tto = this.addDFAState(cfgs);\n\n\t\tif (suppressEdge) {\n\t\t\treturn to;\n\t\t}\n\t}\n\t// add the edge\n\tif (tk < LexerATNSimulator.MIN_DFA_EDGE || tk > LexerATNSimulator.MAX_DFA_EDGE) {\n\t\t// Only track edges within the DFA bounds\n\t\treturn to;\n\t}\n\tif (LexerATNSimulator.debug) {\n\t\tconsole.log(\"EDGE \" + from_ + \" -> \" + to + \" upon \" + tk);\n\t}\n\tif (from_.edges === null) {\n\t\t// make room for tokens 1..n and -1 masquerading as index 0\n\t\tfrom_.edges = [];\n\t}\n\tfrom_.edges[tk - LexerATNSimulator.MIN_DFA_EDGE] = to; // connect\n\n\treturn to;\n};\n\n// Add a new DFA state if there isn't one with this set of\n// configurations already. This method also detects the first\n// configuration containing an ATN rule stop state. Later, when\n// traversing the DFA, we will know which rule to accept.\nLexerATNSimulator.prototype.addDFAState = function(configs) {\n\tvar proposed = new DFAState(null, configs);\n\tvar firstConfigWithRuleStopState = null;\n\tfor (var i = 0; i < configs.items.length; i++) {\n\t\tvar cfg = configs.items[i];\n\t\tif (cfg.state instanceof RuleStopState) {\n\t\t\tfirstConfigWithRuleStopState = cfg;\n\t\t\tbreak;\n\t\t}\n\t}\n\tif (firstConfigWithRuleStopState !== null) {\n\t\tproposed.isAcceptState = true;\n\t\tproposed.lexerActionExecutor = firstConfigWithRuleStopState.lexerActionExecutor;\n\t\tproposed.prediction = this.atn.ruleToTokenType[firstConfigWithRuleStopState.state.ruleIndex];\n\t}\n\tvar dfa = this.decisionToDFA[this.mode];\n\tvar existing = dfa.states.get(proposed);\n\tif (existing!==null) {\n\t\treturn existing;\n\t}\n\tvar newState = proposed;\n\tnewState.stateNumber = dfa.states.length;\n\tconfigs.setReadonly(true);\n\tnewState.configs = configs;\n\tdfa.states.add(newState);\n\treturn newState;\n};\n\nLexerATNSimulator.prototype.getDFA = function(mode) {\n\treturn this.decisionToDFA[mode];\n};\n\n// Get the text matched so far for the current token.\nLexerATNSimulator.prototype.getText = function(input) {\n\t// index is first lookahead char, don't include.\n\treturn input.getText(this.startIndex, input.index - 1);\n};\n\nLexerATNSimulator.prototype.consume = function(input) {\n\tvar curChar = input.LA(1);\n\tif (curChar === \"\\n\".charCodeAt(0)) {\n\t\tthis.line += 1;\n\t\tthis.column = 0;\n\t} else {\n\t\tthis.column += 1;\n\t}\n\tinput.consume();\n};\n\nLexerATNSimulator.prototype.getTokenName = function(tt) {\n\tif (tt === -1) {\n\t\treturn \"EOF\";\n\t} else {\n\t\treturn \"'\" + String.fromCharCode(tt) + \"'\";\n\t}\n};\n\nexports.LexerATNSimulator = LexerATNSimulator;\n\n\n//# sourceURL=webpack:///./antlr4/atn/LexerATNSimulator.js?");

/***/ }),

/***/ "./antlr4/atn/LexerAction.js":
/*!***********************************!*\
  !*** ./antlr4/atn/LexerAction.js ***!
  \***********************************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("//\n/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n //\n\nfunction LexerActionType() {\n}\n\nLexerActionType.CHANNEL = 0;     //The type of a {@link LexerChannelAction} action.\nLexerActionType.CUSTOM = 1;      //The type of a {@link LexerCustomAction} action.\nLexerActionType.MODE = 2;        //The type of a {@link LexerModeAction} action.\nLexerActionType.MORE = 3;        //The type of a {@link LexerMoreAction} action.\nLexerActionType.POP_MODE = 4;    //The type of a {@link LexerPopModeAction} action.\nLexerActionType.PUSH_MODE = 5;   //The type of a {@link LexerPushModeAction} action.\nLexerActionType.SKIP = 6;        //The type of a {@link LexerSkipAction} action.\nLexerActionType.TYPE = 7;        //The type of a {@link LexerTypeAction} action.\n\nfunction LexerAction(action) {\n    this.actionType = action;\n    this.isPositionDependent = false;\n    return this;\n}\n\nLexerAction.prototype.hashCode = function() {\n    var hash = new Hash();\n    this.updateHashCode(hash);\n    return hash.finish()\n};\n\nLexerAction.prototype.updateHashCode = function(hash) {\n    hash.update(this.actionType);\n};\n\nLexerAction.prototype.equals = function(other) {\n    return this === other;\n};\n\n\n\n//\n// Implements the {@code skip} lexer action by calling {@link Lexer//skip}.\n//\n// <p>The {@code skip} command does not have any parameters, so this action is\n// implemented as a singleton instance exposed by {@link //INSTANCE}.</p>\nfunction LexerSkipAction() {\n\tLexerAction.call(this, LexerActionType.SKIP);\n\treturn this;\n}\n\nLexerSkipAction.prototype = Object.create(LexerAction.prototype);\nLexerSkipAction.prototype.constructor = LexerSkipAction;\n\n// Provides a singleton instance of this parameterless lexer action.\nLexerSkipAction.INSTANCE = new LexerSkipAction();\n\nLexerSkipAction.prototype.execute = function(lexer) {\n    lexer.skip();\n};\n\nLexerSkipAction.prototype.toString = function() {\n\treturn \"skip\";\n};\n\n//  Implements the {@code type} lexer action by calling {@link Lexer//setType}\n// with the assigned type.\nfunction LexerTypeAction(type) {\n\tLexerAction.call(this, LexerActionType.TYPE);\n\tthis.type = type;\n\treturn this;\n}\n\nLexerTypeAction.prototype = Object.create(LexerAction.prototype);\nLexerTypeAction.prototype.constructor = LexerTypeAction;\n\nLexerTypeAction.prototype.execute = function(lexer) {\n    lexer.type = this.type;\n};\n\nLexerTypeAction.prototype.updateHashCode = function(hash) {\n    hash.update(this.actionType, this.type);\n};\n\n\nLexerTypeAction.prototype.equals = function(other) {\n    if(this === other) {\n        return true;\n    } else if (! (other instanceof LexerTypeAction)) {\n        return false;\n    } else {\n        return this.type === other.type;\n    }\n};\n\nLexerTypeAction.prototype.toString = function() {\n    return \"type(\" + this.type + \")\";\n};\n\n// Implements the {@code pushMode} lexer action by calling\n// {@link Lexer//pushMode} with the assigned mode.\nfunction LexerPushModeAction(mode) {\n\tLexerAction.call(this, LexerActionType.PUSH_MODE);\n    this.mode = mode;\n    return this;\n}\n\nLexerPushModeAction.prototype = Object.create(LexerAction.prototype);\nLexerPushModeAction.prototype.constructor = LexerPushModeAction;\n\n// <p>This action is implemented by calling {@link Lexer//pushMode} with the\n// value provided by {@link //getMode}.</p>\nLexerPushModeAction.prototype.execute = function(lexer) {\n    lexer.pushMode(this.mode);\n};\n\nLexerPushModeAction.prototype.updateHashCode = function(hash) {\n    hash.update(this.actionType, this.mode);\n};\n\nLexerPushModeAction.prototype.equals = function(other) {\n    if (this === other) {\n        return true;\n    } else if (! (other instanceof LexerPushModeAction)) {\n        return false;\n    } else {\n        return this.mode === other.mode;\n    }\n};\n\nLexerPushModeAction.prototype.toString = function() {\n\treturn \"pushMode(\" + this.mode + \")\";\n};\n\n\n// Implements the {@code popMode} lexer action by calling {@link Lexer//popMode}.\n//\n// <p>The {@code popMode} command does not have any parameters, so this action is\n// implemented as a singleton instance exposed by {@link //INSTANCE}.</p>\nfunction LexerPopModeAction() {\n\tLexerAction.call(this,LexerActionType.POP_MODE);\n\treturn this;\n}\n\nLexerPopModeAction.prototype = Object.create(LexerAction.prototype);\nLexerPopModeAction.prototype.constructor = LexerPopModeAction;\n\nLexerPopModeAction.INSTANCE = new LexerPopModeAction();\n\n// <p>This action is implemented by calling {@link Lexer//popMode}.</p>\nLexerPopModeAction.prototype.execute = function(lexer) {\n    lexer.popMode();\n};\n\nLexerPopModeAction.prototype.toString = function() {\n\treturn \"popMode\";\n};\n\n// Implements the {@code more} lexer action by calling {@link Lexer//more}.\n//\n// <p>The {@code more} command does not have any parameters, so this action is\n// implemented as a singleton instance exposed by {@link //INSTANCE}.</p>\nfunction LexerMoreAction() {\n\tLexerAction.call(this, LexerActionType.MORE);\n\treturn this;\n}\n\nLexerMoreAction.prototype = Object.create(LexerAction.prototype);\nLexerMoreAction.prototype.constructor = LexerMoreAction;\n\nLexerMoreAction.INSTANCE = new LexerMoreAction();\n\n// <p>This action is implemented by calling {@link Lexer//popMode}.</p>\nLexerMoreAction.prototype.execute = function(lexer) {\n    lexer.more();\n};\n\nLexerMoreAction.prototype.toString = function() {\n    return \"more\";\n};\n\n\n// Implements the {@code mode} lexer action by calling {@link Lexer//mode} with\n// the assigned mode.\nfunction LexerModeAction(mode) {\n\tLexerAction.call(this, LexerActionType.MODE);\n    this.mode = mode;\n    return this;\n}\n\nLexerModeAction.prototype = Object.create(LexerAction.prototype);\nLexerModeAction.prototype.constructor = LexerModeAction;\n\n// <p>This action is implemented by calling {@link Lexer//mode} with the\n// value provided by {@link //getMode}.</p>\nLexerModeAction.prototype.execute = function(lexer) {\n    lexer.mode(this.mode);\n};\n\nLexerModeAction.prototype.updateHashCode = function(hash) {\n    hash.update(this.actionType, this.mode);\n};\n\nLexerModeAction.prototype.equals = function(other) {\n    if (this === other) {\n        return true;\n    } else if (! (other instanceof LexerModeAction)) {\n        return false;\n    } else {\n        return this.mode === other.mode;\n    }\n};\n\nLexerModeAction.prototype.toString = function() {\n    return \"mode(\" + this.mode + \")\";\n};\n\n// Executes a custom lexer action by calling {@link Recognizer//action} with the\n// rule and action indexes assigned to the custom action. The implementation of\n// a custom action is added to the generated code for the lexer in an override\n// of {@link Recognizer//action} when the grammar is compiled.\n//\n// <p>This class may represent embedded actions created with the <code>{...}</code>\n// syntax in ANTLR 4, as well as actions created for lexer commands where the\n// command argument could not be evaluated when the grammar was compiled.</p>\n\n\n    // Constructs a custom lexer action with the specified rule and action\n    // indexes.\n    //\n    // @param ruleIndex The rule index to use for calls to\n    // {@link Recognizer//action}.\n    // @param actionIndex The action index to use for calls to\n    // {@link Recognizer//action}.\n\nfunction LexerCustomAction(ruleIndex, actionIndex) {\n\tLexerAction.call(this, LexerActionType.CUSTOM);\n    this.ruleIndex = ruleIndex;\n    this.actionIndex = actionIndex;\n    this.isPositionDependent = true;\n    return this;\n}\n\nLexerCustomAction.prototype = Object.create(LexerAction.prototype);\nLexerCustomAction.prototype.constructor = LexerCustomAction;\n\n// <p>Custom actions are implemented by calling {@link Lexer//action} with the\n// appropriate rule and action indexes.</p>\nLexerCustomAction.prototype.execute = function(lexer) {\n    lexer.action(null, this.ruleIndex, this.actionIndex);\n};\n\nLexerCustomAction.prototype.updateHashCode = function(hash) {\n    hash.update(this.actionType, this.ruleIndex, this.actionIndex);\n};\n\nLexerCustomAction.prototype.equals = function(other) {\n    if (this === other) {\n        return true;\n    } else if (! (other instanceof LexerCustomAction)) {\n        return false;\n    } else {\n        return this.ruleIndex === other.ruleIndex && this.actionIndex === other.actionIndex;\n    }\n};\n\n// Implements the {@code channel} lexer action by calling\n// {@link Lexer//setChannel} with the assigned channel.\n// Constructs a new {@code channel} action with the specified channel value.\n// @param channel The channel value to pass to {@link Lexer//setChannel}.\nfunction LexerChannelAction(channel) {\n\tLexerAction.call(this, LexerActionType.CHANNEL);\n    this.channel = channel;\n    return this;\n}\n\nLexerChannelAction.prototype = Object.create(LexerAction.prototype);\nLexerChannelAction.prototype.constructor = LexerChannelAction;\n\n// <p>This action is implemented by calling {@link Lexer//setChannel} with the\n// value provided by {@link //getChannel}.</p>\nLexerChannelAction.prototype.execute = function(lexer) {\n    lexer._channel = this.channel;\n};\n\nLexerChannelAction.prototype.updateHashCode = function(hash) {\n    hash.update(this.actionType, this.channel);\n};\n\nLexerChannelAction.prototype.equals = function(other) {\n    if (this === other) {\n        return true;\n    } else if (! (other instanceof LexerChannelAction)) {\n        return false;\n    } else {\n        return this.channel === other.channel;\n    }\n};\n\nLexerChannelAction.prototype.toString = function() {\n    return \"channel(\" + this.channel + \")\";\n};\n\n// This implementation of {@link LexerAction} is used for tracking input offsets\n// for position-dependent actions within a {@link LexerActionExecutor}.\n//\n// <p>This action is not serialized as part of the ATN, and is only required for\n// position-dependent lexer actions which appear at a location other than the\n// end of a rule. For more information about DFA optimizations employed for\n// lexer actions, see {@link LexerActionExecutor//append} and\n// {@link LexerActionExecutor//fixOffsetBeforeMatch}.</p>\n\n// Constructs a new indexed custom action by associating a character offset\n// with a {@link LexerAction}.\n//\n// <p>Note: This class is only required for lexer actions for which\n// {@link LexerAction//isPositionDependent} returns {@code true}.</p>\n//\n// @param offset The offset into the input {@link CharStream}, relative to\n// the token start index, at which the specified lexer action should be\n// executed.\n// @param action The lexer action to execute at a particular offset in the\n// input {@link CharStream}.\nfunction LexerIndexedCustomAction(offset, action) {\n\tLexerAction.call(this, action.actionType);\n    this.offset = offset;\n    this.action = action;\n    this.isPositionDependent = true;\n    return this;\n}\n\nLexerIndexedCustomAction.prototype = Object.create(LexerAction.prototype);\nLexerIndexedCustomAction.prototype.constructor = LexerIndexedCustomAction;\n\n// <p>This method calls {@link //execute} on the result of {@link //getAction}\n// using the provided {@code lexer}.</p>\nLexerIndexedCustomAction.prototype.execute = function(lexer) {\n    // assume the input stream position was properly set by the calling code\n    this.action.execute(lexer);\n};\n\nLexerIndexedCustomAction.prototype.updateHashCode = function(hash) {\n    hash.update(this.actionType, this.offset, this.action);\n};\n\nLexerIndexedCustomAction.prototype.equals = function(other) {\n    if (this === other) {\n        return true;\n    } else if (! (other instanceof LexerIndexedCustomAction)) {\n        return false;\n    } else {\n        return this.offset === other.offset && this.action === other.action;\n    }\n};\n\n\nexports.LexerActionType = LexerActionType;\nexports.LexerSkipAction = LexerSkipAction;\nexports.LexerChannelAction = LexerChannelAction;\nexports.LexerCustomAction = LexerCustomAction;\nexports.LexerIndexedCustomAction = LexerIndexedCustomAction;\nexports.LexerMoreAction = LexerMoreAction;\nexports.LexerTypeAction = LexerTypeAction;\nexports.LexerPushModeAction = LexerPushModeAction;\nexports.LexerPopModeAction = LexerPopModeAction;\nexports.LexerModeAction = LexerModeAction;\n\n//# sourceURL=webpack:///./antlr4/atn/LexerAction.js?");

/***/ }),

/***/ "./antlr4/atn/LexerActionExecutor.js":
/*!*******************************************!*\
  !*** ./antlr4/atn/LexerActionExecutor.js ***!
  \*******************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("//\n/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n///\n\n// Represents an executor for a sequence of lexer actions which traversed during\n// the matching operation of a lexer rule (token).\n//\n// <p>The executor tracks position information for position-dependent lexer actions\n// efficiently, ensuring that actions appearing only at the end of the rule do\n// not cause bloating of the {@link DFA} created for the lexer.</p>\n\nvar hashStuff = __webpack_require__(/*! ../Utils */ \"./antlr4/Utils.js\").hashStuff;\nvar LexerIndexedCustomAction = __webpack_require__(/*! ./LexerAction */ \"./antlr4/atn/LexerAction.js\").LexerIndexedCustomAction;\n\nfunction LexerActionExecutor(lexerActions) {\n\tthis.lexerActions = lexerActions === null ? [] : lexerActions;\n\t// Caches the result of {@link //hashCode} since the hash code is an element\n\t// of the performance-critical {@link LexerATNConfig//hashCode} operation.\n\tthis.cachedHashCode = hashStuff(lexerActions); // \"\".join([str(la) for la in\n\t// lexerActions]))\n\treturn this;\n}\n\n// Creates a {@link LexerActionExecutor} which executes the actions for\n// the input {@code lexerActionExecutor} followed by a specified\n// {@code lexerAction}.\n//\n// @param lexerActionExecutor The executor for actions already traversed by\n// the lexer while matching a token within a particular\n// {@link LexerATNConfig}. If this is {@code null}, the method behaves as\n// though it were an empty executor.\n// @param lexerAction The lexer action to execute after the actions\n// specified in {@code lexerActionExecutor}.\n//\n// @return A {@link LexerActionExecutor} for executing the combine actions\n// of {@code lexerActionExecutor} and {@code lexerAction}.\nLexerActionExecutor.append = function(lexerActionExecutor, lexerAction) {\n\tif (lexerActionExecutor === null) {\n\t\treturn new LexerActionExecutor([ lexerAction ]);\n\t}\n\tvar lexerActions = lexerActionExecutor.lexerActions.concat([ lexerAction ]);\n\treturn new LexerActionExecutor(lexerActions);\n};\n\n// Creates a {@link LexerActionExecutor} which encodes the current offset\n// for position-dependent lexer actions.\n//\n// <p>Normally, when the executor encounters lexer actions where\n// {@link LexerAction//isPositionDependent} returns {@code true}, it calls\n// {@link IntStream//seek} on the input {@link CharStream} to set the input\n// position to the <em>end</em> of the current token. This behavior provides\n// for efficient DFA representation of lexer actions which appear at the end\n// of a lexer rule, even when the lexer rule matches a variable number of\n// characters.</p>\n//\n// <p>Prior to traversing a match transition in the ATN, the current offset\n// from the token start index is assigned to all position-dependent lexer\n// actions which have not already been assigned a fixed offset. By storing\n// the offsets relative to the token start index, the DFA representation of\n// lexer actions which appear in the middle of tokens remains efficient due\n// to sharing among tokens of the same length, regardless of their absolute\n// position in the input stream.</p>\n//\n// <p>If the current executor already has offsets assigned to all\n// position-dependent lexer actions, the method returns {@code this}.</p>\n//\n// @param offset The current offset to assign to all position-dependent\n// lexer actions which do not already have offsets assigned.\n//\n// @return A {@link LexerActionExecutor} which stores input stream offsets\n// for all position-dependent lexer actions.\n// /\nLexerActionExecutor.prototype.fixOffsetBeforeMatch = function(offset) {\n\tvar updatedLexerActions = null;\n\tfor (var i = 0; i < this.lexerActions.length; i++) {\n\t\tif (this.lexerActions[i].isPositionDependent &&\n\t\t\t\t!(this.lexerActions[i] instanceof LexerIndexedCustomAction)) {\n\t\t\tif (updatedLexerActions === null) {\n\t\t\t\tupdatedLexerActions = this.lexerActions.concat([]);\n\t\t\t}\n\t\t\tupdatedLexerActions[i] = new LexerIndexedCustomAction(offset,\n\t\t\t\t\tthis.lexerActions[i]);\n\t\t}\n\t}\n\tif (updatedLexerActions === null) {\n\t\treturn this;\n\t} else {\n\t\treturn new LexerActionExecutor(updatedLexerActions);\n\t}\n};\n\n// Execute the actions encapsulated by this executor within the context of a\n// particular {@link Lexer}.\n//\n// <p>This method calls {@link IntStream//seek} to set the position of the\n// {@code input} {@link CharStream} prior to calling\n// {@link LexerAction//execute} on a position-dependent action. Before the\n// method returns, the input position will be restored to the same position\n// it was in when the method was invoked.</p>\n//\n// @param lexer The lexer instance.\n// @param input The input stream which is the source for the current token.\n// When this method is called, the current {@link IntStream//index} for\n// {@code input} should be the start of the following token, i.e. 1\n// character past the end of the current token.\n// @param startIndex The token start index. This value may be passed to\n// {@link IntStream//seek} to set the {@code input} position to the beginning\n// of the token.\n// /\nLexerActionExecutor.prototype.execute = function(lexer, input, startIndex) {\n\tvar requiresSeek = false;\n\tvar stopIndex = input.index;\n\ttry {\n\t\tfor (var i = 0; i < this.lexerActions.length; i++) {\n\t\t\tvar lexerAction = this.lexerActions[i];\n\t\t\tif (lexerAction instanceof LexerIndexedCustomAction) {\n\t\t\t\tvar offset = lexerAction.offset;\n\t\t\t\tinput.seek(startIndex + offset);\n\t\t\t\tlexerAction = lexerAction.action;\n\t\t\t\trequiresSeek = (startIndex + offset) !== stopIndex;\n\t\t\t} else if (lexerAction.isPositionDependent) {\n\t\t\t\tinput.seek(stopIndex);\n\t\t\t\trequiresSeek = false;\n\t\t\t}\n\t\t\tlexerAction.execute(lexer);\n\t\t}\n\t} finally {\n\t\tif (requiresSeek) {\n\t\t\tinput.seek(stopIndex);\n\t\t}\n\t}\n};\n\nLexerActionExecutor.prototype.hashCode = function() {\n\treturn this.cachedHashCode;\n};\n\nLexerActionExecutor.prototype.updateHashCode = function(hash) {\n    hash.update(this.cachedHashCode);\n};\n\n\nLexerActionExecutor.prototype.equals = function(other) {\n\tif (this === other) {\n\t\treturn true;\n\t} else if (!(other instanceof LexerActionExecutor)) {\n\t\treturn false;\n\t} else if (this.cachedHashCode != other.cachedHashCode) {\n\t\treturn false;\n\t} else if (this.lexerActions.length != other.lexerActions.length) {\n\t\treturn false;\n\t} else {\n\t\tvar numActions = this.lexerActions.length\n\t\tfor (var idx = 0; idx < numActions; ++idx) {\n\t\t\tif (!this.lexerActions[idx].equals(other.lexerActions[idx])) {\n\t\t\t\treturn false;\n\t\t\t}\n\t\t}\n\t\treturn true;\n\t}\n};\n\nexports.LexerActionExecutor = LexerActionExecutor;\n\n\n//# sourceURL=webpack:///./antlr4/atn/LexerActionExecutor.js?");

/***/ }),

/***/ "./antlr4/atn/ParserATNSimulator.js":
/*!******************************************!*\
  !*** ./antlr4/atn/ParserATNSimulator.js ***!
  \******************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("//\n/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n//\n\n//\n// The embodiment of the adaptive LL(*), ALL(*), parsing strategy.\n//\n// <p>\n// The basic complexity of the adaptive strategy makes it harder to understand.\n// We begin with ATN simulation to build paths in a DFA. Subsequent prediction\n// requests go through the DFA first. If they reach a state without an edge for\n// the current symbol, the algorithm fails over to the ATN simulation to\n// complete the DFA path for the current input (until it finds a conflict state\n// or uniquely predicting state).</p>\n//\n// <p>\n// All of that is done without using the outer context because we want to create\n// a DFA that is not dependent upon the rule invocation stack when we do a\n// prediction. One DFA works in all contexts. We avoid using context not\n// necessarily because it's slower, although it can be, but because of the DFA\n// caching problem. The closure routine only considers the rule invocation stack\n// created during prediction beginning in the decision rule. For example, if\n// prediction occurs without invoking another rule's ATN, there are no context\n// stacks in the configurations. When lack of context leads to a conflict, we\n// don't know if it's an ambiguity or a weakness in the strong LL(*) parsing\n// strategy (versus full LL(*)).</p>\n//\n// <p>\n// When SLL yields a configuration set with conflict, we rewind the input and\n// retry the ATN simulation, this time using full outer context without adding\n// to the DFA. Configuration context stacks will be the full invocation stacks\n// from the start rule. If we get a conflict using full context, then we can\n// definitively say we have a true ambiguity for that input sequence. If we\n// don't get a conflict, it implies that the decision is sensitive to the outer\n// context. (It is not context-sensitive in the sense of context-sensitive\n// grammars.)</p>\n//\n// <p>\n// The next time we reach this DFA state with an SLL conflict, through DFA\n// simulation, we will again retry the ATN simulation using full context mode.\n// This is slow because we can't save the results and have to \"interpret\" the\n// ATN each time we get that input.</p>\n//\n// <p>\n// <strong>CACHING FULL CONTEXT PREDICTIONS</strong></p>\n//\n// <p>\n// We could cache results from full context to predicted alternative easily and\n// that saves a lot of time but doesn't work in presence of predicates. The set\n// of visible predicates from the ATN start state changes depending on the\n// context, because closure can fall off the end of a rule. I tried to cache\n// tuples (stack context, semantic context, predicted alt) but it was slower\n// than interpreting and much more complicated. Also required a huge amount of\n// memory. The goal is not to create the world's fastest parser anyway. I'd like\n// to keep this algorithm simple. By launching multiple threads, we can improve\n// the speed of parsing across a large number of files.</p>\n//\n// <p>\n// There is no strict ordering between the amount of input used by SLL vs LL,\n// which makes it really hard to build a cache for full context. Let's say that\n// we have input A B C that leads to an SLL conflict with full context X. That\n// implies that using X we might only use A B but we could also use A B C D to\n// resolve conflict. Input A B C D could predict alternative 1 in one position\n// in the input and A B C E could predict alternative 2 in another position in\n// input. The conflicting SLL configurations could still be non-unique in the\n// full context prediction, which would lead us to requiring more input than the\n// original A B C.\tTo make a\tprediction cache work, we have to track\tthe exact\n// input\tused during the previous prediction. That amounts to a cache that maps\n// X to a specific DFA for that context.</p>\n//\n// <p>\n// Something should be done for left-recursive expression predictions. They are\n// likely LL(1) + pred eval. Easier to do the whole SLL unless error and retry\n// with full LL thing Sam does.</p>\n//\n// <p>\n// <strong>AVOIDING FULL CONTEXT PREDICTION</strong></p>\n//\n// <p>\n// We avoid doing full context retry when the outer context is empty, we did not\n// dip into the outer context by falling off the end of the decision state rule,\n// or when we force SLL mode.</p>\n//\n// <p>\n// As an example of the not dip into outer context case, consider as super\n// constructor calls versus function calls. One grammar might look like\n// this:</p>\n//\n// <pre>\n// ctorBody\n//   : '{' superCall? stat* '}'\n//   ;\n// </pre>\n//\n// <p>\n// Or, you might see something like</p>\n//\n// <pre>\n// stat\n//   : superCall ';'\n//   | expression ';'\n//   | ...\n//   ;\n// </pre>\n//\n// <p>\n// In both cases I believe that no closure operations will dip into the outer\n// context. In the first case ctorBody in the worst case will stop at the '}'.\n// In the 2nd case it should stop at the ';'. Both cases should stay within the\n// entry rule and not dip into the outer context.</p>\n//\n// <p>\n// <strong>PREDICATES</strong></p>\n//\n// <p>\n// Predicates are always evaluated if present in either SLL or LL both. SLL and\n// LL simulation deals with predicates differently. SLL collects predicates as\n// it performs closure operations like ANTLR v3 did. It delays predicate\n// evaluation until it reaches and accept state. This allows us to cache the SLL\n// ATN simulation whereas, if we had evaluated predicates on-the-fly during\n// closure, the DFA state configuration sets would be different and we couldn't\n// build up a suitable DFA.</p>\n//\n// <p>\n// When building a DFA accept state during ATN simulation, we evaluate any\n// predicates and return the sole semantically valid alternative. If there is\n// more than 1 alternative, we report an ambiguity. If there are 0 alternatives,\n// we throw an exception. Alternatives without predicates act like they have\n// true predicates. The simple way to think about it is to strip away all\n// alternatives with false predicates and choose the minimum alternative that\n// remains.</p>\n//\n// <p>\n// When we start in the DFA and reach an accept state that's predicated, we test\n// those and return the minimum semantically viable alternative. If no\n// alternatives are viable, we throw an exception.</p>\n//\n// <p>\n// During full LL ATN simulation, closure always evaluates predicates and\n// on-the-fly. This is crucial to reducing the configuration set size during\n// closure. It hits a landmine when parsing with the Java grammar, for example,\n// without this on-the-fly evaluation.</p>\n//\n// <p>\n// <strong>SHARING DFA</strong></p>\n//\n// <p>\n// All instances of the same parser share the same decision DFAs through a\n// static field. Each instance gets its own ATN simulator but they share the\n// same {@link //decisionToDFA} field. They also share a\n// {@link PredictionContextCache} object that makes sure that all\n// {@link PredictionContext} objects are shared among the DFA states. This makes\n// a big size difference.</p>\n//\n// <p>\n// <strong>THREAD SAFETY</strong></p>\n//\n// <p>\n// The {@link ParserATNSimulator} locks on the {@link //decisionToDFA} field when\n// it adds a new DFA object to that array. {@link //addDFAEdge}\n// locks on the DFA for the current decision when setting the\n// {@link DFAState//edges} field. {@link //addDFAState} locks on\n// the DFA for the current decision when looking up a DFA state to see if it\n// already exists. We must make sure that all requests to add DFA states that\n// are equivalent result in the same shared DFA object. This is because lots of\n// threads will be trying to update the DFA at once. The\n// {@link //addDFAState} method also locks inside the DFA lock\n// but this time on the shared context cache when it rebuilds the\n// configurations' {@link PredictionContext} objects using cached\n// subgraphs/nodes. No other locking occurs, even during DFA simulation. This is\n// safe as long as we can guarantee that all threads referencing\n// {@code s.edge[t]} get the same physical target {@link DFAState}, or\n// {@code null}. Once into the DFA, the DFA simulation does not reference the\n// {@link DFA//states} map. It follows the {@link DFAState//edges} field to new\n// targets. The DFA simulator will either find {@link DFAState//edges} to be\n// {@code null}, to be non-{@code null} and {@code dfa.edges[t]} null, or\n// {@code dfa.edges[t]} to be non-null. The\n// {@link //addDFAEdge} method could be racing to set the field\n// but in either case the DFA simulator works; if {@code null}, and requests ATN\n// simulation. It could also race trying to get {@code dfa.edges[t]}, but either\n// way it will work because it's not doing a test and set operation.</p>\n//\n// <p>\n// <strong>Starting with SLL then failing to combined SLL/LL (Two-Stage\n// Parsing)</strong></p>\n//\n// <p>\n// Sam pointed out that if SLL does not give a syntax error, then there is no\n// point in doing full LL, which is slower. We only have to try LL if we get a\n// syntax error. For maximum speed, Sam starts the parser set to pure SLL\n// mode with the {@link BailErrorStrategy}:</p>\n//\n// <pre>\n// parser.{@link Parser//getInterpreter() getInterpreter()}.{@link //setPredictionMode setPredictionMode}{@code (}{@link PredictionMode//SLL}{@code )};\n// parser.{@link Parser//setErrorHandler setErrorHandler}(new {@link BailErrorStrategy}());\n// </pre>\n//\n// <p>\n// If it does not get a syntax error, then we're done. If it does get a syntax\n// error, we need to retry with the combined SLL/LL strategy.</p>\n//\n// <p>\n// The reason this works is as follows. If there are no SLL conflicts, then the\n// grammar is SLL (at least for that input set). If there is an SLL conflict,\n// the full LL analysis must yield a set of viable alternatives which is a\n// subset of the alternatives reported by SLL. If the LL set is a singleton,\n// then the grammar is LL but not SLL. If the LL set is the same size as the SLL\n// set, the decision is SLL. If the LL set has size &gt; 1, then that decision\n// is truly ambiguous on the current input. If the LL set is smaller, then the\n// SLL conflict resolution might choose an alternative that the full LL would\n// rule out as a possibility based upon better context information. If that's\n// the case, then the SLL parse will definitely get an error because the full LL\n// analysis says it's not viable. If SLL conflict resolution chooses an\n// alternative within the LL set, them both SLL and LL would choose the same\n// alternative because they both choose the minimum of multiple conflicting\n// alternatives.</p>\n//\n// <p>\n// Let's say we have a set of SLL conflicting alternatives {@code {1, 2, 3}} and\n// a smaller LL set called <em>s</em>. If <em>s</em> is {@code {2, 3}}, then SLL\n// parsing will get an error because SLL will pursue alternative 1. If\n// <em>s</em> is {@code {1, 2}} or {@code {1, 3}} then both SLL and LL will\n// choose the same alternative because alternative one is the minimum of either\n// set. If <em>s</em> is {@code {2}} or {@code {3}} then SLL will get a syntax\n// error. If <em>s</em> is {@code {1}} then SLL will succeed.</p>\n//\n// <p>\n// Of course, if the input is invalid, then we will get an error for sure in\n// both SLL and LL parsing. Erroneous input will therefore require 2 passes over\n// the input.</p>\n//\n\nvar Utils = __webpack_require__(/*! ./../Utils */ \"./antlr4/Utils.js\");\nvar Set = Utils.Set;\nvar BitSet = Utils.BitSet;\nvar DoubleDict = Utils.DoubleDict;\nvar ATN = __webpack_require__(/*! ./ATN */ \"./antlr4/atn/ATN.js\").ATN;\nvar ATNState = __webpack_require__(/*! ./ATNState */ \"./antlr4/atn/ATNState.js\").ATNState;\nvar ATNConfig = __webpack_require__(/*! ./ATNConfig */ \"./antlr4/atn/ATNConfig.js\").ATNConfig;\nvar ATNConfigSet = __webpack_require__(/*! ./ATNConfigSet */ \"./antlr4/atn/ATNConfigSet.js\").ATNConfigSet;\nvar Token = __webpack_require__(/*! ./../Token */ \"./antlr4/Token.js\").Token;\nvar DFAState = __webpack_require__(/*! ./../dfa/DFAState */ \"./antlr4/dfa/DFAState.js\").DFAState;\nvar PredPrediction = __webpack_require__(/*! ./../dfa/DFAState */ \"./antlr4/dfa/DFAState.js\").PredPrediction;\nvar ATNSimulator = __webpack_require__(/*! ./ATNSimulator */ \"./antlr4/atn/ATNSimulator.js\").ATNSimulator;\nvar PredictionMode = __webpack_require__(/*! ./PredictionMode */ \"./antlr4/atn/PredictionMode.js\").PredictionMode;\nvar RuleContext = __webpack_require__(/*! ./../RuleContext */ \"./antlr4/RuleContext.js\").RuleContext;\nvar ParserRuleContext = __webpack_require__(/*! ./../ParserRuleContext */ \"./antlr4/ParserRuleContext.js\").ParserRuleContext;\nvar SemanticContext = __webpack_require__(/*! ./SemanticContext */ \"./antlr4/atn/SemanticContext.js\").SemanticContext;\nvar StarLoopEntryState = __webpack_require__(/*! ./ATNState */ \"./antlr4/atn/ATNState.js\").StarLoopEntryState;\nvar RuleStopState = __webpack_require__(/*! ./ATNState */ \"./antlr4/atn/ATNState.js\").RuleStopState;\nvar PredictionContext = __webpack_require__(/*! ./../PredictionContext */ \"./antlr4/PredictionContext.js\").PredictionContext;\nvar Interval = __webpack_require__(/*! ./../IntervalSet */ \"./antlr4/IntervalSet.js\").Interval;\nvar Transitions = __webpack_require__(/*! ./Transition */ \"./antlr4/atn/Transition.js\");\nvar Transition = Transitions.Transition;\nvar SetTransition = Transitions.SetTransition;\nvar NotSetTransition = Transitions.NotSetTransition;\nvar RuleTransition = Transitions.RuleTransition;\nvar ActionTransition = Transitions.ActionTransition;\nvar NoViableAltException = __webpack_require__(/*! ./../error/Errors */ \"./antlr4/error/Errors.js\").NoViableAltException;\n\nvar SingletonPredictionContext = __webpack_require__(/*! ./../PredictionContext */ \"./antlr4/PredictionContext.js\").SingletonPredictionContext;\nvar predictionContextFromRuleContext = __webpack_require__(/*! ./../PredictionContext */ \"./antlr4/PredictionContext.js\").predictionContextFromRuleContext;\n\nfunction ParserATNSimulator(parser, atn, decisionToDFA, sharedContextCache) {\n\tATNSimulator.call(this, atn, sharedContextCache);\n    this.parser = parser;\n    this.decisionToDFA = decisionToDFA;\n    // SLL, LL, or LL + exact ambig detection?//\n    this.predictionMode = PredictionMode.LL;\n    // LAME globals to avoid parameters!!!!! I need these down deep in predTransition\n    this._input = null;\n    this._startIndex = 0;\n    this._outerContext = null;\n    this._dfa = null;\n    // Each prediction operation uses a cache for merge of prediction contexts.\n    //  Don't keep around as it wastes huge amounts of memory. DoubleKeyMap\n    //  isn't synchronized but we're ok since two threads shouldn't reuse same\n    //  parser/atnsim object because it can only handle one input at a time.\n    //  This maps graphs a and b to merged result c. (a,b)&rarr;c. We can avoid\n    //  the merge if we ever see a and b again.  Note that (b,a)&rarr;c should\n    //  also be examined during cache lookup.\n    //\n    this.mergeCache = null;\n    return this;\n}\n\nParserATNSimulator.prototype = Object.create(ATNSimulator.prototype);\nParserATNSimulator.prototype.constructor = ParserATNSimulator;\n\nParserATNSimulator.prototype.debug = false;\nParserATNSimulator.prototype.debug_closure = false;\nParserATNSimulator.prototype.debug_add = false;\nParserATNSimulator.prototype.debug_list_atn_decisions = false;\nParserATNSimulator.prototype.dfa_debug = false;\nParserATNSimulator.prototype.retry_debug = false;\n\n\nParserATNSimulator.prototype.reset = function() {\n};\n\nParserATNSimulator.prototype.adaptivePredict = function(input, decision, outerContext) {\n    if (this.debug || this.debug_list_atn_decisions) {\n        console.log(\"adaptivePredict decision \" + decision +\n                               \" exec LA(1)==\" + this.getLookaheadName(input) +\n                               \" line \" + input.LT(1).line + \":\" +\n                               input.LT(1).column);\n    }\n    this._input = input;\n    this._startIndex = input.index;\n    this._outerContext = outerContext;\n\n    var dfa = this.decisionToDFA[decision];\n    this._dfa = dfa;\n    var m = input.mark();\n    var index = input.index;\n\n    // Now we are certain to have a specific decision's DFA\n    // But, do we still need an initial state?\n    try {\n        var s0;\n        if (dfa.precedenceDfa) {\n            // the start state for a precedence DFA depends on the current\n            // parser precedence, and is provided by a DFA method.\n            s0 = dfa.getPrecedenceStartState(this.parser.getPrecedence());\n        } else {\n            // the start state for a \"regular\" DFA is just s0\n            s0 = dfa.s0;\n        }\n        if (s0===null) {\n            if (outerContext===null) {\n                outerContext = RuleContext.EMPTY;\n            }\n            if (this.debug || this.debug_list_atn_decisions) {\n                console.log(\"predictATN decision \" + dfa.decision +\n                                   \" exec LA(1)==\" + this.getLookaheadName(input) +\n                                   \", outerContext=\" + outerContext.toString(this.parser.ruleNames));\n            }\n\n            var fullCtx = false;\n            var s0_closure = this.computeStartState(dfa.atnStartState, RuleContext.EMPTY, fullCtx);\n\n            if( dfa.precedenceDfa) {\n                // If this is a precedence DFA, we use applyPrecedenceFilter\n                // to convert the computed start state to a precedence start\n                // state. We then use DFA.setPrecedenceStartState to set the\n                // appropriate start state for the precedence level rather\n                // than simply setting DFA.s0.\n                //\n                dfa.s0.configs = s0_closure; // not used for prediction but useful to know start configs anyway\n                s0_closure = this.applyPrecedenceFilter(s0_closure);\n                s0 = this.addDFAState(dfa, new DFAState(null, s0_closure));\n                dfa.setPrecedenceStartState(this.parser.getPrecedence(), s0);\n            } else {\n                s0 = this.addDFAState(dfa, new DFAState(null, s0_closure));\n                dfa.s0 = s0;\n            }\n        }\n        var alt = this.execATN(dfa, s0, input, index, outerContext);\n        if (this.debug) {\n            console.log(\"DFA after predictATN: \" + dfa.toString(this.parser.literalNames));\n        }\n        return alt;\n    } finally {\n        this._dfa = null;\n        this.mergeCache = null; // wack cache after each prediction\n        input.seek(index);\n        input.release(m);\n    }\n};\n// Performs ATN simulation to compute a predicted alternative based\n//  upon the remaining input, but also updates the DFA cache to avoid\n//  having to traverse the ATN again for the same input sequence.\n\n// There are some key conditions we're looking for after computing a new\n// set of ATN configs (proposed DFA state):\n      // if the set is empty, there is no viable alternative for current symbol\n      // does the state uniquely predict an alternative?\n      // does the state have a conflict that would prevent us from\n      //   putting it on the work list?\n\n// We also have some key operations to do:\n      // add an edge from previous DFA state to potentially new DFA state, D,\n      //   upon current symbol but only if adding to work list, which means in all\n      //   cases except no viable alternative (and possibly non-greedy decisions?)\n      // collecting predicates and adding semantic context to DFA accept states\n      // adding rule context to context-sensitive DFA accept states\n      // consuming an input symbol\n      // reporting a conflict\n      // reporting an ambiguity\n      // reporting a context sensitivity\n      // reporting insufficient predicates\n\n// cover these cases:\n//    dead end\n//    single alt\n//    single alt + preds\n//    conflict\n//    conflict + preds\n//\nParserATNSimulator.prototype.execATN = function(dfa, s0, input, startIndex, outerContext ) {\n    if (this.debug || this.debug_list_atn_decisions) {\n        console.log(\"execATN decision \" + dfa.decision +\n                \" exec LA(1)==\" + this.getLookaheadName(input) +\n                \" line \" + input.LT(1).line + \":\" + input.LT(1).column);\n    }\n    var alt;\n    var previousD = s0;\n\n    if (this.debug) {\n        console.log(\"s0 = \" + s0);\n    }\n    var t = input.LA(1);\n    while(true) { // while more work\n        var D = this.getExistingTargetState(previousD, t);\n        if(D===null) {\n            D = this.computeTargetState(dfa, previousD, t);\n        }\n        if(D===ATNSimulator.ERROR) {\n            // if any configs in previous dipped into outer context, that\n            // means that input up to t actually finished entry rule\n            // at least for SLL decision. Full LL doesn't dip into outer\n            // so don't need special case.\n            // We will get an error no matter what so delay until after\n            // decision; better error message. Also, no reachable target\n            // ATN states in SLL implies LL will also get nowhere.\n            // If conflict in states that dip out, choose min since we\n            // will get error no matter what.\n            var e = this.noViableAlt(input, outerContext, previousD.configs, startIndex);\n            input.seek(startIndex);\n            alt = this.getSynValidOrSemInvalidAltThatFinishedDecisionEntryRule(previousD.configs, outerContext);\n            if(alt!==ATN.INVALID_ALT_NUMBER) {\n                return alt;\n            } else {\n                throw e;\n            }\n        }\n        if(D.requiresFullContext && this.predictionMode !== PredictionMode.SLL) {\n            // IF PREDS, MIGHT RESOLVE TO SINGLE ALT => SLL (or syntax error)\n            var conflictingAlts = null;\n            if (D.predicates!==null) {\n                if (this.debug) {\n                    console.log(\"DFA state has preds in DFA sim LL failover\");\n                }\n                var conflictIndex = input.index;\n                if(conflictIndex !== startIndex) {\n                    input.seek(startIndex);\n                }\n                conflictingAlts = this.evalSemanticContext(D.predicates, outerContext, true);\n                if (conflictingAlts.length===1) {\n                    if(this.debug) {\n                        console.log(\"Full LL avoided\");\n                    }\n                    return conflictingAlts.minValue();\n                }\n                if (conflictIndex !== startIndex) {\n                    // restore the index so reporting the fallback to full\n                    // context occurs with the index at the correct spot\n                    input.seek(conflictIndex);\n                }\n            }\n            if (this.dfa_debug) {\n                console.log(\"ctx sensitive state \" + outerContext +\" in \" + D);\n            }\n            var fullCtx = true;\n            var s0_closure = this.computeStartState(dfa.atnStartState, outerContext, fullCtx);\n            this.reportAttemptingFullContext(dfa, conflictingAlts, D.configs, startIndex, input.index);\n            alt = this.execATNWithFullContext(dfa, D, s0_closure, input, startIndex, outerContext);\n            return alt;\n        }\n        if (D.isAcceptState) {\n            if (D.predicates===null) {\n                return D.prediction;\n            }\n            var stopIndex = input.index;\n            input.seek(startIndex);\n            var alts = this.evalSemanticContext(D.predicates, outerContext, true);\n            if (alts.length===0) {\n                throw this.noViableAlt(input, outerContext, D.configs, startIndex);\n            } else if (alts.length===1) {\n                return alts.minValue();\n            } else {\n                // report ambiguity after predicate evaluation to make sure the correct set of ambig alts is reported.\n                this.reportAmbiguity(dfa, D, startIndex, stopIndex, false, alts, D.configs);\n                return alts.minValue();\n            }\n        }\n        previousD = D;\n\n        if (t !== Token.EOF) {\n            input.consume();\n            t = input.LA(1);\n        }\n    }\n};\n//\n// Get an existing target state for an edge in the DFA. If the target state\n// for the edge has not yet been computed or is otherwise not available,\n// this method returns {@code null}.\n//\n// @param previousD The current DFA state\n// @param t The next input symbol\n// @return The existing target DFA state for the given input symbol\n// {@code t}, or {@code null} if the target state for this edge is not\n// already cached\n//\nParserATNSimulator.prototype.getExistingTargetState = function(previousD, t) {\n    var edges = previousD.edges;\n    if (edges===null) {\n        return null;\n    } else {\n        return edges[t + 1] || null;\n    }\n};\n//\n// Compute a target state for an edge in the DFA, and attempt to add the\n// computed state and corresponding edge to the DFA.\n//\n// @param dfa The DFA\n// @param previousD The current DFA state\n// @param t The next input symbol\n//\n// @return The computed target DFA state for the given input symbol\n// {@code t}. If {@code t} does not lead to a valid DFA state, this method\n// returns {@link //ERROR}.\n//\nParserATNSimulator.prototype.computeTargetState = function(dfa, previousD, t) {\n   var reach = this.computeReachSet(previousD.configs, t, false);\n    if(reach===null) {\n        this.addDFAEdge(dfa, previousD, t, ATNSimulator.ERROR);\n        return ATNSimulator.ERROR;\n    }\n    // create new target state; we'll add to DFA after it's complete\n    var D = new DFAState(null, reach);\n\n    var predictedAlt = this.getUniqueAlt(reach);\n\n    if (this.debug) {\n        var altSubSets = PredictionMode.getConflictingAltSubsets(reach);\n        console.log(\"SLL altSubSets=\" + Utils.arrayToString(altSubSets) +\n                    \", previous=\" + previousD.configs +\n                    \", configs=\" + reach +\n                    \", predict=\" + predictedAlt +\n                    \", allSubsetsConflict=\" +\n                    PredictionMode.allSubsetsConflict(altSubSets) + \", conflictingAlts=\" +\n                    this.getConflictingAlts(reach));\n    }\n    if (predictedAlt!==ATN.INVALID_ALT_NUMBER) {\n        // NO CONFLICT, UNIQUELY PREDICTED ALT\n        D.isAcceptState = true;\n        D.configs.uniqueAlt = predictedAlt;\n        D.prediction = predictedAlt;\n    } else if (PredictionMode.hasSLLConflictTerminatingPrediction(this.predictionMode, reach)) {\n        // MORE THAN ONE VIABLE ALTERNATIVE\n        D.configs.conflictingAlts = this.getConflictingAlts(reach);\n        D.requiresFullContext = true;\n        // in SLL-only mode, we will stop at this state and return the minimum alt\n        D.isAcceptState = true;\n        D.prediction = D.configs.conflictingAlts.minValue();\n    }\n    if (D.isAcceptState && D.configs.hasSemanticContext) {\n        this.predicateDFAState(D, this.atn.getDecisionState(dfa.decision));\n        if( D.predicates!==null) {\n            D.prediction = ATN.INVALID_ALT_NUMBER;\n        }\n    }\n    // all adds to dfa are done after we've created full D state\n    D = this.addDFAEdge(dfa, previousD, t, D);\n    return D;\n};\n\nParserATNSimulator.prototype.predicateDFAState = function(dfaState, decisionState) {\n    // We need to test all predicates, even in DFA states that\n    // uniquely predict alternative.\n    var nalts = decisionState.transitions.length;\n    // Update DFA so reach becomes accept state with (predicate,alt)\n    // pairs if preds found for conflicting alts\n    var altsToCollectPredsFrom = this.getConflictingAltsOrUniqueAlt(dfaState.configs);\n    var altToPred = this.getPredsForAmbigAlts(altsToCollectPredsFrom, dfaState.configs, nalts);\n    if (altToPred!==null) {\n        dfaState.predicates = this.getPredicatePredictions(altsToCollectPredsFrom, altToPred);\n        dfaState.prediction = ATN.INVALID_ALT_NUMBER; // make sure we use preds\n    } else {\n        // There are preds in configs but they might go away\n        // when OR'd together like {p}? || NONE == NONE. If neither\n        // alt has preds, resolve to min alt\n        dfaState.prediction = altsToCollectPredsFrom.minValue();\n    }\n};\n\n// comes back with reach.uniqueAlt set to a valid alt\nParserATNSimulator.prototype.execATNWithFullContext = function(dfa, D, // how far we got before failing over\n                                     s0,\n                                     input,\n                                     startIndex,\n                                     outerContext) {\n    if (this.debug || this.debug_list_atn_decisions) {\n        console.log(\"execATNWithFullContext \"+s0);\n    }\n    var fullCtx = true;\n    var foundExactAmbig = false;\n    var reach = null;\n    var previous = s0;\n    input.seek(startIndex);\n    var t = input.LA(1);\n    var predictedAlt = -1;\n    while (true) { // while more work\n        reach = this.computeReachSet(previous, t, fullCtx);\n        if (reach===null) {\n            // if any configs in previous dipped into outer context, that\n            // means that input up to t actually finished entry rule\n            // at least for LL decision. Full LL doesn't dip into outer\n            // so don't need special case.\n            // We will get an error no matter what so delay until after\n            // decision; better error message. Also, no reachable target\n            // ATN states in SLL implies LL will also get nowhere.\n            // If conflict in states that dip out, choose min since we\n            // will get error no matter what.\n            var e = this.noViableAlt(input, outerContext, previous, startIndex);\n            input.seek(startIndex);\n            var alt = this.getSynValidOrSemInvalidAltThatFinishedDecisionEntryRule(previous, outerContext);\n            if(alt!==ATN.INVALID_ALT_NUMBER) {\n                return alt;\n            } else {\n                throw e;\n            }\n        }\n        var altSubSets = PredictionMode.getConflictingAltSubsets(reach);\n        if(this.debug) {\n            console.log(\"LL altSubSets=\" + altSubSets + \", predict=\" +\n                  PredictionMode.getUniqueAlt(altSubSets) + \", resolvesToJustOneViableAlt=\" +\n                  PredictionMode.resolvesToJustOneViableAlt(altSubSets));\n        }\n        reach.uniqueAlt = this.getUniqueAlt(reach);\n        // unique prediction?\n        if(reach.uniqueAlt!==ATN.INVALID_ALT_NUMBER) {\n            predictedAlt = reach.uniqueAlt;\n            break;\n        } else if (this.predictionMode !== PredictionMode.LL_EXACT_AMBIG_DETECTION) {\n            predictedAlt = PredictionMode.resolvesToJustOneViableAlt(altSubSets);\n            if(predictedAlt !== ATN.INVALID_ALT_NUMBER) {\n                break;\n            }\n        } else {\n            // In exact ambiguity mode, we never try to terminate early.\n            // Just keeps scarfing until we know what the conflict is\n            if (PredictionMode.allSubsetsConflict(altSubSets) && PredictionMode.allSubsetsEqual(altSubSets)) {\n                foundExactAmbig = true;\n                predictedAlt = PredictionMode.getSingleViableAlt(altSubSets);\n                break;\n            }\n            // else there are multiple non-conflicting subsets or\n            // we're not sure what the ambiguity is yet.\n            // So, keep going.\n        }\n        previous = reach;\n        if( t !== Token.EOF) {\n            input.consume();\n            t = input.LA(1);\n        }\n    }\n    // If the configuration set uniquely predicts an alternative,\n    // without conflict, then we know that it's a full LL decision\n    // not SLL.\n    if (reach.uniqueAlt !== ATN.INVALID_ALT_NUMBER ) {\n        this.reportContextSensitivity(dfa, predictedAlt, reach, startIndex, input.index);\n        return predictedAlt;\n    }\n    // We do not check predicates here because we have checked them\n    // on-the-fly when doing full context prediction.\n\n    //\n    // In non-exact ambiguity detection mode, we might\tactually be able to\n    // detect an exact ambiguity, but I'm not going to spend the cycles\n    // needed to check. We only emit ambiguity warnings in exact ambiguity\n    // mode.\n    //\n    // For example, we might know that we have conflicting configurations.\n    // But, that does not mean that there is no way forward without a\n    // conflict. It's possible to have nonconflicting alt subsets as in:\n\n    // altSubSets=[{1, 2}, {1, 2}, {1}, {1, 2}]\n\n    // from\n    //\n    //    [(17,1,[5 $]), (13,1,[5 10 $]), (21,1,[5 10 $]), (11,1,[$]),\n    //     (13,2,[5 10 $]), (21,2,[5 10 $]), (11,2,[$])]\n    //\n    // In this case, (17,1,[5 $]) indicates there is some next sequence that\n    // would resolve this without conflict to alternative 1. Any other viable\n    // next sequence, however, is associated with a conflict.  We stop\n    // looking for input because no amount of further lookahead will alter\n    // the fact that we should predict alternative 1.  We just can't say for\n    // sure that there is an ambiguity without looking further.\n\n    this.reportAmbiguity(dfa, D, startIndex, input.index, foundExactAmbig, null, reach);\n\n    return predictedAlt;\n};\n\nParserATNSimulator.prototype.computeReachSet = function(closure, t, fullCtx) {\n    if (this.debug) {\n        console.log(\"in computeReachSet, starting closure: \" + closure);\n    }\n    if( this.mergeCache===null) {\n        this.mergeCache = new DoubleDict();\n    }\n    var intermediate = new ATNConfigSet(fullCtx);\n\n    // Configurations already in a rule stop state indicate reaching the end\n    // of the decision rule (local context) or end of the start rule (full\n    // context). Once reached, these configurations are never updated by a\n    // closure operation, so they are handled separately for the performance\n    // advantage of having a smaller intermediate set when calling closure.\n    //\n    // For full-context reach operations, separate handling is required to\n    // ensure that the alternative matching the longest overall sequence is\n    // chosen when multiple such configurations can match the input.\n\n    var skippedStopStates = null;\n\n    // First figure out where we can reach on input t\n    for (var i=0; i<closure.items.length;i++) {\n        var c = closure.items[i];\n        if(this.debug_add) {\n            console.log(\"testing \" + this.getTokenName(t) + \" at \" + c);\n        }\n        if (c.state instanceof RuleStopState) {\n            if (fullCtx || t === Token.EOF) {\n                if (skippedStopStates===null) {\n                    skippedStopStates = [];\n                }\n                skippedStopStates.push(c);\n                if(this.debug_add) {\n                    console.log(\"added \" + c + \" to skippedStopStates\");\n                }\n            }\n            continue;\n        }\n        for(var j=0;j<c.state.transitions.length;j++) {\n            var trans = c.state.transitions[j];\n            var target = this.getReachableTarget(trans, t);\n            if (target!==null) {\n                var cfg = new ATNConfig({state:target}, c);\n                intermediate.add(cfg, this.mergeCache);\n                if(this.debug_add) {\n                    console.log(\"added \" + cfg + \" to intermediate\");\n                }\n            }\n        }\n    }\n    // Now figure out where the reach operation can take us...\n    var reach = null;\n\n    // This block optimizes the reach operation for intermediate sets which\n    // trivially indicate a termination state for the overall\n    // adaptivePredict operation.\n    //\n    // The conditions assume that intermediate\n    // contains all configurations relevant to the reach set, but this\n    // condition is not true when one or more configurations have been\n    // withheld in skippedStopStates, or when the current symbol is EOF.\n    //\n    if (skippedStopStates===null && t!==Token.EOF) {\n        if (intermediate.items.length===1) {\n            // Don't pursue the closure if there is just one state.\n            // It can only have one alternative; just add to result\n            // Also don't pursue the closure if there is unique alternative\n            // among the configurations.\n            reach = intermediate;\n        } else if (this.getUniqueAlt(intermediate)!==ATN.INVALID_ALT_NUMBER) {\n            // Also don't pursue the closure if there is unique alternative\n            // among the configurations.\n            reach = intermediate;\n        }\n    }\n    // If the reach set could not be trivially determined, perform a closure\n    // operation on the intermediate set to compute its initial value.\n    //\n    if (reach===null) {\n        reach = new ATNConfigSet(fullCtx);\n        var closureBusy = new Set();\n        var treatEofAsEpsilon = t === Token.EOF;\n        for (var k=0; k<intermediate.items.length;k++) {\n            this.closure(intermediate.items[k], reach, closureBusy, false, fullCtx, treatEofAsEpsilon);\n        }\n    }\n    if (t === Token.EOF) {\n        // After consuming EOF no additional input is possible, so we are\n        // only interested in configurations which reached the end of the\n        // decision rule (local context) or end of the start rule (full\n        // context). Update reach to contain only these configurations. This\n        // handles both explicit EOF transitions in the grammar and implicit\n        // EOF transitions following the end of the decision or start rule.\n        //\n        // When reach==intermediate, no closure operation was performed. In\n        // this case, removeAllConfigsNotInRuleStopState needs to check for\n        // reachable rule stop states as well as configurations already in\n        // a rule stop state.\n        //\n        // This is handled before the configurations in skippedStopStates,\n        // because any configurations potentially added from that list are\n        // already guaranteed to meet this condition whether or not it's\n        // required.\n        //\n        reach = this.removeAllConfigsNotInRuleStopState(reach, reach === intermediate);\n    }\n    // If skippedStopStates!==null, then it contains at least one\n    // configuration. For full-context reach operations, these\n    // configurations reached the end of the start rule, in which case we\n    // only add them back to reach if no configuration during the current\n    // closure operation reached such a state. This ensures adaptivePredict\n    // chooses an alternative matching the longest overall sequence when\n    // multiple alternatives are viable.\n    //\n    if (skippedStopStates!==null && ( (! fullCtx) || (! PredictionMode.hasConfigInRuleStopState(reach)))) {\n        for (var l=0; l<skippedStopStates.length;l++) {\n            reach.add(skippedStopStates[l], this.mergeCache);\n        }\n    }\n    if (reach.items.length===0) {\n        return null;\n    } else {\n        return reach;\n    }\n};\n//\n// Return a configuration set containing only the configurations from\n// {@code configs} which are in a {@link RuleStopState}. If all\n// configurations in {@code configs} are already in a rule stop state, this\n// method simply returns {@code configs}.\n//\n// <p>When {@code lookToEndOfRule} is true, this method uses\n// {@link ATN//nextTokens} for each configuration in {@code configs} which is\n// not already in a rule stop state to see if a rule stop state is reachable\n// from the configuration via epsilon-only transitions.</p>\n//\n// @param configs the configuration set to update\n// @param lookToEndOfRule when true, this method checks for rule stop states\n// reachable by epsilon-only transitions from each configuration in\n// {@code configs}.\n//\n// @return {@code configs} if all configurations in {@code configs} are in a\n// rule stop state, otherwise return a new configuration set containing only\n// the configurations from {@code configs} which are in a rule stop state\n//\nParserATNSimulator.prototype.removeAllConfigsNotInRuleStopState = function(configs, lookToEndOfRule) {\n    if (PredictionMode.allConfigsInRuleStopStates(configs)) {\n        return configs;\n    }\n    var result = new ATNConfigSet(configs.fullCtx);\n    for(var i=0; i<configs.items.length;i++) {\n        var config = configs.items[i];\n        if (config.state instanceof RuleStopState) {\n            result.add(config, this.mergeCache);\n            continue;\n        }\n        if (lookToEndOfRule && config.state.epsilonOnlyTransitions) {\n            var nextTokens = this.atn.nextTokens(config.state);\n            if (nextTokens.contains(Token.EPSILON)) {\n                var endOfRuleState = this.atn.ruleToStopState[config.state.ruleIndex];\n                result.add(new ATNConfig({state:endOfRuleState}, config), this.mergeCache);\n            }\n        }\n    }\n    return result;\n};\n\nParserATNSimulator.prototype.computeStartState = function(p, ctx, fullCtx) {\n    // always at least the implicit call to start rule\n    var initialContext = predictionContextFromRuleContext(this.atn, ctx);\n    var configs = new ATNConfigSet(fullCtx);\n    for(var i=0;i<p.transitions.length;i++) {\n        var target = p.transitions[i].target;\n        var c = new ATNConfig({ state:target, alt:i+1, context:initialContext }, null);\n        var closureBusy = new Set();\n        this.closure(c, configs, closureBusy, true, fullCtx, false);\n    }\n    return configs;\n};\n\n//\n// This method transforms the start state computed by\n// {@link //computeStartState} to the special start state used by a\n// precedence DFA for a particular precedence value. The transformation\n// process applies the following changes to the start state's configuration\n// set.\n//\n// <ol>\n// <li>Evaluate the precedence predicates for each configuration using\n// {@link SemanticContext//evalPrecedence}.</li>\n// <li>Remove all configurations which predict an alternative greater than\n// 1, for which another configuration that predicts alternative 1 is in the\n// same ATN state with the same prediction context. This transformation is\n// valid for the following reasons:\n// <ul>\n// <li>The closure block cannot contain any epsilon transitions which bypass\n// the body of the closure, so all states reachable via alternative 1 are\n// part of the precedence alternatives of the transformed left-recursive\n// rule.</li>\n// <li>The \"primary\" portion of a left recursive rule cannot contain an\n// epsilon transition, so the only way an alternative other than 1 can exist\n// in a state that is also reachable via alternative 1 is by nesting calls\n// to the left-recursive rule, with the outer calls not being at the\n// preferred precedence level.</li>\n// </ul>\n// </li>\n// </ol>\n//\n// <p>\n// The prediction context must be considered by this filter to address\n// situations like the following.\n// </p>\n// <code>\n// <pre>\n// grammar TA;\n// prog: statement* EOF;\n// statement: letterA | statement letterA 'b' ;\n// letterA: 'a';\n// </pre>\n// </code>\n// <p>\n// If the above grammar, the ATN state immediately before the token\n// reference {@code 'a'} in {@code letterA} is reachable from the left edge\n// of both the primary and closure blocks of the left-recursive rule\n// {@code statement}. The prediction context associated with each of these\n// configurations distinguishes between them, and prevents the alternative\n// which stepped out to {@code prog} (and then back in to {@code statement}\n// from being eliminated by the filter.\n// </p>\n//\n// @param configs The configuration set computed by\n// {@link //computeStartState} as the start state for the DFA.\n// @return The transformed configuration set representing the start state\n// for a precedence DFA at a particular precedence level (determined by\n// calling {@link Parser//getPrecedence}).\n//\nParserATNSimulator.prototype.applyPrecedenceFilter = function(configs) {\n\tvar config;\n\tvar statesFromAlt1 = [];\n    var configSet = new ATNConfigSet(configs.fullCtx);\n    for(var i=0; i<configs.items.length; i++) {\n        config = configs.items[i];\n        // handle alt 1 first\n        if (config.alt !== 1) {\n            continue;\n        }\n        var updatedContext = config.semanticContext.evalPrecedence(this.parser, this._outerContext);\n        if (updatedContext===null) {\n            // the configuration was eliminated\n            continue;\n        }\n        statesFromAlt1[config.state.stateNumber] = config.context;\n        if (updatedContext !== config.semanticContext) {\n            configSet.add(new ATNConfig({semanticContext:updatedContext}, config), this.mergeCache);\n        } else {\n            configSet.add(config, this.mergeCache);\n        }\n    }\n    for(i=0; i<configs.items.length; i++) {\n        config = configs.items[i];\n        if (config.alt === 1) {\n            // already handled\n            continue;\n        }\n        // In the future, this elimination step could be updated to also\n        // filter the prediction context for alternatives predicting alt>1\n        // (basically a graph subtraction algorithm).\n\t\tif (!config.precedenceFilterSuppressed) {\n            var context = statesFromAlt1[config.state.stateNumber] || null;\n            if (context!==null && context.equals(config.context)) {\n                // eliminated\n                continue;\n            }\n\t\t}\n        configSet.add(config, this.mergeCache);\n    }\n    return configSet;\n};\n\nParserATNSimulator.prototype.getReachableTarget = function(trans, ttype) {\n    if (trans.matches(ttype, 0, this.atn.maxTokenType)) {\n        return trans.target;\n    } else {\n        return null;\n    }\n};\n\nParserATNSimulator.prototype.getPredsForAmbigAlts = function(ambigAlts, configs, nalts) {\n    // REACH=[1|1|[]|0:0, 1|2|[]|0:1]\n    // altToPred starts as an array of all null contexts. The entry at index i\n    // corresponds to alternative i. altToPred[i] may have one of three values:\n    //   1. null: no ATNConfig c is found such that c.alt==i\n    //   2. SemanticContext.NONE: At least one ATNConfig c exists such that\n    //      c.alt==i and c.semanticContext==SemanticContext.NONE. In other words,\n    //      alt i has at least one unpredicated config.\n    //   3. Non-NONE Semantic Context: There exists at least one, and for all\n    //      ATNConfig c such that c.alt==i, c.semanticContext!=SemanticContext.NONE.\n    //\n    // From this, it is clear that NONE||anything==NONE.\n    //\n    var altToPred = [];\n    for(var i=0;i<configs.items.length;i++) {\n        var c = configs.items[i];\n        if(ambigAlts.contains( c.alt )) {\n            altToPred[c.alt] = SemanticContext.orContext(altToPred[c.alt] || null, c.semanticContext);\n        }\n    }\n    var nPredAlts = 0;\n    for (i =1;i< nalts+1;i++) {\n        var pred = altToPred[i] || null;\n        if (pred===null) {\n            altToPred[i] = SemanticContext.NONE;\n        } else if (pred !== SemanticContext.NONE) {\n            nPredAlts += 1;\n        }\n    }\n    // nonambig alts are null in altToPred\n    if (nPredAlts===0) {\n        altToPred = null;\n    }\n    if (this.debug) {\n        console.log(\"getPredsForAmbigAlts result \" + Utils.arrayToString(altToPred));\n    }\n    return altToPred;\n};\n\nParserATNSimulator.prototype.getPredicatePredictions = function(ambigAlts, altToPred) {\n    var pairs = [];\n    var containsPredicate = false;\n    for (var i=1; i<altToPred.length;i++) {\n        var pred = altToPred[i];\n        // unpredicated is indicated by SemanticContext.NONE\n        if( ambigAlts!==null && ambigAlts.contains( i )) {\n            pairs.push(new PredPrediction(pred, i));\n        }\n        if (pred !== SemanticContext.NONE) {\n            containsPredicate = true;\n        }\n    }\n    if (! containsPredicate) {\n        return null;\n    }\n    return pairs;\n};\n\n//\n// This method is used to improve the localization of error messages by\n// choosing an alternative rather than throwing a\n// {@link NoViableAltException} in particular prediction scenarios where the\n// {@link //ERROR} state was reached during ATN simulation.\n//\n// <p>\n// The default implementation of this method uses the following\n// algorithm to identify an ATN configuration which successfully parsed the\n// decision entry rule. Choosing such an alternative ensures that the\n// {@link ParserRuleContext} returned by the calling rule will be complete\n// and valid, and the syntax error will be reported later at a more\n// localized location.</p>\n//\n// <ul>\n// <li>If a syntactically valid path or paths reach the end of the decision rule and\n// they are semantically valid if predicated, return the min associated alt.</li>\n// <li>Else, if a semantically invalid but syntactically valid path exist\n// or paths exist, return the minimum associated alt.\n// </li>\n// <li>Otherwise, return {@link ATN//INVALID_ALT_NUMBER}.</li>\n// </ul>\n//\n// <p>\n// In some scenarios, the algorithm described above could predict an\n// alternative which will result in a {@link FailedPredicateException} in\n// the parser. Specifically, this could occur if the <em>only</em> configuration\n// capable of successfully parsing to the end of the decision rule is\n// blocked by a semantic predicate. By choosing this alternative within\n// {@link //adaptivePredict} instead of throwing a\n// {@link NoViableAltException}, the resulting\n// {@link FailedPredicateException} in the parser will identify the specific\n// predicate which is preventing the parser from successfully parsing the\n// decision rule, which helps developers identify and correct logic errors\n// in semantic predicates.\n// </p>\n//\n// @param configs The ATN configurations which were valid immediately before\n// the {@link //ERROR} state was reached\n// @param outerContext The is the \\gamma_0 initial parser context from the paper\n// or the parser stack at the instant before prediction commences.\n//\n// @return The value to return from {@link //adaptivePredict}, or\n// {@link ATN//INVALID_ALT_NUMBER} if a suitable alternative was not\n// identified and {@link //adaptivePredict} should report an error instead.\n//\nParserATNSimulator.prototype.getSynValidOrSemInvalidAltThatFinishedDecisionEntryRule = function(configs, outerContext) {\n    var cfgs = this.splitAccordingToSemanticValidity(configs, outerContext);\n    var semValidConfigs = cfgs[0];\n    var semInvalidConfigs = cfgs[1];\n    var alt = this.getAltThatFinishedDecisionEntryRule(semValidConfigs);\n    if (alt!==ATN.INVALID_ALT_NUMBER) { // semantically/syntactically viable path exists\n        return alt;\n    }\n    // Is there a syntactically valid path with a failed pred?\n    if (semInvalidConfigs.items.length>0) {\n        alt = this.getAltThatFinishedDecisionEntryRule(semInvalidConfigs);\n        if (alt!==ATN.INVALID_ALT_NUMBER) { // syntactically viable path exists\n            return alt;\n        }\n    }\n    return ATN.INVALID_ALT_NUMBER;\n};\n\nParserATNSimulator.prototype.getAltThatFinishedDecisionEntryRule = function(configs) {\n    var alts = [];\n    for(var i=0;i<configs.items.length; i++) {\n        var c = configs.items[i];\n        if (c.reachesIntoOuterContext>0 || ((c.state instanceof RuleStopState) && c.context.hasEmptyPath())) {\n            if(alts.indexOf(c.alt)<0) {\n                alts.push(c.alt);\n            }\n        }\n    }\n    if (alts.length===0) {\n        return ATN.INVALID_ALT_NUMBER;\n    } else {\n        return Math.min.apply(null, alts);\n    }\n};\n// Walk the list of configurations and split them according to\n//  those that have preds evaluating to true/false.  If no pred, assume\n//  true pred and include in succeeded set.  Returns Pair of sets.\n//\n//  Create a new set so as not to alter the incoming parameter.\n//\n//  Assumption: the input stream has been restored to the starting point\n//  prediction, which is where predicates need to evaluate.\n//\nParserATNSimulator.prototype.splitAccordingToSemanticValidity = function( configs, outerContext) {\n    var succeeded = new ATNConfigSet(configs.fullCtx);\n    var failed = new ATNConfigSet(configs.fullCtx);\n    for(var i=0;i<configs.items.length; i++) {\n        var c = configs.items[i];\n        if (c.semanticContext !== SemanticContext.NONE) {\n            var predicateEvaluationResult = c.semanticContext.evaluate(this.parser, outerContext);\n            if (predicateEvaluationResult) {\n                succeeded.add(c);\n            } else {\n                failed.add(c);\n            }\n        } else {\n            succeeded.add(c);\n        }\n    }\n    return [succeeded, failed];\n};\n\n// Look through a list of predicate/alt pairs, returning alts for the\n//  pairs that win. A {@code NONE} predicate indicates an alt containing an\n//  unpredicated config which behaves as \"always true.\" If !complete\n//  then we stop at the first predicate that evaluates to true. This\n//  includes pairs with null predicates.\n//\nParserATNSimulator.prototype.evalSemanticContext = function(predPredictions, outerContext, complete) {\n    var predictions = new BitSet();\n    for(var i=0;i<predPredictions.length;i++) {\n    \tvar pair = predPredictions[i];\n        if (pair.pred === SemanticContext.NONE) {\n            predictions.add(pair.alt);\n            if (! complete) {\n                break;\n            }\n            continue;\n        }\n        var predicateEvaluationResult = pair.pred.evaluate(this.parser, outerContext);\n        if (this.debug || this.dfa_debug) {\n            console.log(\"eval pred \" + pair + \"=\" + predicateEvaluationResult);\n        }\n        if (predicateEvaluationResult) {\n            if (this.debug || this.dfa_debug) {\n                console.log(\"PREDICT \" + pair.alt);\n            }\n            predictions.add(pair.alt);\n            if (! complete) {\n                break;\n            }\n        }\n    }\n    return predictions;\n};\n\n// TODO: If we are doing predicates, there is no point in pursuing\n//     closure operations if we reach a DFA state that uniquely predicts\n//     alternative. We will not be caching that DFA state and it is a\n//     waste to pursue the closure. Might have to advance when we do\n//     ambig detection thought :(\n//\n\nParserATNSimulator.prototype.closure = function(config, configs, closureBusy, collectPredicates, fullCtx, treatEofAsEpsilon) {\n    var initialDepth = 0;\n    this.closureCheckingStopState(config, configs, closureBusy, collectPredicates,\n                             fullCtx, initialDepth, treatEofAsEpsilon);\n};\n\n\nParserATNSimulator.prototype.closureCheckingStopState = function(config, configs, closureBusy, collectPredicates, fullCtx, depth, treatEofAsEpsilon) {\n    if (this.debug || this.debug_closure) {\n        console.log(\"closure(\" + config.toString(this.parser,true) + \")\");\n        // console.log(\"configs(\" + configs.toString() + \")\");\n        if(config.reachesIntoOuterContext>50) {\n            throw \"problem\";\n        }\n    }\n    if (config.state instanceof RuleStopState) {\n        // We hit rule end. If we have context info, use it\n        // run thru all possible stack tops in ctx\n        if (! config.context.isEmpty()) {\n            for ( var i =0; i<config.context.length; i++) {\n                if (config.context.getReturnState(i) === PredictionContext.EMPTY_RETURN_STATE) {\n                    if (fullCtx) {\n                        configs.add(new ATNConfig({state:config.state, context:PredictionContext.EMPTY}, config), this.mergeCache);\n                        continue;\n                    } else {\n                        // we have no context info, just chase follow links (if greedy)\n                        if (this.debug) {\n                            console.log(\"FALLING off rule \" + this.getRuleName(config.state.ruleIndex));\n                        }\n                        this.closure_(config, configs, closureBusy, collectPredicates,\n                                 fullCtx, depth, treatEofAsEpsilon);\n                    }\n                    continue;\n                }\n                var returnState = this.atn.states[config.context.getReturnState(i)];\n                var newContext = config.context.getParent(i); // \"pop\" return state\n                var parms = {state:returnState, alt:config.alt, context:newContext, semanticContext:config.semanticContext};\n                var c = new ATNConfig(parms, null);\n                // While we have context to pop back from, we may have\n                // gotten that context AFTER having falling off a rule.\n                // Make sure we track that we are now out of context.\n                c.reachesIntoOuterContext = config.reachesIntoOuterContext;\n                this.closureCheckingStopState(c, configs, closureBusy, collectPredicates, fullCtx, depth - 1, treatEofAsEpsilon);\n            }\n            return;\n        } else if( fullCtx) {\n            // reached end of start rule\n            configs.add(config, this.mergeCache);\n            return;\n        } else {\n            // else if we have no context info, just chase follow links (if greedy)\n            if (this.debug) {\n                console.log(\"FALLING off rule \" + this.getRuleName(config.state.ruleIndex));\n            }\n        }\n    }\n    this.closure_(config, configs, closureBusy, collectPredicates, fullCtx, depth, treatEofAsEpsilon);\n};\n\n\n// Do the actual work of walking epsilon edges//\nParserATNSimulator.prototype.closure_ = function(config, configs, closureBusy, collectPredicates, fullCtx, depth, treatEofAsEpsilon) {\n    var p = config.state;\n    // optimization\n    if (! p.epsilonOnlyTransitions) {\n        configs.add(config, this.mergeCache);\n        // make sure to not return here, because EOF transitions can act as\n        // both epsilon transitions and non-epsilon transitions.\n    }\n    for(var i = 0;i<p.transitions.length; i++) {\n        if(i==0 && this.canDropLoopEntryEdgeInLeftRecursiveRule(config))\n            continue;\n\n        var t = p.transitions[i];\n        var continueCollecting = collectPredicates && !(t instanceof ActionTransition);\n        var c = this.getEpsilonTarget(config, t, continueCollecting, depth === 0, fullCtx, treatEofAsEpsilon);\n        if (c!==null) {\n\t\t\tif (!t.isEpsilon && closureBusy.add(c)!==c){\n\t\t\t\t// avoid infinite recursion for EOF* and EOF+\n\t\t\t\tcontinue;\n\t\t\t}\n            var newDepth = depth;\n            if ( config.state instanceof RuleStopState) {\n                // target fell off end of rule; mark resulting c as having dipped into outer context\n                // We can't get here if incoming config was rule stop and we had context\n                // track how far we dip into outer context.  Might\n                // come in handy and we avoid evaluating context dependent\n                // preds if this is > 0.\n\n                if (closureBusy.add(c)!==c) {\n                    // avoid infinite recursion for right-recursive rules\n                    continue;\n                }\n\n\t\t\t\tif (this._dfa !== null && this._dfa.precedenceDfa) {\n\t\t\t\t\tif (t.outermostPrecedenceReturn === this._dfa.atnStartState.ruleIndex) {\n\t\t\t\t\t\tc.precedenceFilterSuppressed = true;\n\t\t\t\t\t}\n\t\t\t\t}\n\n                c.reachesIntoOuterContext += 1;\n                configs.dipsIntoOuterContext = true; // TODO: can remove? only care when we add to set per middle of this method\n                newDepth -= 1;\n                if (this.debug) {\n                    console.log(\"dips into outer ctx: \" + c);\n                }\n            } else if (t instanceof RuleTransition) {\n                // latch when newDepth goes negative - once we step out of the entry context we can't return\n                if (newDepth >= 0) {\n                    newDepth += 1;\n                }\n            }\n            this.closureCheckingStopState(c, configs, closureBusy, continueCollecting, fullCtx, newDepth, treatEofAsEpsilon);\n        }\n    }\n};\n\n\nParserATNSimulator.prototype.canDropLoopEntryEdgeInLeftRecursiveRule = function(config) {\n    // return False\n    var p = config.state;\n    // First check to see if we are in StarLoopEntryState generated during\n    // left-recursion elimination. For efficiency, also check if\n    // the context has an empty stack case. If so, it would mean\n    // global FOLLOW so we can't perform optimization\n    // Are we the special loop entry/exit state? or SLL wildcard\n    if(p.stateType != ATNState.STAR_LOOP_ENTRY)\n        return false;\n    if(p.stateType != ATNState.STAR_LOOP_ENTRY || !p.isPrecedenceDecision ||\n           config.context.isEmpty() || config.context.hasEmptyPath())\n        return false;\n\n    // Require all return states to return back to the same rule that p is in.\n    var numCtxs = config.context.length;\n    for(var i=0; i<numCtxs; i++) { // for each stack context\n        var returnState = this.atn.states[config.context.getReturnState(i)];\n        if (returnState.ruleIndex != p.ruleIndex)\n            return false;\n    }\n\n    var decisionStartState = p.transitions[0].target;\n    var blockEndStateNum = decisionStartState.endState.stateNumber;\n    var blockEndState = this.atn.states[blockEndStateNum];\n\n    // Verify that the top of each stack context leads to loop entry/exit\n    // state through epsilon edges and w/o leaving rule.\n    for(var i=0; i<numCtxs; i++) { // for each stack context\n        var returnStateNumber = config.context.getReturnState(i);\n        var returnState = this.atn.states[returnStateNumber];\n        // all states must have single outgoing epsilon edge\n        if (returnState.transitions.length != 1 || !returnState.transitions[0].isEpsilon)\n            return false;\n\n        // Look for prefix op case like 'not expr', (' type ')' expr\n        var returnStateTarget = returnState.transitions[0].target;\n        if ( returnState.stateType == ATNState.BLOCK_END && returnStateTarget == p )\n            continue;\n\n        // Look for 'expr op expr' or case where expr's return state is block end\n        // of (...)* internal block; the block end points to loop back\n        // which points to p but we don't need to check that\n        if ( returnState == blockEndState )\n            continue;\n\n        // Look for ternary expr ? expr : expr. The return state points at block end,\n        // which points at loop entry state\n        if ( returnStateTarget == blockEndState )\n            continue;\n\n        // Look for complex prefix 'between expr and expr' case where 2nd expr's\n        // return state points at block end state of (...)* internal block\n        if (returnStateTarget.stateType == ATNState.BLOCK_END && returnStateTarget.transitions.length == 1\n                && returnStateTarget.transitions[0].isEpsilon && returnStateTarget.transitions[0].target == p)\n            continue;\n\n        // anything else ain't conforming\n        return false;\n    }\n    return true;\n};\n\n\nParserATNSimulator.prototype.getRuleName = function( index) {\n    if (this.parser!==null && index>=0) {\n        return this.parser.ruleNames[index];\n    } else {\n        return \"<rule \" + index + \">\";\n    }\n};\n\nParserATNSimulator.prototype.getEpsilonTarget = function(config, t, collectPredicates, inContext, fullCtx, treatEofAsEpsilon) {\n    switch(t.serializationType) {\n    case Transition.RULE:\n        return this.ruleTransition(config, t);\n    case Transition.PRECEDENCE:\n        return this.precedenceTransition(config, t, collectPredicates, inContext, fullCtx);\n    case Transition.PREDICATE:\n        return this.predTransition(config, t, collectPredicates, inContext, fullCtx);\n    case Transition.ACTION:\n        return this.actionTransition(config, t);\n    case Transition.EPSILON:\n        return new ATNConfig({state:t.target}, config);\n    case Transition.ATOM:\n    case Transition.RANGE:\n    case Transition.SET:\n        // EOF transitions act like epsilon transitions after the first EOF\n        // transition is traversed\n        if (treatEofAsEpsilon) {\n            if (t.matches(Token.EOF, 0, 1)) {\n                return new ATNConfig({state: t.target}, config);\n            }\n        }\n        return null;\n    default:\n    \treturn null;\n    }\n};\n\nParserATNSimulator.prototype.actionTransition = function(config, t) {\n    if (this.debug) {\n        var index = t.actionIndex==-1 ? 65535 : t.actionIndex;\n        console.log(\"ACTION edge \" + t.ruleIndex + \":\" + index);\n    }\n    return new ATNConfig({state:t.target}, config);\n};\n\nParserATNSimulator.prototype.precedenceTransition = function(config, pt,  collectPredicates, inContext, fullCtx) {\n    if (this.debug) {\n        console.log(\"PRED (collectPredicates=\" + collectPredicates + \") \" +\n                pt.precedence + \">=_p, ctx dependent=true\");\n        if (this.parser!==null) {\n        \tconsole.log(\"context surrounding pred is \" + Utils.arrayToString(this.parser.getRuleInvocationStack()));\n        }\n    }\n    var c = null;\n    if (collectPredicates && inContext) {\n        if (fullCtx) {\n            // In full context mode, we can evaluate predicates on-the-fly\n            // during closure, which dramatically reduces the size of\n            // the config sets. It also obviates the need to test predicates\n            // later during conflict resolution.\n            var currentPosition = this._input.index;\n            this._input.seek(this._startIndex);\n            var predSucceeds = pt.getPredicate().evaluate(this.parser, this._outerContext);\n            this._input.seek(currentPosition);\n            if (predSucceeds) {\n                c = new ATNConfig({state:pt.target}, config); // no pred context\n            }\n        } else {\n            var newSemCtx = SemanticContext.andContext(config.semanticContext, pt.getPredicate());\n            c = new ATNConfig({state:pt.target, semanticContext:newSemCtx}, config);\n        }\n    } else {\n        c = new ATNConfig({state:pt.target}, config);\n    }\n    if (this.debug) {\n        console.log(\"config from pred transition=\" + c);\n    }\n    return c;\n};\n\nParserATNSimulator.prototype.predTransition = function(config, pt, collectPredicates, inContext, fullCtx) {\n    if (this.debug) {\n        console.log(\"PRED (collectPredicates=\" + collectPredicates + \") \" + pt.ruleIndex +\n                \":\" + pt.predIndex + \", ctx dependent=\" + pt.isCtxDependent);\n        if (this.parser!==null) {\n            console.log(\"context surrounding pred is \" + Utils.arrayToString(this.parser.getRuleInvocationStack()));\n        }\n    }\n    var c = null;\n    if (collectPredicates && ((pt.isCtxDependent && inContext) || ! pt.isCtxDependent)) {\n        if (fullCtx) {\n            // In full context mode, we can evaluate predicates on-the-fly\n            // during closure, which dramatically reduces the size of\n            // the config sets. It also obviates the need to test predicates\n            // later during conflict resolution.\n            var currentPosition = this._input.index;\n            this._input.seek(this._startIndex);\n            var predSucceeds = pt.getPredicate().evaluate(this.parser, this._outerContext);\n            this._input.seek(currentPosition);\n            if (predSucceeds) {\n                c = new ATNConfig({state:pt.target}, config); // no pred context\n            }\n        } else {\n            var newSemCtx = SemanticContext.andContext(config.semanticContext, pt.getPredicate());\n            c = new ATNConfig({state:pt.target, semanticContext:newSemCtx}, config);\n        }\n    } else {\n        c = new ATNConfig({state:pt.target}, config);\n    }\n    if (this.debug) {\n        console.log(\"config from pred transition=\" + c);\n    }\n    return c;\n};\n\nParserATNSimulator.prototype.ruleTransition = function(config, t) {\n    if (this.debug) {\n        console.log(\"CALL rule \" + this.getRuleName(t.target.ruleIndex) + \", ctx=\" + config.context);\n    }\n    var returnState = t.followState;\n    var newContext = SingletonPredictionContext.create(config.context, returnState.stateNumber);\n    return new ATNConfig({state:t.target, context:newContext}, config );\n};\n\nParserATNSimulator.prototype.getConflictingAlts = function(configs) {\n    var altsets = PredictionMode.getConflictingAltSubsets(configs);\n    return PredictionMode.getAlts(altsets);\n};\n\n // Sam pointed out a problem with the previous definition, v3, of\n // ambiguous states. If we have another state associated with conflicting\n // alternatives, we should keep going. For example, the following grammar\n //\n // s : (ID | ID ID?) ';' ;\n //\n // When the ATN simulation reaches the state before ';', it has a DFA\n // state that looks like: [12|1|[], 6|2|[], 12|2|[]]. Naturally\n // 12|1|[] and 12|2|[] conflict, but we cannot stop processing this node\n // because alternative to has another way to continue, via [6|2|[]].\n // The key is that we have a single state that has config's only associated\n // with a single alternative, 2, and crucially the state transitions\n // among the configurations are all non-epsilon transitions. That means\n // we don't consider any conflicts that include alternative 2. So, we\n // ignore the conflict between alts 1 and 2. We ignore a set of\n // conflicting alts when there is an intersection with an alternative\n // associated with a single alt state in the state&rarr;config-list map.\n //\n // It's also the case that we might have two conflicting configurations but\n // also a 3rd nonconflicting configuration for a different alternative:\n // [1|1|[], 1|2|[], 8|3|[]]. This can come about from grammar:\n //\n // a : A | A | A B ;\n //\n // After matching input A, we reach the stop state for rule A, state 1.\n // State 8 is the state right before B. Clearly alternatives 1 and 2\n // conflict and no amount of further lookahead will separate the two.\n // However, alternative 3 will be able to continue and so we do not\n // stop working on this state. In the previous example, we're concerned\n // with states associated with the conflicting alternatives. Here alt\n // 3 is not associated with the conflicting configs, but since we can continue\n // looking for input reasonably, I don't declare the state done. We\n // ignore a set of conflicting alts when we have an alternative\n // that we still need to pursue.\n//\n\nParserATNSimulator.prototype.getConflictingAltsOrUniqueAlt = function(configs) {\n    var conflictingAlts = null;\n    if (configs.uniqueAlt!== ATN.INVALID_ALT_NUMBER) {\n        conflictingAlts = new BitSet();\n        conflictingAlts.add(configs.uniqueAlt);\n    } else {\n        conflictingAlts = configs.conflictingAlts;\n    }\n    return conflictingAlts;\n};\n\nParserATNSimulator.prototype.getTokenName = function( t) {\n    if (t===Token.EOF) {\n        return \"EOF\";\n    }\n    if( this.parser!==null && this.parser.literalNames!==null) {\n        if (t >= this.parser.literalNames.length && t >= this.parser.symbolicNames.length) {\n            console.log(\"\" + t + \" ttype out of range: \" + this.parser.literalNames);\n            console.log(\"\" + this.parser.getInputStream().getTokens());\n        } else {\n            var name = this.parser.literalNames[t] || this.parser.symbolicNames[t];\n            return name + \"<\" + t + \">\";\n        }\n    }\n    return \"\" + t;\n};\n\nParserATNSimulator.prototype.getLookaheadName = function(input) {\n    return this.getTokenName(input.LA(1));\n};\n\n// Used for debugging in adaptivePredict around execATN but I cut\n//  it out for clarity now that alg. works well. We can leave this\n//  \"dead\" code for a bit.\n//\nParserATNSimulator.prototype.dumpDeadEndConfigs = function(nvae) {\n    console.log(\"dead end configs: \");\n    var decs = nvae.getDeadEndConfigs();\n    for(var i=0; i<decs.length; i++) {\n    \tvar c = decs[i];\n        var trans = \"no edges\";\n        if (c.state.transitions.length>0) {\n            var t = c.state.transitions[0];\n            if (t instanceof AtomTransition) {\n                trans = \"Atom \"+ this.getTokenName(t.label);\n            } else if (t instanceof SetTransition) {\n                var neg = (t instanceof NotSetTransition);\n                trans = (neg ? \"~\" : \"\") + \"Set \" + t.set;\n            }\n        }\n        console.error(c.toString(this.parser, true) + \":\" + trans);\n    }\n};\n\nParserATNSimulator.prototype.noViableAlt = function(input, outerContext, configs, startIndex) {\n    return new NoViableAltException(this.parser, input, input.get(startIndex), input.LT(1), configs, outerContext);\n};\n\nParserATNSimulator.prototype.getUniqueAlt = function(configs) {\n    var alt = ATN.INVALID_ALT_NUMBER;\n    for(var i=0;i<configs.items.length;i++) {\n    \tvar c = configs.items[i];\n        if (alt === ATN.INVALID_ALT_NUMBER) {\n            alt = c.alt // found first alt\n        } else if( c.alt!==alt) {\n            return ATN.INVALID_ALT_NUMBER;\n        }\n    }\n    return alt;\n};\n\n//\n// Add an edge to the DFA, if possible. This method calls\n// {@link //addDFAState} to ensure the {@code to} state is present in the\n// DFA. If {@code from} is {@code null}, or if {@code t} is outside the\n// range of edges that can be represented in the DFA tables, this method\n// returns without adding the edge to the DFA.\n//\n// <p>If {@code to} is {@code null}, this method returns {@code null}.\n// Otherwise, this method returns the {@link DFAState} returned by calling\n// {@link //addDFAState} for the {@code to} state.</p>\n//\n// @param dfa The DFA\n// @param from The source state for the edge\n// @param t The input symbol\n// @param to The target state for the edge\n//\n// @return If {@code to} is {@code null}, this method returns {@code null};\n// otherwise this method returns the result of calling {@link //addDFAState}\n// on {@code to}\n//\nParserATNSimulator.prototype.addDFAEdge = function(dfa, from_, t, to) {\n    if( this.debug) {\n        console.log(\"EDGE \" + from_ + \" -> \" + to + \" upon \" + this.getTokenName(t));\n    }\n    if (to===null) {\n        return null;\n    }\n    to = this.addDFAState(dfa, to); // used existing if possible not incoming\n    if (from_===null || t < -1 || t > this.atn.maxTokenType) {\n        return to;\n    }\n    if (from_.edges===null) {\n        from_.edges = [];\n    }\n    from_.edges[t+1] = to; // connect\n\n    if (this.debug) {\n        var literalNames = this.parser===null ? null : this.parser.literalNames;\n        var symbolicNames = this.parser===null ? null : this.parser.symbolicNames;\n        console.log(\"DFA=\\n\" + dfa.toString(literalNames, symbolicNames));\n    }\n    return to;\n};\n//\n// Add state {@code D} to the DFA if it is not already present, and return\n// the actual instance stored in the DFA. If a state equivalent to {@code D}\n// is already in the DFA, the existing state is returned. Otherwise this\n// method returns {@code D} after adding it to the DFA.\n//\n// <p>If {@code D} is {@link //ERROR}, this method returns {@link //ERROR} and\n// does not change the DFA.</p>\n//\n// @param dfa The dfa\n// @param D The DFA state to add\n// @return The state stored in the DFA. This will be either the existing\n// state if {@code D} is already in the DFA, or {@code D} itself if the\n// state was not already present.\n//\nParserATNSimulator.prototype.addDFAState = function(dfa, D) {\n    if (D == ATNSimulator.ERROR) {\n        return D;\n    }\n    var existing = dfa.states.get(D);\n    if(existing!==null) {\n        return existing;\n    }\n    D.stateNumber = dfa.states.length;\n    if (! D.configs.readOnly) {\n        D.configs.optimizeConfigs(this);\n        D.configs.setReadonly(true);\n    }\n    dfa.states.add(D);\n    if (this.debug) {\n        console.log(\"adding new DFA state: \" + D);\n    }\n    return D;\n};\n\nParserATNSimulator.prototype.reportAttemptingFullContext = function(dfa, conflictingAlts, configs, startIndex, stopIndex) {\n    if (this.debug || this.retry_debug) {\n        var interval = new Interval(startIndex, stopIndex + 1);\n        console.log(\"reportAttemptingFullContext decision=\" + dfa.decision + \":\" + configs +\n                           \", input=\" + this.parser.getTokenStream().getText(interval));\n    }\n    if (this.parser!==null) {\n        this.parser.getErrorListenerDispatch().reportAttemptingFullContext(this.parser, dfa, startIndex, stopIndex, conflictingAlts, configs);\n    }\n};\n\nParserATNSimulator.prototype.reportContextSensitivity = function(dfa, prediction, configs, startIndex, stopIndex) {\n    if (this.debug || this.retry_debug) {\n        var interval = new Interval(startIndex, stopIndex + 1);\n        console.log(\"reportContextSensitivity decision=\" + dfa.decision + \":\" + configs +\n                           \", input=\" + this.parser.getTokenStream().getText(interval));\n    }\n    if (this.parser!==null) {\n        this.parser.getErrorListenerDispatch().reportContextSensitivity(this.parser, dfa, startIndex, stopIndex, prediction, configs);\n    }\n};\n\n// If context sensitive parsing, we know it's ambiguity not conflict//\nParserATNSimulator.prototype.reportAmbiguity = function(dfa, D, startIndex, stopIndex,\n                               exact, ambigAlts, configs ) {\n    if (this.debug || this.retry_debug) {\n        var interval = new Interval(startIndex, stopIndex + 1);\n        console.log(\"reportAmbiguity \" + ambigAlts + \":\" + configs +\n                           \", input=\" + this.parser.getTokenStream().getText(interval));\n    }\n    if (this.parser!==null) {\n        this.parser.getErrorListenerDispatch().reportAmbiguity(this.parser, dfa, startIndex, stopIndex, exact, ambigAlts, configs);\n    }\n};\n\nexports.ParserATNSimulator = ParserATNSimulator;\n\n//# sourceURL=webpack:///./antlr4/atn/ParserATNSimulator.js?");

/***/ }),

/***/ "./antlr4/atn/PredictionMode.js":
/*!**************************************!*\
  !*** ./antlr4/atn/PredictionMode.js ***!
  \**************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("//\n/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n//\n//\n// This enumeration defines the prediction modes available in ANTLR 4 along with\n// utility methods for analyzing configuration sets for conflicts and/or\n// ambiguities.\n\nvar Set = __webpack_require__(/*! ./../Utils */ \"./antlr4/Utils.js\").Set;\nvar Map = __webpack_require__(/*! ./../Utils */ \"./antlr4/Utils.js\").Map;\nvar BitSet = __webpack_require__(/*! ./../Utils */ \"./antlr4/Utils.js\").BitSet;\nvar AltDict = __webpack_require__(/*! ./../Utils */ \"./antlr4/Utils.js\").AltDict;\nvar ATN = __webpack_require__(/*! ./ATN */ \"./antlr4/atn/ATN.js\").ATN;\nvar RuleStopState = __webpack_require__(/*! ./ATNState */ \"./antlr4/atn/ATNState.js\").RuleStopState;\nvar ATNConfigSet = __webpack_require__(/*! ./ATNConfigSet */ \"./antlr4/atn/ATNConfigSet.js\").ATNConfigSet;\nvar ATNConfig = __webpack_require__(/*! ./ATNConfig */ \"./antlr4/atn/ATNConfig.js\").ATNConfig;\nvar SemanticContext = __webpack_require__(/*! ./SemanticContext */ \"./antlr4/atn/SemanticContext.js\").SemanticContext;\nvar Hash = __webpack_require__(/*! ../Utils */ \"./antlr4/Utils.js\").Hash;\nvar hashStuff = __webpack_require__(/*! ./../Utils */ \"./antlr4/Utils.js\").hashStuff;\nvar equalArrays = __webpack_require__(/*! ./../Utils */ \"./antlr4/Utils.js\").equalArrays;\n\nfunction PredictionMode() {\n\treturn this;\n}\n\n//\n// The SLL(*) prediction mode. This prediction mode ignores the current\n// parser context when making predictions. This is the fastest prediction\n// mode, and provides correct results for many grammars. This prediction\n// mode is more powerful than the prediction mode provided by ANTLR 3, but\n// may result in syntax errors for grammar and input combinations which are\n// not SLL.\n//\n// <p>\n// When using this prediction mode, the parser will either return a correct\n// parse tree (i.e. the same parse tree that would be returned with the\n// {@link //LL} prediction mode), or it will report a syntax error. If a\n// syntax error is encountered when using the {@link //SLL} prediction mode,\n// it may be due to either an actual syntax error in the input or indicate\n// that the particular combination of grammar and input requires the more\n// powerful {@link //LL} prediction abilities to complete successfully.</p>\n//\n// <p>\n// This prediction mode does not provide any guarantees for prediction\n// behavior for syntactically-incorrect inputs.</p>\n//\nPredictionMode.SLL = 0;\n//\n// The LL(*) prediction mode. This prediction mode allows the current parser\n// context to be used for resolving SLL conflicts that occur during\n// prediction. This is the fastest prediction mode that guarantees correct\n// parse results for all combinations of grammars with syntactically correct\n// inputs.\n//\n// <p>\n// When using this prediction mode, the parser will make correct decisions\n// for all syntactically-correct grammar and input combinations. However, in\n// cases where the grammar is truly ambiguous this prediction mode might not\n// report a precise answer for <em>exactly which</em> alternatives are\n// ambiguous.</p>\n//\n// <p>\n// This prediction mode does not provide any guarantees for prediction\n// behavior for syntactically-incorrect inputs.</p>\n//\nPredictionMode.LL = 1;\n//\n// The LL(*) prediction mode with exact ambiguity detection. In addition to\n// the correctness guarantees provided by the {@link //LL} prediction mode,\n// this prediction mode instructs the prediction algorithm to determine the\n// complete and exact set of ambiguous alternatives for every ambiguous\n// decision encountered while parsing.\n//\n// <p>\n// This prediction mode may be used for diagnosing ambiguities during\n// grammar development. Due to the performance overhead of calculating sets\n// of ambiguous alternatives, this prediction mode should be avoided when\n// the exact results are not necessary.</p>\n//\n// <p>\n// This prediction mode does not provide any guarantees for prediction\n// behavior for syntactically-incorrect inputs.</p>\n//\nPredictionMode.LL_EXACT_AMBIG_DETECTION = 2;\n\n\n//\n// Computes the SLL prediction termination condition.\n//\n// <p>\n// This method computes the SLL prediction termination condition for both of\n// the following cases.</p>\n//\n// <ul>\n// <li>The usual SLL+LL fallback upon SLL conflict</li>\n// <li>Pure SLL without LL fallback</li>\n// </ul>\n//\n// <p><strong>COMBINED SLL+LL PARSING</strong></p>\n//\n// <p>When LL-fallback is enabled upon SLL conflict, correct predictions are\n// ensured regardless of how the termination condition is computed by this\n// method. Due to the substantially higher cost of LL prediction, the\n// prediction should only fall back to LL when the additional lookahead\n// cannot lead to a unique SLL prediction.</p>\n//\n// <p>Assuming combined SLL+LL parsing, an SLL configuration set with only\n// conflicting subsets should fall back to full LL, even if the\n// configuration sets don't resolve to the same alternative (e.g.\n// {@code {1,2}} and {@code {3,4}}. If there is at least one non-conflicting\n// configuration, SLL could continue with the hopes that more lookahead will\n// resolve via one of those non-conflicting configurations.</p>\n//\n// <p>Here's the prediction termination rule them: SLL (for SLL+LL parsing)\n// stops when it sees only conflicting configuration subsets. In contrast,\n// full LL keeps going when there is uncertainty.</p>\n//\n// <p><strong>HEURISTIC</strong></p>\n//\n// <p>As a heuristic, we stop prediction when we see any conflicting subset\n// unless we see a state that only has one alternative associated with it.\n// The single-alt-state thing lets prediction continue upon rules like\n// (otherwise, it would admit defeat too soon):</p>\n//\n// <p>{@code [12|1|[], 6|2|[], 12|2|[]]. s : (ID | ID ID?) ';' ;}</p>\n//\n// <p>When the ATN simulation reaches the state before {@code ';'}, it has a\n// DFA state that looks like: {@code [12|1|[], 6|2|[], 12|2|[]]}. Naturally\n// {@code 12|1|[]} and {@code 12|2|[]} conflict, but we cannot stop\n// processing this node because alternative to has another way to continue,\n// via {@code [6|2|[]]}.</p>\n//\n// <p>It also let's us continue for this rule:</p>\n//\n// <p>{@code [1|1|[], 1|2|[], 8|3|[]] a : A | A | A B ;}</p>\n//\n// <p>After matching input A, we reach the stop state for rule A, state 1.\n// State 8 is the state right before B. Clearly alternatives 1 and 2\n// conflict and no amount of further lookahead will separate the two.\n// However, alternative 3 will be able to continue and so we do not stop\n// working on this state. In the previous example, we're concerned with\n// states associated with the conflicting alternatives. Here alt 3 is not\n// associated with the conflicting configs, but since we can continue\n// looking for input reasonably, don't declare the state done.</p>\n//\n// <p><strong>PURE SLL PARSING</strong></p>\n//\n// <p>To handle pure SLL parsing, all we have to do is make sure that we\n// combine stack contexts for configurations that differ only by semantic\n// predicate. From there, we can do the usual SLL termination heuristic.</p>\n//\n// <p><strong>PREDICATES IN SLL+LL PARSING</strong></p>\n//\n// <p>SLL decisions don't evaluate predicates until after they reach DFA stop\n// states because they need to create the DFA cache that works in all\n// semantic situations. In contrast, full LL evaluates predicates collected\n// during start state computation so it can ignore predicates thereafter.\n// This means that SLL termination detection can totally ignore semantic\n// predicates.</p>\n//\n// <p>Implementation-wise, {@link ATNConfigSet} combines stack contexts but not\n// semantic predicate contexts so we might see two configurations like the\n// following.</p>\n//\n// <p>{@code (s, 1, x, {}), (s, 1, x', {p})}</p>\n//\n// <p>Before testing these configurations against others, we have to merge\n// {@code x} and {@code x'} (without modifying the existing configurations).\n// For example, we test {@code (x+x')==x''} when looking for conflicts in\n// the following configurations.</p>\n//\n// <p>{@code (s, 1, x, {}), (s, 1, x', {p}), (s, 2, x'', {})}</p>\n//\n// <p>If the configuration set has predicates (as indicated by\n// {@link ATNConfigSet//hasSemanticContext}), this algorithm makes a copy of\n// the configurations to strip out all of the predicates so that a standard\n// {@link ATNConfigSet} will merge everything ignoring predicates.</p>\n//\nPredictionMode.hasSLLConflictTerminatingPrediction = function( mode, configs) {\n    // Configs in rule stop states indicate reaching the end of the decision\n    // rule (local context) or end of start rule (full context). If all\n    // configs meet this condition, then none of the configurations is able\n    // to match additional input so we terminate prediction.\n    //\n    if (PredictionMode.allConfigsInRuleStopStates(configs)) {\n        return true;\n    }\n    // pure SLL mode parsing\n    if (mode === PredictionMode.SLL) {\n        // Don't bother with combining configs from different semantic\n        // contexts if we can fail over to full LL; costs more time\n        // since we'll often fail over anyway.\n        if (configs.hasSemanticContext) {\n            // dup configs, tossing out semantic predicates\n            var dup = new ATNConfigSet();\n            for(var i=0;i<configs.items.length;i++) {\n            \tvar c = configs.items[i];\n                c = new ATNConfig({semanticContext:SemanticContext.NONE}, c);\n                dup.add(c);\n            }\n            configs = dup;\n        }\n        // now we have combined contexts for configs with dissimilar preds\n    }\n    // pure SLL or combined SLL+LL mode parsing\n    var altsets = PredictionMode.getConflictingAltSubsets(configs);\n    return PredictionMode.hasConflictingAltSet(altsets) && !PredictionMode.hasStateAssociatedWithOneAlt(configs);\n};\n\n// Checks if any configuration in {@code configs} is in a\n// {@link RuleStopState}. Configurations meeting this condition have reached\n// the end of the decision rule (local context) or end of start rule (full\n// context).\n//\n// @param configs the configuration set to test\n// @return {@code true} if any configuration in {@code configs} is in a\n// {@link RuleStopState}, otherwise {@code false}\nPredictionMode.hasConfigInRuleStopState = function(configs) {\n\tfor(var i=0;i<configs.items.length;i++) {\n\t\tvar c = configs.items[i];\n        if (c.state instanceof RuleStopState) {\n            return true;\n        }\n\t}\n    return false;\n};\n\n// Checks if all configurations in {@code configs} are in a\n// {@link RuleStopState}. Configurations meeting this condition have reached\n// the end of the decision rule (local context) or end of start rule (full\n// context).\n//\n// @param configs the configuration set to test\n// @return {@code true} if all configurations in {@code configs} are in a\n// {@link RuleStopState}, otherwise {@code false}\nPredictionMode.allConfigsInRuleStopStates = function(configs) {\n\tfor(var i=0;i<configs.items.length;i++) {\n\t\tvar c = configs.items[i];\n        if (!(c.state instanceof RuleStopState)) {\n            return false;\n        }\n\t}\n    return true;\n};\n\n//\n// Full LL prediction termination.\n//\n// <p>Can we stop looking ahead during ATN simulation or is there some\n// uncertainty as to which alternative we will ultimately pick, after\n// consuming more input? Even if there are partial conflicts, we might know\n// that everything is going to resolve to the same minimum alternative. That\n// means we can stop since no more lookahead will change that fact. On the\n// other hand, there might be multiple conflicts that resolve to different\n// minimums. That means we need more look ahead to decide which of those\n// alternatives we should predict.</p>\n//\n// <p>The basic idea is to split the set of configurations {@code C}, into\n// conflicting subsets {@code (s, _, ctx, _)} and singleton subsets with\n// non-conflicting configurations. Two configurations conflict if they have\n// identical {@link ATNConfig//state} and {@link ATNConfig//context} values\n// but different {@link ATNConfig//alt} value, e.g. {@code (s, i, ctx, _)}\n// and {@code (s, j, ctx, _)} for {@code i!=j}.</p>\n//\n// <p>Reduce these configuration subsets to the set of possible alternatives.\n// You can compute the alternative subsets in one pass as follows:</p>\n//\n// <p>{@code A_s,ctx = {i | (s, i, ctx, _)}} for each configuration in\n// {@code C} holding {@code s} and {@code ctx} fixed.</p>\n//\n// <p>Or in pseudo-code, for each configuration {@code c} in {@code C}:</p>\n//\n// <pre>\n// map[c] U= c.{@link ATNConfig//alt alt} // map hash/equals uses s and x, not\n// alt and not pred\n// </pre>\n//\n// <p>The values in {@code map} are the set of {@code A_s,ctx} sets.</p>\n//\n// <p>If {@code |A_s,ctx|=1} then there is no conflict associated with\n// {@code s} and {@code ctx}.</p>\n//\n// <p>Reduce the subsets to singletons by choosing a minimum of each subset. If\n// the union of these alternative subsets is a singleton, then no amount of\n// more lookahead will help us. We will always pick that alternative. If,\n// however, there is more than one alternative, then we are uncertain which\n// alternative to predict and must continue looking for resolution. We may\n// or may not discover an ambiguity in the future, even if there are no\n// conflicting subsets this round.</p>\n//\n// <p>The biggest sin is to terminate early because it means we've made a\n// decision but were uncertain as to the eventual outcome. We haven't used\n// enough lookahead. On the other hand, announcing a conflict too late is no\n// big deal; you will still have the conflict. It's just inefficient. It\n// might even look until the end of file.</p>\n//\n// <p>No special consideration for semantic predicates is required because\n// predicates are evaluated on-the-fly for full LL prediction, ensuring that\n// no configuration contains a semantic context during the termination\n// check.</p>\n//\n// <p><strong>CONFLICTING CONFIGS</strong></p>\n//\n// <p>Two configurations {@code (s, i, x)} and {@code (s, j, x')}, conflict\n// when {@code i!=j} but {@code x=x'}. Because we merge all\n// {@code (s, i, _)} configurations together, that means that there are at\n// most {@code n} configurations associated with state {@code s} for\n// {@code n} possible alternatives in the decision. The merged stacks\n// complicate the comparison of configuration contexts {@code x} and\n// {@code x'}. Sam checks to see if one is a subset of the other by calling\n// merge and checking to see if the merged result is either {@code x} or\n// {@code x'}. If the {@code x} associated with lowest alternative {@code i}\n// is the superset, then {@code i} is the only possible prediction since the\n// others resolve to {@code min(i)} as well. However, if {@code x} is\n// associated with {@code j>i} then at least one stack configuration for\n// {@code j} is not in conflict with alternative {@code i}. The algorithm\n// should keep going, looking for more lookahead due to the uncertainty.</p>\n//\n// <p>For simplicity, I'm doing a equality check between {@code x} and\n// {@code x'} that lets the algorithm continue to consume lookahead longer\n// than necessary. The reason I like the equality is of course the\n// simplicity but also because that is the test you need to detect the\n// alternatives that are actually in conflict.</p>\n//\n// <p><strong>CONTINUE/STOP RULE</strong></p>\n//\n// <p>Continue if union of resolved alternative sets from non-conflicting and\n// conflicting alternative subsets has more than one alternative. We are\n// uncertain about which alternative to predict.</p>\n//\n// <p>The complete set of alternatives, {@code [i for (_,i,_)]}, tells us which\n// alternatives are still in the running for the amount of input we've\n// consumed at this point. The conflicting sets let us to strip away\n// configurations that won't lead to more states because we resolve\n// conflicts to the configuration with a minimum alternate for the\n// conflicting set.</p>\n//\n// <p><strong>CASES</strong></p>\n//\n// <ul>\n//\n// <li>no conflicts and more than 1 alternative in set =&gt; continue</li>\n//\n// <li> {@code (s, 1, x)}, {@code (s, 2, x)}, {@code (s, 3, z)},\n// {@code (s', 1, y)}, {@code (s', 2, y)} yields non-conflicting set\n// {@code {3}} U conflicting sets {@code min({1,2})} U {@code min({1,2})} =\n// {@code {1,3}} =&gt; continue\n// </li>\n//\n// <li>{@code (s, 1, x)}, {@code (s, 2, x)}, {@code (s', 1, y)},\n// {@code (s', 2, y)}, {@code (s'', 1, z)} yields non-conflicting set\n// {@code {1}} U conflicting sets {@code min({1,2})} U {@code min({1,2})} =\n// {@code {1}} =&gt; stop and predict 1</li>\n//\n// <li>{@code (s, 1, x)}, {@code (s, 2, x)}, {@code (s', 1, y)},\n// {@code (s', 2, y)} yields conflicting, reduced sets {@code {1}} U\n// {@code {1}} = {@code {1}} =&gt; stop and predict 1, can announce\n// ambiguity {@code {1,2}}</li>\n//\n// <li>{@code (s, 1, x)}, {@code (s, 2, x)}, {@code (s', 2, y)},\n// {@code (s', 3, y)} yields conflicting, reduced sets {@code {1}} U\n// {@code {2}} = {@code {1,2}} =&gt; continue</li>\n//\n// <li>{@code (s, 1, x)}, {@code (s, 2, x)}, {@code (s', 3, y)},\n// {@code (s', 4, y)} yields conflicting, reduced sets {@code {1}} U\n// {@code {3}} = {@code {1,3}} =&gt; continue</li>\n//\n// </ul>\n//\n// <p><strong>EXACT AMBIGUITY DETECTION</strong></p>\n//\n// <p>If all states report the same conflicting set of alternatives, then we\n// know we have the exact ambiguity set.</p>\n//\n// <p><code>|A_<em>i</em>|&gt;1</code> and\n// <code>A_<em>i</em> = A_<em>j</em></code> for all <em>i</em>, <em>j</em>.</p>\n//\n// <p>In other words, we continue examining lookahead until all {@code A_i}\n// have more than one alternative and all {@code A_i} are the same. If\n// {@code A={{1,2}, {1,3}}}, then regular LL prediction would terminate\n// because the resolved set is {@code {1}}. To determine what the real\n// ambiguity is, we have to know whether the ambiguity is between one and\n// two or one and three so we keep going. We can only stop prediction when\n// we need exact ambiguity detection when the sets look like\n// {@code A={{1,2}}} or {@code {{1,2},{1,2}}}, etc...</p>\n//\nPredictionMode.resolvesToJustOneViableAlt = function(altsets) {\n    return PredictionMode.getSingleViableAlt(altsets);\n};\n\n//\n// Determines if every alternative subset in {@code altsets} contains more\n// than one alternative.\n//\n// @param altsets a collection of alternative subsets\n// @return {@code true} if every {@link BitSet} in {@code altsets} has\n// {@link BitSet//cardinality cardinality} &gt; 1, otherwise {@code false}\n//\nPredictionMode.allSubsetsConflict = function(altsets) {\n    return ! PredictionMode.hasNonConflictingAltSet(altsets);\n};\n//\n// Determines if any single alternative subset in {@code altsets} contains\n// exactly one alternative.\n//\n// @param altsets a collection of alternative subsets\n// @return {@code true} if {@code altsets} contains a {@link BitSet} with\n// {@link BitSet//cardinality cardinality} 1, otherwise {@code false}\n//\nPredictionMode.hasNonConflictingAltSet = function(altsets) {\n\tfor(var i=0;i<altsets.length;i++) {\n\t\tvar alts = altsets[i];\n        if (alts.length===1) {\n            return true;\n        }\n\t}\n    return false;\n};\n\n//\n// Determines if any single alternative subset in {@code altsets} contains\n// more than one alternative.\n//\n// @param altsets a collection of alternative subsets\n// @return {@code true} if {@code altsets} contains a {@link BitSet} with\n// {@link BitSet//cardinality cardinality} &gt; 1, otherwise {@code false}\n//\nPredictionMode.hasConflictingAltSet = function(altsets) {\n\tfor(var i=0;i<altsets.length;i++) {\n\t\tvar alts = altsets[i];\n        if (alts.length>1) {\n            return true;\n        }\n\t}\n    return false;\n};\n\n//\n// Determines if every alternative subset in {@code altsets} is equivalent.\n//\n// @param altsets a collection of alternative subsets\n// @return {@code true} if every member of {@code altsets} is equal to the\n// others, otherwise {@code false}\n//\nPredictionMode.allSubsetsEqual = function(altsets) {\n    var first = null;\n\tfor(var i=0;i<altsets.length;i++) {\n\t\tvar alts = altsets[i];\n        if (first === null) {\n            first = alts;\n        } else if (alts!==first) {\n            return false;\n        }\n\t}\n    return true;\n};\n\n//\n// Returns the unique alternative predicted by all alternative subsets in\n// {@code altsets}. If no such alternative exists, this method returns\n// {@link ATN//INVALID_ALT_NUMBER}.\n//\n// @param altsets a collection of alternative subsets\n//\nPredictionMode.getUniqueAlt = function(altsets) {\n    var all = PredictionMode.getAlts(altsets);\n    if (all.length===1) {\n        return all.minValue();\n    } else {\n        return ATN.INVALID_ALT_NUMBER;\n    }\n};\n\n// Gets the complete set of represented alternatives for a collection of\n// alternative subsets. This method returns the union of each {@link BitSet}\n// in {@code altsets}.\n//\n// @param altsets a collection of alternative subsets\n// @return the set of represented alternatives in {@code altsets}\n//\nPredictionMode.getAlts = function(altsets) {\n    var all = new BitSet();\n    altsets.map( function(alts) { all.or(alts); });\n    return all;\n};\n\n//\n// This function gets the conflicting alt subsets from a configuration set.\n// For each configuration {@code c} in {@code configs}:\n//\n// <pre>\n// map[c] U= c.{@link ATNConfig//alt alt} // map hash/equals uses s and x, not\n// alt and not pred\n// </pre>\n\nPredictionMode.getConflictingAltSubsets = function(configs) {\n    var configToAlts = new Map();\n    configToAlts.hashFunction = function(cfg) { hashStuff(cfg.state.stateNumber, cfg.context); };\n    configToAlts.equalsFunction = function(c1, c2) { return c1.state.stateNumber==c2.state.stateNumber && c1.context.equals(c2.context);}\n    configs.items.map(function(cfg) {\n        var alts = configToAlts.get(cfg);\n        if (alts === null) {\n            alts = new BitSet();\n            configToAlts.put(cfg, alts);\n        }\n        alts.add(cfg.alt);\n\t});\n    return configToAlts.getValues();\n};\n\n//\n// Get a map from state to alt subset from a configuration set. For each\n// configuration {@code c} in {@code configs}:\n//\n// <pre>\n// map[c.{@link ATNConfig//state state}] U= c.{@link ATNConfig//alt alt}\n// </pre>\n//\nPredictionMode.getStateToAltMap = function(configs) {\n    var m = new AltDict();\n    configs.items.map(function(c) {\n        var alts = m.get(c.state);\n        if (alts === null) {\n            alts = new BitSet();\n            m.put(c.state, alts);\n        }\n        alts.add(c.alt);\n    });\n    return m;\n};\n\nPredictionMode.hasStateAssociatedWithOneAlt = function(configs) {\n    var values = PredictionMode.getStateToAltMap(configs).values();\n    for(var i=0;i<values.length;i++) {\n        if (values[i].length===1) {\n            return true;\n        }\n    }\n    return false;\n};\n\nPredictionMode.getSingleViableAlt = function(altsets) {\n    var result = null;\n\tfor(var i=0;i<altsets.length;i++) {\n\t\tvar alts = altsets[i];\n        var minAlt = alts.minValue();\n        if(result===null) {\n            result = minAlt;\n        } else if(result!==minAlt) { // more than 1 viable alt\n            return ATN.INVALID_ALT_NUMBER;\n        }\n\t}\n    return result;\n};\n\nexports.PredictionMode = PredictionMode;\n\n\n//# sourceURL=webpack:///./antlr4/atn/PredictionMode.js?");

/***/ }),

/***/ "./antlr4/atn/SemanticContext.js":
/*!***************************************!*\
  !*** ./antlr4/atn/SemanticContext.js ***!
  \***************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("//\n/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n//\n\n// A tree structure used to record the semantic context in which\n//  an ATN configuration is valid.  It's either a single predicate,\n//  a conjunction {@code p1&&p2}, or a sum of products {@code p1||p2}.\n//\n//  <p>I have scoped the {@link AND}, {@link OR}, and {@link Predicate} subclasses of\n//  {@link SemanticContext} within the scope of this outer class.</p>\n//\n\nvar Set = __webpack_require__(/*! ./../Utils */ \"./antlr4/Utils.js\").Set;\nvar Hash = __webpack_require__(/*! ./../Utils */ \"./antlr4/Utils.js\").Hash;\n\nfunction SemanticContext() {\n\treturn this;\n}\n\nSemanticContext.prototype.hashCode = function() {\n    var hash = new Hash();\n    this.updateHashCode(hash);\n    return hash.finish();\n};\n\n// For context independent predicates, we evaluate them without a local\n// context (i.e., null context). That way, we can evaluate them without\n// having to create proper rule-specific context during prediction (as\n// opposed to the parser, which creates them naturally). In a practical\n// sense, this avoids a cast exception from RuleContext to myruleContext.\n//\n// <p>For context dependent predicates, we must pass in a local context so that\n// references such as $arg evaluate properly as _localctx.arg. We only\n// capture context dependent predicates in the context in which we begin\n// prediction, so we passed in the outer context here in case of context\n// dependent predicate evaluation.</p>\n//\nSemanticContext.prototype.evaluate = function(parser, outerContext) {\n};\n\n//\n// Evaluate the precedence predicates for the context and reduce the result.\n//\n// @param parser The parser instance.\n// @param outerContext The current parser context object.\n// @return The simplified semantic context after precedence predicates are\n// evaluated, which will be one of the following values.\n// <ul>\n// <li>{@link //NONE}: if the predicate simplifies to {@code true} after\n// precedence predicates are evaluated.</li>\n// <li>{@code null}: if the predicate simplifies to {@code false} after\n// precedence predicates are evaluated.</li>\n// <li>{@code this}: if the semantic context is not changed as a result of\n// precedence predicate evaluation.</li>\n// <li>A non-{@code null} {@link SemanticContext}: the new simplified\n// semantic context after precedence predicates are evaluated.</li>\n// </ul>\n//\nSemanticContext.prototype.evalPrecedence = function(parser, outerContext) {\n\treturn this;\n};\n\nSemanticContext.andContext = function(a, b) {\n\tif (a === null || a === SemanticContext.NONE) {\n\t\treturn b;\n\t}\n\tif (b === null || b === SemanticContext.NONE) {\n\t\treturn a;\n\t}\n\tvar result = new AND(a, b);\n\tif (result.opnds.length === 1) {\n\t\treturn result.opnds[0];\n\t} else {\n\t\treturn result;\n\t}\n};\n\nSemanticContext.orContext = function(a, b) {\n\tif (a === null) {\n\t\treturn b;\n\t}\n\tif (b === null) {\n\t\treturn a;\n\t}\n\tif (a === SemanticContext.NONE || b === SemanticContext.NONE) {\n\t\treturn SemanticContext.NONE;\n\t}\n\tvar result = new OR(a, b);\n\tif (result.opnds.length === 1) {\n\t\treturn result.opnds[0];\n\t} else {\n\t\treturn result;\n\t}\n};\n\nfunction Predicate(ruleIndex, predIndex, isCtxDependent) {\n\tSemanticContext.call(this);\n\tthis.ruleIndex = ruleIndex === undefined ? -1 : ruleIndex;\n\tthis.predIndex = predIndex === undefined ? -1 : predIndex;\n\tthis.isCtxDependent = isCtxDependent === undefined ? false : isCtxDependent; // e.g., $i ref in pred\n\treturn this;\n}\n\nPredicate.prototype = Object.create(SemanticContext.prototype);\nPredicate.prototype.constructor = Predicate;\n\n//The default {@link SemanticContext}, which is semantically equivalent to\n//a predicate of the form {@code {true}?}.\n//\nSemanticContext.NONE = new Predicate();\n\n\nPredicate.prototype.evaluate = function(parser, outerContext) {\n\tvar localctx = this.isCtxDependent ? outerContext : null;\n\treturn parser.sempred(localctx, this.ruleIndex, this.predIndex);\n};\n\nPredicate.prototype.updateHashCode = function(hash) {\n\thash.update(this.ruleIndex, this.predIndex, this.isCtxDependent);\n};\n\nPredicate.prototype.equals = function(other) {\n\tif (this === other) {\n\t\treturn true;\n\t} else if (!(other instanceof Predicate)) {\n\t\treturn false;\n\t} else {\n\t\treturn this.ruleIndex === other.ruleIndex &&\n\t\t\t\tthis.predIndex === other.predIndex &&\n\t\t\t\tthis.isCtxDependent === other.isCtxDependent;\n\t}\n};\n\nPredicate.prototype.toString = function() {\n\treturn \"{\" + this.ruleIndex + \":\" + this.predIndex + \"}?\";\n};\n\nfunction PrecedencePredicate(precedence) {\n\tSemanticContext.call(this);\n\tthis.precedence = precedence === undefined ? 0 : precedence;\n}\n\nPrecedencePredicate.prototype = Object.create(SemanticContext.prototype);\nPrecedencePredicate.prototype.constructor = PrecedencePredicate;\n\nPrecedencePredicate.prototype.evaluate = function(parser, outerContext) {\n\treturn parser.precpred(outerContext, this.precedence);\n};\n\nPrecedencePredicate.prototype.evalPrecedence = function(parser, outerContext) {\n\tif (parser.precpred(outerContext, this.precedence)) {\n\t\treturn SemanticContext.NONE;\n\t} else {\n\t\treturn null;\n\t}\n};\n\nPrecedencePredicate.prototype.compareTo = function(other) {\n\treturn this.precedence - other.precedence;\n};\n\nPrecedencePredicate.prototype.updateHashCode = function(hash) {\n    hash.update(31);\n};\n\nPrecedencePredicate.prototype.equals = function(other) {\n\tif (this === other) {\n\t\treturn true;\n\t} else if (!(other instanceof PrecedencePredicate)) {\n\t\treturn false;\n\t} else {\n\t\treturn this.precedence === other.precedence;\n\t}\n};\n\nPrecedencePredicate.prototype.toString = function() {\n\treturn \"{\"+this.precedence+\">=prec}?\";\n};\n\n\n\nPrecedencePredicate.filterPrecedencePredicates = function(set) {\n\tvar result = [];\n\tset.values().map( function(context) {\n\t\tif (context instanceof PrecedencePredicate) {\n\t\t\tresult.push(context);\n\t\t}\n\t});\n\treturn result;\n};\n\n\n// A semantic context which is true whenever none of the contained contexts\n// is false.\n//\nfunction AND(a, b) {\n\tSemanticContext.call(this);\n\tvar operands = new Set();\n\tif (a instanceof AND) {\n\t\ta.opnds.map(function(o) {\n\t\t\toperands.add(o);\n\t\t});\n\t} else {\n\t\toperands.add(a);\n\t}\n\tif (b instanceof AND) {\n\t\tb.opnds.map(function(o) {\n\t\t\toperands.add(o);\n\t\t});\n\t} else {\n\t\toperands.add(b);\n\t}\n\tvar precedencePredicates = PrecedencePredicate.filterPrecedencePredicates(operands);\n\tif (precedencePredicates.length > 0) {\n\t\t// interested in the transition with the lowest precedence\n\t\tvar reduced = null;\n\t\tprecedencePredicates.map( function(p) {\n\t\t\tif(reduced===null || p.precedence<reduced.precedence) {\n\t\t\t\treduced = p;\n\t\t\t}\n\t\t});\n\t\toperands.add(reduced);\n\t}\n\tthis.opnds = operands.values();\n\treturn this;\n}\n\nAND.prototype = Object.create(SemanticContext.prototype);\nAND.prototype.constructor = AND;\n\nAND.prototype.equals = function(other) {\n\tif (this === other) {\n\t\treturn true;\n\t} else if (!(other instanceof AND)) {\n\t\treturn false;\n\t} else {\n\t\treturn this.opnds === other.opnds;\n\t}\n};\n\nAND.prototype.updateHashCode = function(hash) {\n    hash.update(this.opnds, \"AND\");\n};\n//\n// {@inheritDoc}\n//\n// <p>\n// The evaluation of predicates by this context is short-circuiting, but\n// unordered.</p>\n//\nAND.prototype.evaluate = function(parser, outerContext) {\n\tfor (var i = 0; i < this.opnds.length; i++) {\n\t\tif (!this.opnds[i].evaluate(parser, outerContext)) {\n\t\t\treturn false;\n\t\t}\n\t}\n\treturn true;\n};\n\nAND.prototype.evalPrecedence = function(parser, outerContext) {\n\tvar differs = false;\n\tvar operands = [];\n\tfor (var i = 0; i < this.opnds.length; i++) {\n\t\tvar context = this.opnds[i];\n\t\tvar evaluated = context.evalPrecedence(parser, outerContext);\n\t\tdiffers |= (evaluated !== context);\n\t\tif (evaluated === null) {\n\t\t\t// The AND context is false if any element is false\n\t\t\treturn null;\n\t\t} else if (evaluated !== SemanticContext.NONE) {\n\t\t\t// Reduce the result by skipping true elements\n\t\t\toperands.push(evaluated);\n\t\t}\n\t}\n\tif (!differs) {\n\t\treturn this;\n\t}\n\tif (operands.length === 0) {\n\t\t// all elements were true, so the AND context is true\n\t\treturn SemanticContext.NONE;\n\t}\n\tvar result = null;\n\toperands.map(function(o) {\n\t\tresult = result === null ? o : SemanticContext.andContext(result, o);\n\t});\n\treturn result;\n};\n\nAND.prototype.toString = function() {\n\tvar s = \"\";\n\tthis.opnds.map(function(o) {\n\t\ts += \"&& \" + o.toString();\n\t});\n\treturn s.length > 3 ? s.slice(3) : s;\n};\n\n//\n// A semantic context which is true whenever at least one of the contained\n// contexts is true.\n//\nfunction OR(a, b) {\n\tSemanticContext.call(this);\n\tvar operands = new Set();\n\tif (a instanceof OR) {\n\t\ta.opnds.map(function(o) {\n\t\t\toperands.add(o);\n\t\t});\n\t} else {\n\t\toperands.add(a);\n\t}\n\tif (b instanceof OR) {\n\t\tb.opnds.map(function(o) {\n\t\t\toperands.add(o);\n\t\t});\n\t} else {\n\t\toperands.add(b);\n\t}\n\n\tvar precedencePredicates = PrecedencePredicate.filterPrecedencePredicates(operands);\n\tif (precedencePredicates.length > 0) {\n\t\t// interested in the transition with the highest precedence\n\t\tvar s = precedencePredicates.sort(function(a, b) {\n\t\t\treturn a.compareTo(b);\n\t\t});\n\t\tvar reduced = s[s.length-1];\n\t\toperands.add(reduced);\n\t}\n\tthis.opnds = operands.values();\n\treturn this;\n}\n\nOR.prototype = Object.create(SemanticContext.prototype);\nOR.prototype.constructor = OR;\n\nOR.prototype.constructor = function(other) {\n\tif (this === other) {\n\t\treturn true;\n\t} else if (!(other instanceof OR)) {\n\t\treturn false;\n\t} else {\n\t\treturn this.opnds === other.opnds;\n\t}\n};\n\nOR.prototype.updateHashCode = function(hash) {\n    hash.update(this.opnds, \"OR\");\n};\n\n// <p>\n// The evaluation of predicates by this context is short-circuiting, but\n// unordered.</p>\n//\nOR.prototype.evaluate = function(parser, outerContext) {\n\tfor (var i = 0; i < this.opnds.length; i++) {\n\t\tif (this.opnds[i].evaluate(parser, outerContext)) {\n\t\t\treturn true;\n\t\t}\n\t}\n\treturn false;\n};\n\nOR.prototype.evalPrecedence = function(parser, outerContext) {\n\tvar differs = false;\n\tvar operands = [];\n\tfor (var i = 0; i < this.opnds.length; i++) {\n\t\tvar context = this.opnds[i];\n\t\tvar evaluated = context.evalPrecedence(parser, outerContext);\n\t\tdiffers |= (evaluated !== context);\n\t\tif (evaluated === SemanticContext.NONE) {\n\t\t\t// The OR context is true if any element is true\n\t\t\treturn SemanticContext.NONE;\n\t\t} else if (evaluated !== null) {\n\t\t\t// Reduce the result by skipping false elements\n\t\t\toperands.push(evaluated);\n\t\t}\n\t}\n\tif (!differs) {\n\t\treturn this;\n\t}\n\tif (operands.length === 0) {\n\t\t// all elements were false, so the OR context is false\n\t\treturn null;\n\t}\n\tvar result = null;\n\toperands.map(function(o) {\n\t\treturn result === null ? o : SemanticContext.orContext(result, o);\n\t});\n\treturn result;\n};\n\nOR.prototype.toString = function() {\n\tvar s = \"\";\n\tthis.opnds.map(function(o) {\n\t\ts += \"|| \" + o.toString();\n\t});\n\treturn s.length > 3 ? s.slice(3) : s;\n};\n\nexports.SemanticContext = SemanticContext;\nexports.PrecedencePredicate = PrecedencePredicate;\nexports.Predicate = Predicate;\n\n\n//# sourceURL=webpack:///./antlr4/atn/SemanticContext.js?");

/***/ }),

/***/ "./antlr4/atn/Transition.js":
/*!**********************************!*\
  !*** ./antlr4/atn/Transition.js ***!
  \**********************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n//\n\n//  An ATN transition between any two ATN states.  Subclasses define\n//  atom, set, epsilon, action, predicate, rule transitions.\n//\n//  <p>This is a one way link.  It emanates from a state (usually via a list of\n//  transitions) and has a target state.</p>\n//\n//  <p>Since we never have to change the ATN transitions once we construct it,\n//  we can fix these transitions as specific classes. The DFA transitions\n//  on the other hand need to update the labels as it adds transitions to\n//  the states. We'll use the term Edge for the DFA to distinguish them from\n//  ATN transitions.</p>\n\nvar Token = __webpack_require__(/*! ./../Token */ \"./antlr4/Token.js\").Token;\nvar Interval = __webpack_require__(/*! ./../IntervalSet */ \"./antlr4/IntervalSet.js\").Interval;\nvar IntervalSet = __webpack_require__(/*! ./../IntervalSet */ \"./antlr4/IntervalSet.js\").IntervalSet;\nvar Predicate = __webpack_require__(/*! ./SemanticContext */ \"./antlr4/atn/SemanticContext.js\").Predicate;\nvar PrecedencePredicate = __webpack_require__(/*! ./SemanticContext */ \"./antlr4/atn/SemanticContext.js\").PrecedencePredicate;\n\nfunction Transition (target) {\n    // The target of this transition.\n    if (target===undefined || target===null) {\n        throw \"target cannot be null.\";\n    }\n    this.target = target;\n    // Are we epsilon, action, sempred?\n    this.isEpsilon = false;\n    this.label = null;\n    return this;\n}\n    // constants for serialization\nTransition.EPSILON = 1;\nTransition.RANGE = 2;\nTransition.RULE = 3;\nTransition.PREDICATE = 4; // e.g., {isType(input.LT(1))}?\nTransition.ATOM = 5;\nTransition.ACTION = 6;\nTransition.SET = 7; // ~(A|B) or ~atom, wildcard, which convert to next 2\nTransition.NOT_SET = 8;\nTransition.WILDCARD = 9;\nTransition.PRECEDENCE = 10;\n\nTransition.serializationNames = [\n            \"INVALID\",\n            \"EPSILON\",\n            \"RANGE\",\n            \"RULE\",\n            \"PREDICATE\",\n            \"ATOM\",\n            \"ACTION\",\n            \"SET\",\n            \"NOT_SET\",\n            \"WILDCARD\",\n            \"PRECEDENCE\"\n        ];\n\nTransition.serializationTypes = {\n        EpsilonTransition: Transition.EPSILON,\n        RangeTransition: Transition.RANGE,\n        RuleTransition: Transition.RULE,\n        PredicateTransition: Transition.PREDICATE,\n        AtomTransition: Transition.ATOM,\n        ActionTransition: Transition.ACTION,\n        SetTransition: Transition.SET,\n        NotSetTransition: Transition.NOT_SET,\n        WildcardTransition: Transition.WILDCARD,\n        PrecedencePredicateTransition: Transition.PRECEDENCE\n    };\n\n\n// TODO: make all transitions sets? no, should remove set edges\nfunction AtomTransition(target, label) {\n\tTransition.call(this, target);\n\tthis.label_ = label; // The token type or character value; or, signifies special label.\n    this.label = this.makeLabel();\n    this.serializationType = Transition.ATOM;\n    return this;\n}\n\nAtomTransition.prototype = Object.create(Transition.prototype);\nAtomTransition.prototype.constructor = AtomTransition;\n\nAtomTransition.prototype.makeLabel = function() {\n\tvar s = new IntervalSet();\n    s.addOne(this.label_);\n    return s;\n};\n\nAtomTransition.prototype.matches = function( symbol, minVocabSymbol,  maxVocabSymbol) {\n    return this.label_ === symbol;\n};\n\nAtomTransition.prototype.toString = function() {\n\treturn this.label_;\n};\n\nfunction RuleTransition(ruleStart, ruleIndex, precedence, followState) {\n\tTransition.call(this, ruleStart);\n    this.ruleIndex = ruleIndex; // ptr to the rule definition object for this rule ref\n    this.precedence = precedence;\n    this.followState = followState; // what node to begin computations following ref to rule\n    this.serializationType = Transition.RULE;\n    this.isEpsilon = true;\n    return this;\n}\n\nRuleTransition.prototype = Object.create(Transition.prototype);\nRuleTransition.prototype.constructor = RuleTransition;\n\nRuleTransition.prototype.matches = function(symbol, minVocabSymbol,  maxVocabSymbol) {\n\treturn false;\n};\n\n\nfunction EpsilonTransition(target, outermostPrecedenceReturn) {\n\tTransition.call(this, target);\n    this.serializationType = Transition.EPSILON;\n    this.isEpsilon = true;\n    this.outermostPrecedenceReturn = outermostPrecedenceReturn;\n    return this;\n}\n\nEpsilonTransition.prototype = Object.create(Transition.prototype);\nEpsilonTransition.prototype.constructor = EpsilonTransition;\n\nEpsilonTransition.prototype.matches = function( symbol, minVocabSymbol,  maxVocabSymbol) {\n\treturn false;\n};\n\nEpsilonTransition.prototype.toString = function() {\n\treturn \"epsilon\";\n};\n\nfunction RangeTransition(target, start, stop) {\n\tTransition.call(this, target);\n\tthis.serializationType = Transition.RANGE;\n    this.start = start;\n    this.stop = stop;\n    this.label = this.makeLabel();\n    return this;\n}\n\nRangeTransition.prototype = Object.create(Transition.prototype);\nRangeTransition.prototype.constructor = RangeTransition;\n\nRangeTransition.prototype.makeLabel = function() {\n    var s = new IntervalSet();\n    s.addRange(this.start, this.stop);\n    return s;\n};\n\nRangeTransition.prototype.matches = function(symbol, minVocabSymbol,  maxVocabSymbol) {\n\treturn symbol >= this.start && symbol <= this.stop;\n};\n\nRangeTransition.prototype.toString = function() {\n\treturn \"'\" + String.fromCharCode(this.start) + \"'..'\" + String.fromCharCode(this.stop) + \"'\";\n};\n\nfunction AbstractPredicateTransition(target) {\n\tTransition.call(this, target);\n\treturn this;\n}\n\nAbstractPredicateTransition.prototype = Object.create(Transition.prototype);\nAbstractPredicateTransition.prototype.constructor = AbstractPredicateTransition;\n\nfunction PredicateTransition(target, ruleIndex, predIndex, isCtxDependent) {\n\tAbstractPredicateTransition.call(this, target);\n    this.serializationType = Transition.PREDICATE;\n    this.ruleIndex = ruleIndex;\n    this.predIndex = predIndex;\n    this.isCtxDependent = isCtxDependent; // e.g., $i ref in pred\n    this.isEpsilon = true;\n    return this;\n}\n\nPredicateTransition.prototype = Object.create(AbstractPredicateTransition.prototype);\nPredicateTransition.prototype.constructor = PredicateTransition;\n\nPredicateTransition.prototype.matches = function(symbol, minVocabSymbol,  maxVocabSymbol) {\n\treturn false;\n};\n\nPredicateTransition.prototype.getPredicate = function() {\n\treturn new Predicate(this.ruleIndex, this.predIndex, this.isCtxDependent);\n};\n\nPredicateTransition.prototype.toString = function() {\n\treturn \"pred_\" + this.ruleIndex + \":\" + this.predIndex;\n};\n\nfunction ActionTransition(target, ruleIndex, actionIndex, isCtxDependent) {\n\tTransition.call(this, target);\n    this.serializationType = Transition.ACTION;\n    this.ruleIndex = ruleIndex;\n    this.actionIndex = actionIndex===undefined ? -1 : actionIndex;\n    this.isCtxDependent = isCtxDependent===undefined ? false : isCtxDependent; // e.g., $i ref in pred\n    this.isEpsilon = true;\n    return this;\n}\n\nActionTransition.prototype = Object.create(Transition.prototype);\nActionTransition.prototype.constructor = ActionTransition;\n\n\nActionTransition.prototype.matches = function(symbol, minVocabSymbol,  maxVocabSymbol) {\n\treturn false;\n};\n\nActionTransition.prototype.toString = function() {\n\treturn \"action_\" + this.ruleIndex + \":\" + this.actionIndex;\n};\n\n\n// A transition containing a set of values.\nfunction SetTransition(target, set) {\n\tTransition.call(this, target);\n\tthis.serializationType = Transition.SET;\n    if (set !==undefined && set !==null) {\n        this.label = set;\n    } else {\n        this.label = new IntervalSet();\n        this.label.addOne(Token.INVALID_TYPE);\n    }\n    return this;\n}\n\nSetTransition.prototype = Object.create(Transition.prototype);\nSetTransition.prototype.constructor = SetTransition;\n\nSetTransition.prototype.matches = function(symbol, minVocabSymbol,  maxVocabSymbol) {\n\treturn this.label.contains(symbol);\n};\n\n\nSetTransition.prototype.toString = function() {\n\treturn this.label.toString();\n};\n\nfunction NotSetTransition(target, set) {\n\tSetTransition.call(this, target, set);\n\tthis.serializationType = Transition.NOT_SET;\n\treturn this;\n}\n\nNotSetTransition.prototype = Object.create(SetTransition.prototype);\nNotSetTransition.prototype.constructor = NotSetTransition;\n\nNotSetTransition.prototype.matches = function(symbol, minVocabSymbol,  maxVocabSymbol) {\n\treturn symbol >= minVocabSymbol && symbol <= maxVocabSymbol &&\n\t\t\t!SetTransition.prototype.matches.call(this, symbol, minVocabSymbol, maxVocabSymbol);\n};\n\nNotSetTransition.prototype.toString = function() {\n\treturn '~' + SetTransition.prototype.toString.call(this);\n};\n\nfunction WildcardTransition(target) {\n\tTransition.call(this, target);\n\tthis.serializationType = Transition.WILDCARD;\n\treturn this;\n}\n\nWildcardTransition.prototype = Object.create(Transition.prototype);\nWildcardTransition.prototype.constructor = WildcardTransition;\n\n\nWildcardTransition.prototype.matches = function(symbol, minVocabSymbol,  maxVocabSymbol) {\n\treturn symbol >= minVocabSymbol && symbol <= maxVocabSymbol;\n};\n\nWildcardTransition.prototype.toString = function() {\n\treturn \".\";\n};\n\nfunction PrecedencePredicateTransition(target, precedence) {\n\tAbstractPredicateTransition.call(this, target);\n    this.serializationType = Transition.PRECEDENCE;\n    this.precedence = precedence;\n    this.isEpsilon = true;\n    return this;\n}\n\nPrecedencePredicateTransition.prototype = Object.create(AbstractPredicateTransition.prototype);\nPrecedencePredicateTransition.prototype.constructor = PrecedencePredicateTransition;\n\nPrecedencePredicateTransition.prototype.matches = function(symbol, minVocabSymbol,  maxVocabSymbol) {\n\treturn false;\n};\n\nPrecedencePredicateTransition.prototype.getPredicate = function() {\n\treturn new PrecedencePredicate(this.precedence);\n};\n\nPrecedencePredicateTransition.prototype.toString = function() {\n\treturn this.precedence + \" >= _p\";\n};\n\nexports.Transition = Transition;\nexports.AtomTransition = AtomTransition;\nexports.SetTransition = SetTransition;\nexports.NotSetTransition = NotSetTransition;\nexports.RuleTransition = RuleTransition;\nexports.ActionTransition = ActionTransition;\nexports.EpsilonTransition = EpsilonTransition;\nexports.RangeTransition = RangeTransition;\nexports.WildcardTransition = WildcardTransition;\nexports.PredicateTransition = PredicateTransition;\nexports.PrecedencePredicateTransition = PrecedencePredicateTransition;\nexports.AbstractPredicateTransition = AbstractPredicateTransition;\n\n//# sourceURL=webpack:///./antlr4/atn/Transition.js?");

/***/ }),

/***/ "./antlr4/atn/index.js":
/*!*****************************!*\
  !*** ./antlr4/atn/index.js ***!
  \*****************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nexports.ATN = __webpack_require__(/*! ./ATN */ \"./antlr4/atn/ATN.js\").ATN;\nexports.ATNDeserializer = __webpack_require__(/*! ./ATNDeserializer */ \"./antlr4/atn/ATNDeserializer.js\").ATNDeserializer;\nexports.LexerATNSimulator = __webpack_require__(/*! ./LexerATNSimulator */ \"./antlr4/atn/LexerATNSimulator.js\").LexerATNSimulator;\nexports.ParserATNSimulator = __webpack_require__(/*! ./ParserATNSimulator */ \"./antlr4/atn/ParserATNSimulator.js\").ParserATNSimulator;\nexports.PredictionMode = __webpack_require__(/*! ./PredictionMode */ \"./antlr4/atn/PredictionMode.js\").PredictionMode;\n\n\n//# sourceURL=webpack:///./antlr4/atn/index.js?");

/***/ }),

/***/ "./antlr4/dfa/DFA.js":
/*!***************************!*\
  !*** ./antlr4/dfa/DFA.js ***!
  \***************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("//\n/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nvar Set = __webpack_require__(/*! ../Utils */ \"./antlr4/Utils.js\").Set;\nvar DFAState = __webpack_require__(/*! ./DFAState */ \"./antlr4/dfa/DFAState.js\").DFAState;\nvar StarLoopEntryState = __webpack_require__(/*! ../atn/ATNState */ \"./antlr4/atn/ATNState.js\").StarLoopEntryState;\nvar ATNConfigSet = __webpack_require__(/*! ./../atn/ATNConfigSet */ \"./antlr4/atn/ATNConfigSet.js\").ATNConfigSet;\nvar DFASerializer = __webpack_require__(/*! ./DFASerializer */ \"./antlr4/dfa/DFASerializer.js\").DFASerializer;\nvar LexerDFASerializer = __webpack_require__(/*! ./DFASerializer */ \"./antlr4/dfa/DFASerializer.js\").LexerDFASerializer;\n\n\n\nfunction DFA(atnStartState, decision) {\n\tif (decision === undefined) {\n\t\tdecision = 0;\n\t}\n\t// From which ATN state did we create this DFA?\n\tthis.atnStartState = atnStartState;\n\tthis.decision = decision;\n\t// A set of all DFA states. Use {@link Map} so we can get old state back\n\t// ({@link Set} only allows you to see if it's there).\n\tthis._states = new Set();\n\tthis.s0 = null;\n\t// {@code true} if this DFA is for a precedence decision; otherwise,\n\t// {@code false}. This is the backing field for {@link //isPrecedenceDfa},\n\t// {@link //setPrecedenceDfa}.\n\tthis.precedenceDfa = false;\n    if (atnStartState instanceof StarLoopEntryState)\n    {\n        if (atnStartState.isPrecedenceDecision) {\n            this.precedenceDfa = true;\n            var precedenceState = new DFAState(null, new ATNConfigSet());\n            precedenceState.edges = [];\n            precedenceState.isAcceptState = false;\n            precedenceState.requiresFullContext = false;\n            this.s0 = precedenceState;\n        }\n    }\n\treturn this;\n}\n\n// Get the start state for a specific precedence value.\n//\n// @param precedence The current precedence.\n// @return The start state corresponding to the specified precedence, or\n// {@code null} if no start state exists for the specified precedence.\n//\n// @throws IllegalStateException if this is not a precedence DFA.\n// @see //isPrecedenceDfa()\n\nDFA.prototype.getPrecedenceStartState = function(precedence) {\n\tif (!(this.precedenceDfa)) {\n\t\tthrow (\"Only precedence DFAs may contain a precedence start state.\");\n\t}\n\t// s0.edges is never null for a precedence DFA\n\tif (precedence < 0 || precedence >= this.s0.edges.length) {\n\t\treturn null;\n\t}\n\treturn this.s0.edges[precedence] || null;\n};\n\n// Set the start state for a specific precedence value.\n//\n// @param precedence The current precedence.\n// @param startState The start state corresponding to the specified\n// precedence.\n//\n// @throws IllegalStateException if this is not a precedence DFA.\n// @see //isPrecedenceDfa()\n//\nDFA.prototype.setPrecedenceStartState = function(precedence, startState) {\n\tif (!(this.precedenceDfa)) {\n\t\tthrow (\"Only precedence DFAs may contain a precedence start state.\");\n\t}\n\tif (precedence < 0) {\n\t\treturn;\n\t}\n\n\t// synchronization on s0 here is ok. when the DFA is turned into a\n\t// precedence DFA, s0 will be initialized once and not updated again\n\t// s0.edges is never null for a precedence DFA\n\tthis.s0.edges[precedence] = startState;\n};\n\n//\n// Sets whether this is a precedence DFA. If the specified value differs\n// from the current DFA configuration, the following actions are taken;\n// otherwise no changes are made to the current DFA.\n//\n// <ul>\n// <li>The {@link //states} map is cleared</li>\n// <li>If {@code precedenceDfa} is {@code false}, the initial state\n// {@link //s0} is set to {@code null}; otherwise, it is initialized to a new\n// {@link DFAState} with an empty outgoing {@link DFAState//edges} array to\n// store the start states for individual precedence values.</li>\n// <li>The {@link //precedenceDfa} field is updated</li>\n// </ul>\n//\n// @param precedenceDfa {@code true} if this is a precedence DFA; otherwise,\n// {@code false}\n\nDFA.prototype.setPrecedenceDfa = function(precedenceDfa) {\n\tif (this.precedenceDfa!==precedenceDfa) {\n\t\tthis._states = new DFAStatesSet();\n\t\tif (precedenceDfa) {\n\t\t\tvar precedenceState = new DFAState(null, new ATNConfigSet());\n\t\t\tprecedenceState.edges = [];\n\t\t\tprecedenceState.isAcceptState = false;\n\t\t\tprecedenceState.requiresFullContext = false;\n\t\t\tthis.s0 = precedenceState;\n\t\t} else {\n\t\t\tthis.s0 = null;\n\t\t}\n\t\tthis.precedenceDfa = precedenceDfa;\n\t}\n};\n\nObject.defineProperty(DFA.prototype, \"states\", {\n\tget : function() {\n\t\treturn this._states;\n\t}\n});\n\n// Return a list of all states in this DFA, ordered by state number.\nDFA.prototype.sortedStates = function() {\n\tvar list = this._states.values();\n\treturn list.sort(function(a, b) {\n\t\treturn a.stateNumber - b.stateNumber;\n\t});\n};\n\nDFA.prototype.toString = function(literalNames, symbolicNames) {\n\tliteralNames = literalNames || null;\n\tsymbolicNames = symbolicNames || null;\n\tif (this.s0 === null) {\n\t\treturn \"\";\n\t}\n\tvar serializer = new DFASerializer(this, literalNames, symbolicNames);\n\treturn serializer.toString();\n};\n\nDFA.prototype.toLexerString = function() {\n\tif (this.s0 === null) {\n\t\treturn \"\";\n\t}\n\tvar serializer = new LexerDFASerializer(this);\n\treturn serializer.toString();\n};\n\nexports.DFA = DFA;\n\n\n//# sourceURL=webpack:///./antlr4/dfa/DFA.js?");

/***/ }),

/***/ "./antlr4/dfa/DFASerializer.js":
/*!*************************************!*\
  !*** ./antlr4/dfa/DFASerializer.js ***!
  \*************************************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\n// A DFA walker that knows how to dump them to serialized strings.#/\n\n\nfunction DFASerializer(dfa, literalNames, symbolicNames) {\n\tthis.dfa = dfa;\n\tthis.literalNames = literalNames || [];\n\tthis.symbolicNames = symbolicNames || [];\n\treturn this;\n}\n\nDFASerializer.prototype.toString = function() {\n   if(this.dfa.s0 === null) {\n       return null;\n   }\n   var buf = \"\";\n   var states = this.dfa.sortedStates();\n   for(var i=0;i<states.length;i++) {\n       var s = states[i];\n       if(s.edges!==null) {\n            var n = s.edges.length;\n            for(var j=0;j<n;j++) {\n                var t = s.edges[j] || null;\n                if(t!==null && t.stateNumber !== 0x7FFFFFFF) {\n                    buf = buf.concat(this.getStateString(s));\n                    buf = buf.concat(\"-\");\n                    buf = buf.concat(this.getEdgeLabel(j));\n                    buf = buf.concat(\"->\");\n                    buf = buf.concat(this.getStateString(t));\n                    buf = buf.concat('\\n');\n                }\n            }\n       }\n   }\n   return buf.length===0 ? null : buf;\n};\n\nDFASerializer.prototype.getEdgeLabel = function(i) {\n    if (i===0) {\n        return \"EOF\";\n    } else if(this.literalNames !==null || this.symbolicNames!==null) {\n        return this.literalNames[i-1] || this.symbolicNames[i-1];\n    } else {\n        return String.fromCharCode(i-1);\n    }\n};\n\nDFASerializer.prototype.getStateString = function(s) {\n    var baseStateStr = ( s.isAcceptState ? \":\" : \"\") + \"s\" + s.stateNumber + ( s.requiresFullContext ? \"^\" : \"\");\n    if(s.isAcceptState) {\n        if (s.predicates !== null) {\n            return baseStateStr + \"=>\" + s.predicates.toString();\n        } else {\n            return baseStateStr + \"=>\" + s.prediction.toString();\n        }\n    } else {\n        return baseStateStr;\n    }\n};\n\nfunction LexerDFASerializer(dfa) {\n\tDFASerializer.call(this, dfa, null);\n\treturn this;\n}\n\nLexerDFASerializer.prototype = Object.create(DFASerializer.prototype);\nLexerDFASerializer.prototype.constructor = LexerDFASerializer;\n\nLexerDFASerializer.prototype.getEdgeLabel = function(i) {\n\treturn \"'\" + String.fromCharCode(i) + \"'\";\n};\n\nexports.DFASerializer = DFASerializer;\nexports.LexerDFASerializer = LexerDFASerializer;\n\n\n\n//# sourceURL=webpack:///./antlr4/dfa/DFASerializer.js?");

/***/ }),

/***/ "./antlr4/dfa/DFAState.js":
/*!********************************!*\
  !*** ./antlr4/dfa/DFAState.js ***!
  \********************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("//\n/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n///\n\nvar ATNConfigSet = __webpack_require__(/*! ./../atn/ATNConfigSet */ \"./antlr4/atn/ATNConfigSet.js\").ATNConfigSet;\nvar Utils = __webpack_require__(/*! ./../Utils */ \"./antlr4/Utils.js\");\nvar Hash = Utils.Hash;\nvar Set = Utils.Set;\n\n// Map a predicate to a predicted alternative.///\n\nfunction PredPrediction(pred, alt) {\n\tthis.alt = alt;\n\tthis.pred = pred;\n\treturn this;\n}\n\nPredPrediction.prototype.toString = function() {\n\treturn \"(\" + this.pred + \", \" + this.alt + \")\";\n};\n\n// A DFA state represents a set of possible ATN configurations.\n// As Aho, Sethi, Ullman p. 117 says \"The DFA uses its state\n// to keep track of all possible states the ATN can be in after\n// reading each input symbol. That is to say, after reading\n// input a1a2..an, the DFA is in a state that represents the\n// subset T of the states of the ATN that are reachable from the\n// ATN's start state along some path labeled a1a2..an.\"\n// In conventional NFA&rarr;DFA conversion, therefore, the subset T\n// would be a bitset representing the set of states the\n// ATN could be in. We need to track the alt predicted by each\n// state as well, however. More importantly, we need to maintain\n// a stack of states, tracking the closure operations as they\n// jump from rule to rule, emulating rule invocations (method calls).\n// I have to add a stack to simulate the proper lookahead sequences for\n// the underlying LL grammar from which the ATN was derived.\n//\n// <p>I use a set of ATNConfig objects not simple states. An ATNConfig\n// is both a state (ala normal conversion) and a RuleContext describing\n// the chain of rules (if any) followed to arrive at that state.</p>\n//\n// <p>A DFA state may have multiple references to a particular state,\n// but with different ATN contexts (with same or different alts)\n// meaning that state was reached via a different set of rule invocations.</p>\n// /\n\nfunction DFAState(stateNumber, configs) {\n\tif (stateNumber === null) {\n\t\tstateNumber = -1;\n\t}\n\tif (configs === null) {\n\t\tconfigs = new ATNConfigSet();\n\t}\n\tthis.stateNumber = stateNumber;\n\tthis.configs = configs;\n\t// {@code edges[symbol]} points to target of symbol. Shift up by 1 so (-1)\n\t// {@link Token//EOF} maps to {@code edges[0]}.\n\tthis.edges = null;\n\tthis.isAcceptState = false;\n\t// if accept state, what ttype do we match or alt do we predict?\n\t// This is set to {@link ATN//INVALID_ALT_NUMBER} when {@link\n\t// //predicates}{@code !=null} or\n\t// {@link //requiresFullContext}.\n\tthis.prediction = 0;\n\tthis.lexerActionExecutor = null;\n\t// Indicates that this state was created during SLL prediction that\n\t// discovered a conflict between the configurations in the state. Future\n\t// {@link ParserATNSimulator//execATN} invocations immediately jumped doing\n\t// full context prediction if this field is true.\n\tthis.requiresFullContext = false;\n\t// During SLL parsing, this is a list of predicates associated with the\n\t// ATN configurations of the DFA state. When we have predicates,\n\t// {@link //requiresFullContext} is {@code false} since full context\n\t// prediction evaluates predicates\n\t// on-the-fly. If this is not null, then {@link //prediction} is\n\t// {@link ATN//INVALID_ALT_NUMBER}.\n\t//\n\t// <p>We only use these for non-{@link //requiresFullContext} but\n\t// conflicting states. That\n\t// means we know from the context (it's $ or we don't dip into outer\n\t// context) that it's an ambiguity not a conflict.</p>\n\t//\n\t// <p>This list is computed by {@link\n\t// ParserATNSimulator//predicateDFAState}.</p>\n\tthis.predicates = null;\n\treturn this;\n}\n\n// Get the set of all alts mentioned by all ATN configurations in this\n// DFA state.\nDFAState.prototype.getAltSet = function() {\n\tvar alts = new Set();\n\tif (this.configs !== null) {\n\t\tfor (var i = 0; i < this.configs.length; i++) {\n\t\t\tvar c = this.configs[i];\n\t\t\talts.add(c.alt);\n\t\t}\n\t}\n\tif (alts.length === 0) {\n\t\treturn null;\n\t} else {\n\t\treturn alts;\n\t}\n};\n\n// Two {@link DFAState} instances are equal if their ATN configuration sets\n// are the same. This method is used to see if a state already exists.\n//\n// <p>Because the number of alternatives and number of ATN configurations are\n// finite, there is a finite number of DFA states that can be processed.\n// This is necessary to show that the algorithm terminates.</p>\n//\n// <p>Cannot test the DFA state numbers here because in\n// {@link ParserATNSimulator//addDFAState} we need to know if any other state\n// exists that has this exact set of ATN configurations. The\n// {@link //stateNumber} is irrelevant.</p>\nDFAState.prototype.equals = function(other) {\n\t// compare set of ATN configurations in this set with other\n\treturn this === other ||\n\t\t\t(other instanceof DFAState &&\n\t\t\t\tthis.configs.equals(other.configs));\n};\n\nDFAState.prototype.toString = function() {\n\tvar s = \"\" + this.stateNumber + \":\" + this.configs;\n\tif(this.isAcceptState) {\n        s = s + \"=>\";\n        if (this.predicates !== null)\n            s = s + this.predicates;\n        else\n            s = s + this.prediction;\n    }\n\treturn s;\n};\n\nDFAState.prototype.hashCode = function() {\n\tvar hash = new Hash();\n\thash.update(this.configs);\n\tif(this.isAcceptState) {\n        if (this.predicates !== null)\n            hash.update(this.predicates);\n        else\n            hash.update(this.prediction);\n    }\n    return hash.finish();\n};\n\nexports.DFAState = DFAState;\nexports.PredPrediction = PredPrediction;\n\n\n//# sourceURL=webpack:///./antlr4/dfa/DFAState.js?");

/***/ }),

/***/ "./antlr4/dfa/index.js":
/*!*****************************!*\
  !*** ./antlr4/dfa/index.js ***!
  \*****************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nexports.DFA = __webpack_require__(/*! ./DFA */ \"./antlr4/dfa/DFA.js\").DFA;\nexports.DFASerializer = __webpack_require__(/*! ./DFASerializer */ \"./antlr4/dfa/DFASerializer.js\").DFASerializer;\nexports.LexerDFASerializer = __webpack_require__(/*! ./DFASerializer */ \"./antlr4/dfa/DFASerializer.js\").LexerDFASerializer;\nexports.PredPrediction = __webpack_require__(/*! ./DFAState */ \"./antlr4/dfa/DFAState.js\").PredPrediction;\n\n\n//# sourceURL=webpack:///./antlr4/dfa/index.js?");

/***/ }),

/***/ "./antlr4/error/DiagnosticErrorListener.js":
/*!*************************************************!*\
  !*** ./antlr4/error/DiagnosticErrorListener.js ***!
  \*************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("//\n/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n//\n\n//\n// This implementation of {@link ANTLRErrorListener} can be used to identify\n// certain potential correctness and performance problems in grammars. \"Reports\"\n// are made by calling {@link Parser//notifyErrorListeners} with the appropriate\n// message.\n//\n// <ul>\n// <li><b>Ambiguities</b>: These are cases where more than one path through the\n// grammar can match the input.</li>\n// <li><b>Weak context sensitivity</b>: These are cases where full-context\n// prediction resolved an SLL conflict to a unique alternative which equaled the\n// minimum alternative of the SLL conflict.</li>\n// <li><b>Strong (forced) context sensitivity</b>: These are cases where the\n// full-context prediction resolved an SLL conflict to a unique alternative,\n// <em>and</em> the minimum alternative of the SLL conflict was found to not be\n// a truly viable alternative. Two-stage parsing cannot be used for inputs where\n// this situation occurs.</li>\n// </ul>\n\nvar BitSet = __webpack_require__(/*! ./../Utils */ \"./antlr4/Utils.js\").BitSet;\nvar ErrorListener = __webpack_require__(/*! ./ErrorListener */ \"./antlr4/error/ErrorListener.js\").ErrorListener;\nvar Interval = __webpack_require__(/*! ./../IntervalSet */ \"./antlr4/IntervalSet.js\").Interval;\n\nfunction DiagnosticErrorListener(exactOnly) {\n\tErrorListener.call(this);\n\texactOnly = exactOnly || true;\n\t// whether all ambiguities or only exact ambiguities are reported.\n\tthis.exactOnly = exactOnly;\n\treturn this;\n}\n\nDiagnosticErrorListener.prototype = Object.create(ErrorListener.prototype);\nDiagnosticErrorListener.prototype.constructor = DiagnosticErrorListener;\n\nDiagnosticErrorListener.prototype.reportAmbiguity = function(recognizer, dfa,\n\t\tstartIndex, stopIndex, exact, ambigAlts, configs) {\n\tif (this.exactOnly && !exact) {\n\t\treturn;\n\t}\n\tvar msg = \"reportAmbiguity d=\" +\n\t\t\tthis.getDecisionDescription(recognizer, dfa) +\n\t\t\t\": ambigAlts=\" +\n\t\t\tthis.getConflictingAlts(ambigAlts, configs) +\n\t\t\t\", input='\" +\n\t\t\trecognizer.getTokenStream().getText(new Interval(startIndex, stopIndex)) + \"'\";\n\trecognizer.notifyErrorListeners(msg);\n};\n\nDiagnosticErrorListener.prototype.reportAttemptingFullContext = function(\n\t\trecognizer, dfa, startIndex, stopIndex, conflictingAlts, configs) {\n\tvar msg = \"reportAttemptingFullContext d=\" +\n\t\t\tthis.getDecisionDescription(recognizer, dfa) +\n\t\t\t\", input='\" +\n\t\t\trecognizer.getTokenStream().getText(new Interval(startIndex, stopIndex)) + \"'\";\n\trecognizer.notifyErrorListeners(msg);\n};\n\nDiagnosticErrorListener.prototype.reportContextSensitivity = function(\n\t\trecognizer, dfa, startIndex, stopIndex, prediction, configs) {\n\tvar msg = \"reportContextSensitivity d=\" +\n\t\t\tthis.getDecisionDescription(recognizer, dfa) +\n\t\t\t\", input='\" +\n\t\t\trecognizer.getTokenStream().getText(new Interval(startIndex, stopIndex)) + \"'\";\n\trecognizer.notifyErrorListeners(msg);\n};\n\nDiagnosticErrorListener.prototype.getDecisionDescription = function(recognizer, dfa) {\n\tvar decision = dfa.decision;\n\tvar ruleIndex = dfa.atnStartState.ruleIndex;\n\n\tvar ruleNames = recognizer.ruleNames;\n\tif (ruleIndex < 0 || ruleIndex >= ruleNames.length) {\n\t\treturn \"\" + decision;\n\t}\n\tvar ruleName = ruleNames[ruleIndex] || null;\n\tif (ruleName === null || ruleName.length === 0) {\n\t\treturn \"\" + decision;\n\t}\n\treturn \"\" + decision + \" (\" + ruleName + \")\";\n};\n\n//\n// Computes the set of conflicting or ambiguous alternatives from a\n// configuration set, if that information was not already provided by the\n// parser.\n//\n// @param reportedAlts The set of conflicting or ambiguous alternatives, as\n// reported by the parser.\n// @param configs The conflicting or ambiguous configuration set.\n// @return Returns {@code reportedAlts} if it is not {@code null}, otherwise\n// returns the set of alternatives represented in {@code configs}.\n//\nDiagnosticErrorListener.prototype.getConflictingAlts = function(reportedAlts, configs) {\n\tif (reportedAlts !== null) {\n\t\treturn reportedAlts;\n\t}\n\tvar result = new BitSet();\n\tfor (var i = 0; i < configs.items.length; i++) {\n\t\tresult.add(configs.items[i].alt);\n\t}\n\treturn \"{\" + result.values().join(\", \") + \"}\";\n};\n\nexports.DiagnosticErrorListener = DiagnosticErrorListener;\n\n//# sourceURL=webpack:///./antlr4/error/DiagnosticErrorListener.js?");

/***/ }),

/***/ "./antlr4/error/ErrorListener.js":
/*!***************************************!*\
  !*** ./antlr4/error/ErrorListener.js ***!
  \***************************************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("//\n/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\n// Provides an empty default implementation of {@link ANTLRErrorListener}. The\n// default implementation of each method does nothing, but can be overridden as\n// necessary.\n\nfunction ErrorListener() {\n\treturn this;\n}\n\nErrorListener.prototype.syntaxError = function(recognizer, offendingSymbol, line, column, msg, e) {\n};\n\nErrorListener.prototype.reportAmbiguity = function(recognizer, dfa, startIndex, stopIndex, exact, ambigAlts, configs) {\n};\n\nErrorListener.prototype.reportAttemptingFullContext = function(recognizer, dfa, startIndex, stopIndex, conflictingAlts, configs) {\n};\n\nErrorListener.prototype.reportContextSensitivity = function(recognizer, dfa, startIndex, stopIndex, prediction, configs) {\n};\n\nfunction ConsoleErrorListener() {\n\tErrorListener.call(this);\n\treturn this;\n}\n\nConsoleErrorListener.prototype = Object.create(ErrorListener.prototype);\nConsoleErrorListener.prototype.constructor = ConsoleErrorListener;\n\n//\n// Provides a default instance of {@link ConsoleErrorListener}.\n//\nConsoleErrorListener.INSTANCE = new ConsoleErrorListener();\n\n//\n// {@inheritDoc}\n//\n// <p>\n// This implementation prints messages to {@link System//err} containing the\n// values of {@code line}, {@code charPositionInLine}, and {@code msg} using\n// the following format.</p>\n//\n// <pre>\n// line <em>line</em>:<em>charPositionInLine</em> <em>msg</em>\n// </pre>\n//\nConsoleErrorListener.prototype.syntaxError = function(recognizer, offendingSymbol, line, column, msg, e) {\n    console.error(\"line \" + line + \":\" + column + \" \" + msg);\n};\n\nfunction ProxyErrorListener(delegates) {\n\tErrorListener.call(this);\n    if (delegates===null) {\n        throw \"delegates\";\n    }\n    this.delegates = delegates;\n\treturn this;\n}\n\nProxyErrorListener.prototype = Object.create(ErrorListener.prototype);\nProxyErrorListener.prototype.constructor = ProxyErrorListener;\n\nProxyErrorListener.prototype.syntaxError = function(recognizer, offendingSymbol, line, column, msg, e) {\n    this.delegates.map(function(d) { d.syntaxError(recognizer, offendingSymbol, line, column, msg, e); });\n};\n\nProxyErrorListener.prototype.reportAmbiguity = function(recognizer, dfa, startIndex, stopIndex, exact, ambigAlts, configs) {\n    this.delegates.map(function(d) { d.reportAmbiguity(recognizer, dfa, startIndex, stopIndex, exact, ambigAlts, configs); });\n};\n\nProxyErrorListener.prototype.reportAttemptingFullContext = function(recognizer, dfa, startIndex, stopIndex, conflictingAlts, configs) {\n\tthis.delegates.map(function(d) { d.reportAttemptingFullContext(recognizer, dfa, startIndex, stopIndex, conflictingAlts, configs); });\n};\n\nProxyErrorListener.prototype.reportContextSensitivity = function(recognizer, dfa, startIndex, stopIndex, prediction, configs) {\n\tthis.delegates.map(function(d) { d.reportContextSensitivity(recognizer, dfa, startIndex, stopIndex, prediction, configs); });\n};\n\nexports.ErrorListener = ErrorListener;\nexports.ConsoleErrorListener = ConsoleErrorListener;\nexports.ProxyErrorListener = ProxyErrorListener;\n\n\n\n//# sourceURL=webpack:///./antlr4/error/ErrorListener.js?");

/***/ }),

/***/ "./antlr4/error/ErrorStrategy.js":
/*!***************************************!*\
  !*** ./antlr4/error/ErrorStrategy.js ***!
  \***************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("//\n/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n//\n\nvar Token = __webpack_require__(/*! ./../Token */ \"./antlr4/Token.js\").Token;\nvar Errors = __webpack_require__(/*! ./Errors */ \"./antlr4/error/Errors.js\");\nvar NoViableAltException = Errors.NoViableAltException;\nvar InputMismatchException = Errors.InputMismatchException;\nvar FailedPredicateException = Errors.FailedPredicateException;\nvar ParseCancellationException = Errors.ParseCancellationException;\nvar ATNState = __webpack_require__(/*! ./../atn/ATNState */ \"./antlr4/atn/ATNState.js\").ATNState;\nvar Interval = __webpack_require__(/*! ./../IntervalSet */ \"./antlr4/IntervalSet.js\").Interval;\nvar IntervalSet = __webpack_require__(/*! ./../IntervalSet */ \"./antlr4/IntervalSet.js\").IntervalSet;\n\nfunction ErrorStrategy() {\n\n}\n\nErrorStrategy.prototype.reset = function(recognizer){\n};\n\nErrorStrategy.prototype.recoverInline = function(recognizer){\n};\n\nErrorStrategy.prototype.recover = function(recognizer, e){\n};\n\nErrorStrategy.prototype.sync = function(recognizer){\n};\n\nErrorStrategy.prototype.inErrorRecoveryMode = function(recognizer){\n};\n\nErrorStrategy.prototype.reportError = function(recognizer){\n};\n\n\n\n// This is the default implementation of {@link ANTLRErrorStrategy} used for\n// error reporting and recovery in ANTLR parsers.\n//\nfunction DefaultErrorStrategy() {\n\tErrorStrategy.call(this);\n    // Indicates whether the error strategy is currently \"recovering from an\n    // error\". This is used to suppress reporting multiple error messages while\n    // attempting to recover from a detected syntax error.\n    //\n    // @see //inErrorRecoveryMode\n    //\n    this.errorRecoveryMode = false;\n\n    // The index into the input stream where the last error occurred.\n    // This is used to prevent infinite loops where an error is found\n    // but no token is consumed during recovery...another error is found,\n    // ad nauseum. This is a failsafe mechanism to guarantee that at least\n    // one token/tree node is consumed for two errors.\n    //\n    this.lastErrorIndex = -1;\n    this.lastErrorStates = null;\n    return this;\n}\n\nDefaultErrorStrategy.prototype = Object.create(ErrorStrategy.prototype);\nDefaultErrorStrategy.prototype.constructor = DefaultErrorStrategy;\n\n// <p>The default implementation simply calls {@link //endErrorCondition} to\n// ensure that the handler is not in error recovery mode.</p>\nDefaultErrorStrategy.prototype.reset = function(recognizer) {\n    this.endErrorCondition(recognizer);\n};\n\n//\n// This method is called to enter error recovery mode when a recognition\n// exception is reported.\n//\n// @param recognizer the parser instance\n//\nDefaultErrorStrategy.prototype.beginErrorCondition = function(recognizer) {\n    this.errorRecoveryMode = true;\n};\n\nDefaultErrorStrategy.prototype.inErrorRecoveryMode = function(recognizer) {\n    return this.errorRecoveryMode;\n};\n\n//\n// This method is called to leave error recovery mode after recovering from\n// a recognition exception.\n//\n// @param recognizer\n//\nDefaultErrorStrategy.prototype.endErrorCondition = function(recognizer) {\n    this.errorRecoveryMode = false;\n    this.lastErrorStates = null;\n    this.lastErrorIndex = -1;\n};\n\n//\n// {@inheritDoc}\n//\n// <p>The default implementation simply calls {@link //endErrorCondition}.</p>\n//\nDefaultErrorStrategy.prototype.reportMatch = function(recognizer) {\n    this.endErrorCondition(recognizer);\n};\n\n//\n// {@inheritDoc}\n//\n// <p>The default implementation returns immediately if the handler is already\n// in error recovery mode. Otherwise, it calls {@link //beginErrorCondition}\n// and dispatches the reporting task based on the runtime type of {@code e}\n// according to the following table.</p>\n//\n// <ul>\n// <li>{@link NoViableAltException}: Dispatches the call to\n// {@link //reportNoViableAlternative}</li>\n// <li>{@link InputMismatchException}: Dispatches the call to\n// {@link //reportInputMismatch}</li>\n// <li>{@link FailedPredicateException}: Dispatches the call to\n// {@link //reportFailedPredicate}</li>\n// <li>All other types: calls {@link Parser//notifyErrorListeners} to report\n// the exception</li>\n// </ul>\n//\nDefaultErrorStrategy.prototype.reportError = function(recognizer, e) {\n   // if we've already reported an error and have not matched a token\n   // yet successfully, don't report any errors.\n    if(this.inErrorRecoveryMode(recognizer)) {\n        return; // don't report spurious errors\n    }\n    this.beginErrorCondition(recognizer);\n    if ( e instanceof NoViableAltException ) {\n        this.reportNoViableAlternative(recognizer, e);\n    } else if ( e instanceof InputMismatchException ) {\n        this.reportInputMismatch(recognizer, e);\n    } else if ( e instanceof FailedPredicateException ) {\n        this.reportFailedPredicate(recognizer, e);\n    } else {\n        console.log(\"unknown recognition error type: \" + e.constructor.name);\n        console.log(e.stack);\n        recognizer.notifyErrorListeners(e.getOffendingToken(), e.getMessage(), e);\n    }\n};\n//\n// {@inheritDoc}\n//\n// <p>The default implementation resynchronizes the parser by consuming tokens\n// until we find one in the resynchronization set--loosely the set of tokens\n// that can follow the current rule.</p>\n//\nDefaultErrorStrategy.prototype.recover = function(recognizer, e) {\n    if (this.lastErrorIndex===recognizer.getInputStream().index &&\n        this.lastErrorStates !== null && this.lastErrorStates.indexOf(recognizer.state)>=0) {\n\t\t// uh oh, another error at same token index and previously-visited\n\t\t// state in ATN; must be a case where LT(1) is in the recovery\n\t\t// token set so nothing got consumed. Consume a single token\n\t\t// at least to prevent an infinite loop; this is a failsafe.\n\t\trecognizer.consume();\n    }\n    this.lastErrorIndex = recognizer._input.index;\n    if (this.lastErrorStates === null) {\n        this.lastErrorStates = [];\n    }\n    this.lastErrorStates.push(recognizer.state);\n    var followSet = this.getErrorRecoverySet(recognizer);\n    this.consumeUntil(recognizer, followSet);\n};\n\n// The default implementation of {@link ANTLRErrorStrategy//sync} makes sure\n// that the current lookahead symbol is consistent with what were expecting\n// at this point in the ATN. You can call this anytime but ANTLR only\n// generates code to check before subrules/loops and each iteration.\n//\n// <p>Implements Jim Idle's magic sync mechanism in closures and optional\n// subrules. E.g.,</p>\n//\n// <pre>\n// a : sync ( stuff sync )* ;\n// sync : {consume to what can follow sync} ;\n// </pre>\n//\n// At the start of a sub rule upon error, {@link //sync} performs single\n// token deletion, if possible. If it can't do that, it bails on the current\n// rule and uses the default error recovery, which consumes until the\n// resynchronization set of the current rule.\n//\n// <p>If the sub rule is optional ({@code (...)?}, {@code (...)*}, or block\n// with an empty alternative), then the expected set includes what follows\n// the subrule.</p>\n//\n// <p>During loop iteration, it consumes until it sees a token that can start a\n// sub rule or what follows loop. Yes, that is pretty aggressive. We opt to\n// stay in the loop as long as possible.</p>\n//\n// <p><strong>ORIGINS</strong></p>\n//\n// <p>Previous versions of ANTLR did a poor job of their recovery within loops.\n// A single mismatch token or missing token would force the parser to bail\n// out of the entire rules surrounding the loop. So, for rule</p>\n//\n// <pre>\n// classDef : 'class' ID '{' member* '}'\n// </pre>\n//\n// input with an extra token between members would force the parser to\n// consume until it found the next class definition rather than the next\n// member definition of the current class.\n//\n// <p>This functionality cost a little bit of effort because the parser has to\n// compare token set at the start of the loop and at each iteration. If for\n// some reason speed is suffering for you, you can turn off this\n// functionality by simply overriding this method as a blank { }.</p>\n//\nDefaultErrorStrategy.prototype.sync = function(recognizer) {\n    // If already recovering, don't try to sync\n    if (this.inErrorRecoveryMode(recognizer)) {\n        return;\n    }\n    var s = recognizer._interp.atn.states[recognizer.state];\n    var la = recognizer.getTokenStream().LA(1);\n    // try cheaper subset first; might get lucky. seems to shave a wee bit off\n    var nextTokens = recognizer.atn.nextTokens(s);\n    if (nextTokens.contains(Token.EPSILON) || nextTokens.contains(la)) {\n        return;\n    }\n    switch (s.stateType) {\n    case ATNState.BLOCK_START:\n    case ATNState.STAR_BLOCK_START:\n    case ATNState.PLUS_BLOCK_START:\n    case ATNState.STAR_LOOP_ENTRY:\n       // report error and recover if possible\n        if( this.singleTokenDeletion(recognizer) !== null) {\n            return;\n        } else {\n            throw new InputMismatchException(recognizer);\n        }\n        break;\n    case ATNState.PLUS_LOOP_BACK:\n    case ATNState.STAR_LOOP_BACK:\n        this.reportUnwantedToken(recognizer);\n        var expecting = new IntervalSet();\n        expecting.addSet(recognizer.getExpectedTokens());\n        var whatFollowsLoopIterationOrRule = expecting.addSet(this.getErrorRecoverySet(recognizer));\n        this.consumeUntil(recognizer, whatFollowsLoopIterationOrRule);\n        break;\n    default:\n        // do nothing if we can't identify the exact kind of ATN state\n    }\n};\n\n// This is called by {@link //reportError} when the exception is a\n// {@link NoViableAltException}.\n//\n// @see //reportError\n//\n// @param recognizer the parser instance\n// @param e the recognition exception\n//\nDefaultErrorStrategy.prototype.reportNoViableAlternative = function(recognizer, e) {\n    var tokens = recognizer.getTokenStream();\n    var input;\n    if(tokens !== null) {\n        if (e.startToken.type===Token.EOF) {\n            input = \"<EOF>\";\n        } else {\n            input = tokens.getText(new Interval(e.startToken.tokenIndex, e.offendingToken.tokenIndex));\n        }\n    } else {\n        input = \"<unknown input>\";\n    }\n    var msg = \"no viable alternative at input \" + this.escapeWSAndQuote(input);\n    recognizer.notifyErrorListeners(msg, e.offendingToken, e);\n};\n\n//\n// This is called by {@link //reportError} when the exception is an\n// {@link InputMismatchException}.\n//\n// @see //reportError\n//\n// @param recognizer the parser instance\n// @param e the recognition exception\n//\nDefaultErrorStrategy.prototype.reportInputMismatch = function(recognizer, e) {\n    var msg = \"mismatched input \" + this.getTokenErrorDisplay(e.offendingToken) +\n          \" expecting \" + e.getExpectedTokens().toString(recognizer.literalNames, recognizer.symbolicNames);\n    recognizer.notifyErrorListeners(msg, e.offendingToken, e);\n};\n\n//\n// This is called by {@link //reportError} when the exception is a\n// {@link FailedPredicateException}.\n//\n// @see //reportError\n//\n// @param recognizer the parser instance\n// @param e the recognition exception\n//\nDefaultErrorStrategy.prototype.reportFailedPredicate = function(recognizer, e) {\n    var ruleName = recognizer.ruleNames[recognizer._ctx.ruleIndex];\n    var msg = \"rule \" + ruleName + \" \" + e.message;\n    recognizer.notifyErrorListeners(msg, e.offendingToken, e);\n};\n\n// This method is called to report a syntax error which requires the removal\n// of a token from the input stream. At the time this method is called, the\n// erroneous symbol is current {@code LT(1)} symbol and has not yet been\n// removed from the input stream. When this method returns,\n// {@code recognizer} is in error recovery mode.\n//\n// <p>This method is called when {@link //singleTokenDeletion} identifies\n// single-token deletion as a viable recovery strategy for a mismatched\n// input error.</p>\n//\n// <p>The default implementation simply returns if the handler is already in\n// error recovery mode. Otherwise, it calls {@link //beginErrorCondition} to\n// enter error recovery mode, followed by calling\n// {@link Parser//notifyErrorListeners}.</p>\n//\n// @param recognizer the parser instance\n//\nDefaultErrorStrategy.prototype.reportUnwantedToken = function(recognizer) {\n    if (this.inErrorRecoveryMode(recognizer)) {\n        return;\n    }\n    this.beginErrorCondition(recognizer);\n    var t = recognizer.getCurrentToken();\n    var tokenName = this.getTokenErrorDisplay(t);\n    var expecting = this.getExpectedTokens(recognizer);\n    var msg = \"extraneous input \" + tokenName + \" expecting \" +\n        expecting.toString(recognizer.literalNames, recognizer.symbolicNames);\n    recognizer.notifyErrorListeners(msg, t, null);\n};\n// This method is called to report a syntax error which requires the\n// insertion of a missing token into the input stream. At the time this\n// method is called, the missing token has not yet been inserted. When this\n// method returns, {@code recognizer} is in error recovery mode.\n//\n// <p>This method is called when {@link //singleTokenInsertion} identifies\n// single-token insertion as a viable recovery strategy for a mismatched\n// input error.</p>\n//\n// <p>The default implementation simply returns if the handler is already in\n// error recovery mode. Otherwise, it calls {@link //beginErrorCondition} to\n// enter error recovery mode, followed by calling\n// {@link Parser//notifyErrorListeners}.</p>\n//\n// @param recognizer the parser instance\n//\nDefaultErrorStrategy.prototype.reportMissingToken = function(recognizer) {\n    if ( this.inErrorRecoveryMode(recognizer)) {\n        return;\n    }\n    this.beginErrorCondition(recognizer);\n    var t = recognizer.getCurrentToken();\n    var expecting = this.getExpectedTokens(recognizer);\n    var msg = \"missing \" + expecting.toString(recognizer.literalNames, recognizer.symbolicNames) +\n          \" at \" + this.getTokenErrorDisplay(t);\n    recognizer.notifyErrorListeners(msg, t, null);\n};\n\n// <p>The default implementation attempts to recover from the mismatched input\n// by using single token insertion and deletion as described below. If the\n// recovery attempt fails, this method throws an\n// {@link InputMismatchException}.</p>\n//\n// <p><strong>EXTRA TOKEN</strong> (single token deletion)</p>\n//\n// <p>{@code LA(1)} is not what we are looking for. If {@code LA(2)} has the\n// right token, however, then assume {@code LA(1)} is some extra spurious\n// token and delete it. Then consume and return the next token (which was\n// the {@code LA(2)} token) as the successful result of the match operation.</p>\n//\n// <p>This recovery strategy is implemented by {@link\n// //singleTokenDeletion}.</p>\n//\n// <p><strong>MISSING TOKEN</strong> (single token insertion)</p>\n//\n// <p>If current token (at {@code LA(1)}) is consistent with what could come\n// after the expected {@code LA(1)} token, then assume the token is missing\n// and use the parser's {@link TokenFactory} to create it on the fly. The\n// \"insertion\" is performed by returning the created token as the successful\n// result of the match operation.</p>\n//\n// <p>This recovery strategy is implemented by {@link\n// //singleTokenInsertion}.</p>\n//\n// <p><strong>EXAMPLE</strong></p>\n//\n// <p>For example, Input {@code i=(3;} is clearly missing the {@code ')'}. When\n// the parser returns from the nested call to {@code expr}, it will have\n// call chain:</p>\n//\n// <pre>\n// stat &rarr; expr &rarr; atom\n// </pre>\n//\n// and it will be trying to match the {@code ')'} at this point in the\n// derivation:\n//\n// <pre>\n// =&gt; ID '=' '(' INT ')' ('+' atom)* ';'\n// ^\n// </pre>\n//\n// The attempt to match {@code ')'} will fail when it sees {@code ';'} and\n// call {@link //recoverInline}. To recover, it sees that {@code LA(1)==';'}\n// is in the set of tokens that can follow the {@code ')'} token reference\n// in rule {@code atom}. It can assume that you forgot the {@code ')'}.\n//\nDefaultErrorStrategy.prototype.recoverInline = function(recognizer) {\n    // SINGLE TOKEN DELETION\n    var matchedSymbol = this.singleTokenDeletion(recognizer);\n    if (matchedSymbol !== null) {\n        // we have deleted the extra token.\n        // now, move past ttype token as if all were ok\n        recognizer.consume();\n        return matchedSymbol;\n    }\n    // SINGLE TOKEN INSERTION\n    if (this.singleTokenInsertion(recognizer)) {\n        return this.getMissingSymbol(recognizer);\n    }\n    // even that didn't work; must throw the exception\n    throw new InputMismatchException(recognizer);\n};\n\n//\n// This method implements the single-token insertion inline error recovery\n// strategy. It is called by {@link //recoverInline} if the single-token\n// deletion strategy fails to recover from the mismatched input. If this\n// method returns {@code true}, {@code recognizer} will be in error recovery\n// mode.\n//\n// <p>This method determines whether or not single-token insertion is viable by\n// checking if the {@code LA(1)} input symbol could be successfully matched\n// if it were instead the {@code LA(2)} symbol. If this method returns\n// {@code true}, the caller is responsible for creating and inserting a\n// token with the correct type to produce this behavior.</p>\n//\n// @param recognizer the parser instance\n// @return {@code true} if single-token insertion is a viable recovery\n// strategy for the current mismatched input, otherwise {@code false}\n//\nDefaultErrorStrategy.prototype.singleTokenInsertion = function(recognizer) {\n    var currentSymbolType = recognizer.getTokenStream().LA(1);\n    // if current token is consistent with what could come after current\n    // ATN state, then we know we're missing a token; error recovery\n    // is free to conjure up and insert the missing token\n    var atn = recognizer._interp.atn;\n    var currentState = atn.states[recognizer.state];\n    var next = currentState.transitions[0].target;\n    var expectingAtLL2 = atn.nextTokens(next, recognizer._ctx);\n    if (expectingAtLL2.contains(currentSymbolType) ){\n        this.reportMissingToken(recognizer);\n        return true;\n    } else {\n        return false;\n    }\n};\n\n// This method implements the single-token deletion inline error recovery\n// strategy. It is called by {@link //recoverInline} to attempt to recover\n// from mismatched input. If this method returns null, the parser and error\n// handler state will not have changed. If this method returns non-null,\n// {@code recognizer} will <em>not</em> be in error recovery mode since the\n// returned token was a successful match.\n//\n// <p>If the single-token deletion is successful, this method calls\n// {@link //reportUnwantedToken} to report the error, followed by\n// {@link Parser//consume} to actually \"delete\" the extraneous token. Then,\n// before returning {@link //reportMatch} is called to signal a successful\n// match.</p>\n//\n// @param recognizer the parser instance\n// @return the successfully matched {@link Token} instance if single-token\n// deletion successfully recovers from the mismatched input, otherwise\n// {@code null}\n//\nDefaultErrorStrategy.prototype.singleTokenDeletion = function(recognizer) {\n    var nextTokenType = recognizer.getTokenStream().LA(2);\n    var expecting = this.getExpectedTokens(recognizer);\n    if (expecting.contains(nextTokenType)) {\n        this.reportUnwantedToken(recognizer);\n        // print(\"recoverFromMismatchedToken deleting \" \\\n        // + str(recognizer.getTokenStream().LT(1)) \\\n        // + \" since \" + str(recognizer.getTokenStream().LT(2)) \\\n        // + \" is what we want\", file=sys.stderr)\n        recognizer.consume(); // simply delete extra token\n        // we want to return the token we're actually matching\n        var matchedSymbol = recognizer.getCurrentToken();\n        this.reportMatch(recognizer); // we know current token is correct\n        return matchedSymbol;\n    } else {\n        return null;\n    }\n};\n\n// Conjure up a missing token during error recovery.\n//\n// The recognizer attempts to recover from single missing\n// symbols. But, actions might refer to that missing symbol.\n// For example, x=ID {f($x);}. The action clearly assumes\n// that there has been an identifier matched previously and that\n// $x points at that token. If that token is missing, but\n// the next token in the stream is what we want we assume that\n// this token is missing and we keep going. Because we\n// have to return some token to replace the missing token,\n// we have to conjure one up. This method gives the user control\n// over the tokens returned for missing tokens. Mostly,\n// you will want to create something special for identifier\n// tokens. For literals such as '{' and ',', the default\n// action in the parser or tree parser works. It simply creates\n// a CommonToken of the appropriate type. The text will be the token.\n// If you change what tokens must be created by the lexer,\n// override this method to create the appropriate tokens.\n//\nDefaultErrorStrategy.prototype.getMissingSymbol = function(recognizer) {\n    var currentSymbol = recognizer.getCurrentToken();\n    var expecting = this.getExpectedTokens(recognizer);\n    var expectedTokenType = expecting.first(); // get any element\n    var tokenText;\n    if (expectedTokenType===Token.EOF) {\n        tokenText = \"<missing EOF>\";\n    } else {\n        tokenText = \"<missing \" + recognizer.literalNames[expectedTokenType] + \">\";\n    }\n    var current = currentSymbol;\n    var lookback = recognizer.getTokenStream().LT(-1);\n    if (current.type===Token.EOF && lookback !== null) {\n        current = lookback;\n    }\n    return recognizer.getTokenFactory().create(current.source,\n        expectedTokenType, tokenText, Token.DEFAULT_CHANNEL,\n        -1, -1, current.line, current.column);\n};\n\nDefaultErrorStrategy.prototype.getExpectedTokens = function(recognizer) {\n    return recognizer.getExpectedTokens();\n};\n\n// How should a token be displayed in an error message? The default\n// is to display just the text, but during development you might\n// want to have a lot of information spit out. Override in that case\n// to use t.toString() (which, for CommonToken, dumps everything about\n// the token). This is better than forcing you to override a method in\n// your token objects because you don't have to go modify your lexer\n// so that it creates a new Java type.\n//\nDefaultErrorStrategy.prototype.getTokenErrorDisplay = function(t) {\n    if (t === null) {\n        return \"<no token>\";\n    }\n    var s = t.text;\n    if (s === null) {\n        if (t.type===Token.EOF) {\n            s = \"<EOF>\";\n        } else {\n            s = \"<\" + t.type + \">\";\n        }\n    }\n    return this.escapeWSAndQuote(s);\n};\n\nDefaultErrorStrategy.prototype.escapeWSAndQuote = function(s) {\n    s = s.replace(/\\n/g,\"\\\\n\");\n    s = s.replace(/\\r/g,\"\\\\r\");\n    s = s.replace(/\\t/g,\"\\\\t\");\n    return \"'\" + s + \"'\";\n};\n\n// Compute the error recovery set for the current rule. During\n// rule invocation, the parser pushes the set of tokens that can\n// follow that rule reference on the stack; this amounts to\n// computing FIRST of what follows the rule reference in the\n// enclosing rule. See LinearApproximator.FIRST().\n// This local follow set only includes tokens\n// from within the rule; i.e., the FIRST computation done by\n// ANTLR stops at the end of a rule.\n//\n// EXAMPLE\n//\n// When you find a \"no viable alt exception\", the input is not\n// consistent with any of the alternatives for rule r. The best\n// thing to do is to consume tokens until you see something that\n// can legally follow a call to r//or* any rule that called r.\n// You don't want the exact set of viable next tokens because the\n// input might just be missing a token--you might consume the\n// rest of the input looking for one of the missing tokens.\n//\n// Consider grammar:\n//\n// a : '[' b ']'\n// | '(' b ')'\n// ;\n// b : c '^' INT ;\n// c : ID\n// | INT\n// ;\n//\n// At each rule invocation, the set of tokens that could follow\n// that rule is pushed on a stack. Here are the various\n// context-sensitive follow sets:\n//\n// FOLLOW(b1_in_a) = FIRST(']') = ']'\n// FOLLOW(b2_in_a) = FIRST(')') = ')'\n// FOLLOW(c_in_b) = FIRST('^') = '^'\n//\n// Upon erroneous input \"[]\", the call chain is\n//\n// a -> b -> c\n//\n// and, hence, the follow context stack is:\n//\n// depth follow set start of rule execution\n// 0 <EOF> a (from main())\n// 1 ']' b\n// 2 '^' c\n//\n// Notice that ')' is not included, because b would have to have\n// been called from a different context in rule a for ')' to be\n// included.\n//\n// For error recovery, we cannot consider FOLLOW(c)\n// (context-sensitive or otherwise). We need the combined set of\n// all context-sensitive FOLLOW sets--the set of all tokens that\n// could follow any reference in the call chain. We need to\n// resync to one of those tokens. Note that FOLLOW(c)='^' and if\n// we resync'd to that token, we'd consume until EOF. We need to\n// sync to context-sensitive FOLLOWs for a, b, and c: {']','^'}.\n// In this case, for input \"[]\", LA(1) is ']' and in the set, so we would\n// not consume anything. After printing an error, rule c would\n// return normally. Rule b would not find the required '^' though.\n// At this point, it gets a mismatched token error and throws an\n// exception (since LA(1) is not in the viable following token\n// set). The rule exception handler tries to recover, but finds\n// the same recovery set and doesn't consume anything. Rule b\n// exits normally returning to rule a. Now it finds the ']' (and\n// with the successful match exits errorRecovery mode).\n//\n// So, you can see that the parser walks up the call chain looking\n// for the token that was a member of the recovery set.\n//\n// Errors are not generated in errorRecovery mode.\n//\n// ANTLR's error recovery mechanism is based upon original ideas:\n//\n// \"Algorithms + Data Structures = Programs\" by Niklaus Wirth\n//\n// and\n//\n// \"A note on error recovery in recursive descent parsers\":\n// http://portal.acm.org/citation.cfm?id=947902.947905\n//\n// Later, Josef Grosch had some good ideas:\n//\n// \"Efficient and Comfortable Error Recovery in Recursive Descent\n// Parsers\":\n// ftp://www.cocolab.com/products/cocktail/doca4.ps/ell.ps.zip\n//\n// Like Grosch I implement context-sensitive FOLLOW sets that are combined\n// at run-time upon error to avoid overhead during parsing.\n//\nDefaultErrorStrategy.prototype.getErrorRecoverySet = function(recognizer) {\n    var atn = recognizer._interp.atn;\n    var ctx = recognizer._ctx;\n    var recoverSet = new IntervalSet();\n    while (ctx !== null && ctx.invokingState>=0) {\n        // compute what follows who invoked us\n        var invokingState = atn.states[ctx.invokingState];\n        var rt = invokingState.transitions[0];\n        var follow = atn.nextTokens(rt.followState);\n        recoverSet.addSet(follow);\n        ctx = ctx.parentCtx;\n    }\n    recoverSet.removeOne(Token.EPSILON);\n    return recoverSet;\n};\n\n// Consume tokens until one matches the given token set.//\nDefaultErrorStrategy.prototype.consumeUntil = function(recognizer, set) {\n    var ttype = recognizer.getTokenStream().LA(1);\n    while( ttype !== Token.EOF && !set.contains(ttype)) {\n        recognizer.consume();\n        ttype = recognizer.getTokenStream().LA(1);\n    }\n};\n\n//\n// This implementation of {@link ANTLRErrorStrategy} responds to syntax errors\n// by immediately canceling the parse operation with a\n// {@link ParseCancellationException}. The implementation ensures that the\n// {@link ParserRuleContext//exception} field is set for all parse tree nodes\n// that were not completed prior to encountering the error.\n//\n// <p>\n// This error strategy is useful in the following scenarios.</p>\n//\n// <ul>\n// <li><strong>Two-stage parsing:</strong> This error strategy allows the first\n// stage of two-stage parsing to immediately terminate if an error is\n// encountered, and immediately fall back to the second stage. In addition to\n// avoiding wasted work by attempting to recover from errors here, the empty\n// implementation of {@link BailErrorStrategy//sync} improves the performance of\n// the first stage.</li>\n// <li><strong>Silent validation:</strong> When syntax errors are not being\n// reported or logged, and the parse result is simply ignored if errors occur,\n// the {@link BailErrorStrategy} avoids wasting work on recovering from errors\n// when the result will be ignored either way.</li>\n// </ul>\n//\n// <p>\n// {@code myparser.setErrorHandler(new BailErrorStrategy());}</p>\n//\n// @see Parser//setErrorHandler(ANTLRErrorStrategy)\n//\nfunction BailErrorStrategy() {\n\tDefaultErrorStrategy.call(this);\n\treturn this;\n}\n\nBailErrorStrategy.prototype = Object.create(DefaultErrorStrategy.prototype);\nBailErrorStrategy.prototype.constructor = BailErrorStrategy;\n\n// Instead of recovering from exception {@code e}, re-throw it wrapped\n// in a {@link ParseCancellationException} so it is not caught by the\n// rule function catches. Use {@link Exception//getCause()} to get the\n// original {@link RecognitionException}.\n//\nBailErrorStrategy.prototype.recover = function(recognizer, e) {\n    var context = recognizer._ctx;\n    while (context !== null) {\n        context.exception = e;\n        context = context.parentCtx;\n    }\n    throw new ParseCancellationException(e);\n};\n\n// Make sure we don't attempt to recover inline; if the parser\n// successfully recovers, it won't throw an exception.\n//\nBailErrorStrategy.prototype.recoverInline = function(recognizer) {\n    this.recover(recognizer, new InputMismatchException(recognizer));\n};\n\n// Make sure we don't attempt to recover from problems in subrules.//\nBailErrorStrategy.prototype.sync = function(recognizer) {\n    // pass\n};\n\nexports.BailErrorStrategy = BailErrorStrategy;\nexports.DefaultErrorStrategy = DefaultErrorStrategy;\n\n\n//# sourceURL=webpack:///./antlr4/error/ErrorStrategy.js?");

/***/ }),

/***/ "./antlr4/error/Errors.js":
/*!********************************!*\
  !*** ./antlr4/error/Errors.js ***!
  \********************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\n// The root of the ANTLR exception hierarchy. In general, ANTLR tracks just\n//  3 kinds of errors: prediction errors, failed predicate errors, and\n//  mismatched input errors. In each case, the parser knows where it is\n//  in the input, where it is in the ATN, the rule invocation stack,\n//  and what kind of problem occurred.\n\nvar PredicateTransition = __webpack_require__(/*! ./../atn/Transition */ \"./antlr4/atn/Transition.js\").PredicateTransition;\n\nfunction RecognitionException(params) {\n\tError.call(this);\n\tif (!!Error.captureStackTrace) {\n        Error.captureStackTrace(this, RecognitionException);\n\t} else {\n\t\tvar stack = new Error().stack;\n\t}\n\tthis.message = params.message;\n    this.recognizer = params.recognizer;\n    this.input = params.input;\n    this.ctx = params.ctx;\n    // The current {@link Token} when an error occurred. Since not all streams\n    // support accessing symbols by index, we have to track the {@link Token}\n    // instance itself.\n    this.offendingToken = null;\n    // Get the ATN state number the parser was in at the time the error\n    // occurred. For {@link NoViableAltException} and\n    // {@link LexerNoViableAltException} exceptions, this is the\n    // {@link DecisionState} number. For others, it is the state whose outgoing\n    // edge we couldn't match.\n    this.offendingState = -1;\n    if (this.recognizer!==null) {\n        this.offendingState = this.recognizer.state;\n    }\n    return this;\n}\n\nRecognitionException.prototype = Object.create(Error.prototype);\nRecognitionException.prototype.constructor = RecognitionException;\n\n// <p>If the state number is not known, this method returns -1.</p>\n\n//\n// Gets the set of input symbols which could potentially follow the\n// previously matched symbol at the time this exception was thrown.\n//\n// <p>If the set of expected tokens is not known and could not be computed,\n// this method returns {@code null}.</p>\n//\n// @return The set of token types that could potentially follow the current\n// state in the ATN, or {@code null} if the information is not available.\n// /\nRecognitionException.prototype.getExpectedTokens = function() {\n    if (this.recognizer!==null) {\n        return this.recognizer.atn.getExpectedTokens(this.offendingState, this.ctx);\n    } else {\n        return null;\n    }\n};\n\nRecognitionException.prototype.toString = function() {\n    return this.message;\n};\n\nfunction LexerNoViableAltException(lexer, input, startIndex, deadEndConfigs) {\n\tRecognitionException.call(this, {message:\"\", recognizer:lexer, input:input, ctx:null});\n    this.startIndex = startIndex;\n    this.deadEndConfigs = deadEndConfigs;\n    return this;\n}\n\nLexerNoViableAltException.prototype = Object.create(RecognitionException.prototype);\nLexerNoViableAltException.prototype.constructor = LexerNoViableAltException;\n\nLexerNoViableAltException.prototype.toString = function() {\n    var symbol = \"\";\n    if (this.startIndex >= 0 && this.startIndex < this.input.size) {\n        symbol = this.input.getText((this.startIndex,this.startIndex));\n    }\n    return \"LexerNoViableAltException\" + symbol;\n};\n\n// Indicates that the parser could not decide which of two or more paths\n// to take based upon the remaining input. It tracks the starting token\n// of the offending input and also knows where the parser was\n// in the various paths when the error. Reported by reportNoViableAlternative()\n//\nfunction NoViableAltException(recognizer, input, startToken, offendingToken, deadEndConfigs, ctx) {\n\tctx = ctx || recognizer._ctx;\n\toffendingToken = offendingToken || recognizer.getCurrentToken();\n\tstartToken = startToken || recognizer.getCurrentToken();\n\tinput = input || recognizer.getInputStream();\n\tRecognitionException.call(this, {message:\"\", recognizer:recognizer, input:input, ctx:ctx});\n    // Which configurations did we try at input.index() that couldn't match\n\t// input.LT(1)?//\n    this.deadEndConfigs = deadEndConfigs;\n    // The token object at the start index; the input stream might\n    // not be buffering tokens so get a reference to it. (At the\n    // time the error occurred, of course the stream needs to keep a\n    // buffer all of the tokens but later we might not have access to those.)\n    this.startToken = startToken;\n    this.offendingToken = offendingToken;\n}\n\nNoViableAltException.prototype = Object.create(RecognitionException.prototype);\nNoViableAltException.prototype.constructor = NoViableAltException;\n\n// This signifies any kind of mismatched input exceptions such as\n// when the current input does not match the expected token.\n//\nfunction InputMismatchException(recognizer) {\n\tRecognitionException.call(this, {message:\"\", recognizer:recognizer, input:recognizer.getInputStream(), ctx:recognizer._ctx});\n    this.offendingToken = recognizer.getCurrentToken();\n}\n\nInputMismatchException.prototype = Object.create(RecognitionException.prototype);\nInputMismatchException.prototype.constructor = InputMismatchException;\n\n// A semantic predicate failed during validation. Validation of predicates\n// occurs when normally parsing the alternative just like matching a token.\n// Disambiguating predicate evaluation occurs when we test a predicate during\n// prediction.\n\nfunction FailedPredicateException(recognizer, predicate, message) {\n\tRecognitionException.call(this, {message:this.formatMessage(predicate,message || null), recognizer:recognizer,\n                         input:recognizer.getInputStream(), ctx:recognizer._ctx});\n    var s = recognizer._interp.atn.states[recognizer.state];\n    var trans = s.transitions[0];\n    if (trans instanceof PredicateTransition) {\n        this.ruleIndex = trans.ruleIndex;\n        this.predicateIndex = trans.predIndex;\n    } else {\n        this.ruleIndex = 0;\n        this.predicateIndex = 0;\n    }\n    this.predicate = predicate;\n    this.offendingToken = recognizer.getCurrentToken();\n    return this;\n}\n\nFailedPredicateException.prototype = Object.create(RecognitionException.prototype);\nFailedPredicateException.prototype.constructor = FailedPredicateException;\n\nFailedPredicateException.prototype.formatMessage = function(predicate, message) {\n    if (message !==null) {\n        return message;\n    } else {\n        return \"failed predicate: {\" + predicate + \"}?\";\n    }\n};\n\nfunction ParseCancellationException() {\n\tError.call(this);\n\tError.captureStackTrace(this, ParseCancellationException);\n\treturn this;\n}\n\nParseCancellationException.prototype = Object.create(Error.prototype);\nParseCancellationException.prototype.constructor = ParseCancellationException;\n\nexports.RecognitionException = RecognitionException;\nexports.NoViableAltException = NoViableAltException;\nexports.LexerNoViableAltException = LexerNoViableAltException;\nexports.InputMismatchException = InputMismatchException;\nexports.FailedPredicateException = FailedPredicateException;\nexports.ParseCancellationException = ParseCancellationException;\n\n\n//# sourceURL=webpack:///./antlr4/error/Errors.js?");

/***/ }),

/***/ "./antlr4/error/index.js":
/*!*******************************!*\
  !*** ./antlr4/error/index.js ***!
  \*******************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nexports.RecognitionException = __webpack_require__(/*! ./Errors */ \"./antlr4/error/Errors.js\").RecognitionException;\nexports.NoViableAltException = __webpack_require__(/*! ./Errors */ \"./antlr4/error/Errors.js\").NoViableAltException;\nexports.LexerNoViableAltException = __webpack_require__(/*! ./Errors */ \"./antlr4/error/Errors.js\").LexerNoViableAltException;\nexports.InputMismatchException = __webpack_require__(/*! ./Errors */ \"./antlr4/error/Errors.js\").InputMismatchException;\nexports.FailedPredicateException = __webpack_require__(/*! ./Errors */ \"./antlr4/error/Errors.js\").FailedPredicateException;\nexports.DiagnosticErrorListener = __webpack_require__(/*! ./DiagnosticErrorListener */ \"./antlr4/error/DiagnosticErrorListener.js\").DiagnosticErrorListener;\nexports.BailErrorStrategy = __webpack_require__(/*! ./ErrorStrategy */ \"./antlr4/error/ErrorStrategy.js\").BailErrorStrategy;\nexports.ErrorListener = __webpack_require__(/*! ./ErrorListener */ \"./antlr4/error/ErrorListener.js\").ErrorListener;\n\n\n//# sourceURL=webpack:///./antlr4/error/index.js?");

/***/ }),

/***/ "./antlr4/index.js":
/*!*************************!*\
  !*** ./antlr4/index.js ***!
  \*************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\nexports.atn = __webpack_require__(/*! ./atn/index */ \"./antlr4/atn/index.js\");\nexports.codepointat = __webpack_require__(/*! ./polyfills/codepointat */ \"./antlr4/polyfills/codepointat.js\");\nexports.dfa = __webpack_require__(/*! ./dfa/index */ \"./antlr4/dfa/index.js\");\nexports.fromcodepoint = __webpack_require__(/*! ./polyfills/fromcodepoint */ \"./antlr4/polyfills/fromcodepoint.js\");\nexports.tree = __webpack_require__(/*! ./tree/index */ \"./antlr4/tree/index.js\");\nexports.error = __webpack_require__(/*! ./error/index */ \"./antlr4/error/index.js\");\nexports.Token = __webpack_require__(/*! ./Token */ \"./antlr4/Token.js\").Token;\nexports.CharStreams = __webpack_require__(/*! ./CharStreams */ \"./antlr4/CharStreams.js\").CharStreams;\nexports.CommonToken = __webpack_require__(/*! ./Token */ \"./antlr4/Token.js\").CommonToken;\nexports.InputStream = __webpack_require__(/*! ./InputStream */ \"./antlr4/InputStream.js\").InputStream;\nexports.FileStream = __webpack_require__(/*! ./FileStream */ \"./antlr4/FileStream.js\").FileStream;\nexports.CommonTokenStream = __webpack_require__(/*! ./CommonTokenStream */ \"./antlr4/CommonTokenStream.js\").CommonTokenStream;\nexports.Lexer = __webpack_require__(/*! ./Lexer */ \"./antlr4/Lexer.js\").Lexer;\nexports.Parser = __webpack_require__(/*! ./Parser */ \"./antlr4/Parser.js\").Parser;\nvar pc = __webpack_require__(/*! ./PredictionContext */ \"./antlr4/PredictionContext.js\");\nexports.PredictionContextCache = pc.PredictionContextCache;\nexports.ParserRuleContext = __webpack_require__(/*! ./ParserRuleContext */ \"./antlr4/ParserRuleContext.js\").ParserRuleContext;\nexports.Interval = __webpack_require__(/*! ./IntervalSet */ \"./antlr4/IntervalSet.js\").Interval;\nexports.Utils = __webpack_require__(/*! ./Utils */ \"./antlr4/Utils.js\");\n\n\n//# sourceURL=webpack:///./antlr4/index.js?");

/***/ }),

/***/ "./antlr4/polyfills/codepointat.js":
/*!*****************************************!*\
  !*** ./antlr4/polyfills/codepointat.js ***!
  \*****************************************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("/*! https://mths.be/codepointat v0.2.0 by @mathias */\nif (!String.prototype.codePointAt) {\n\t(function() {\n\t\t'use strict'; // needed to support `apply`/`call` with `undefined`/`null`\n\t\tvar defineProperty = (function() {\n\t\t\t// IE 8 only supports `Object.defineProperty` on DOM elements\n\t\t\ttry {\n\t\t\t\tvar object = {};\n\t\t\t\tvar $defineProperty = Object.defineProperty;\n\t\t\t\tvar result = $defineProperty(object, object, object) && $defineProperty;\n\t\t\t} catch(error) {}\n\t\t\treturn result;\n\t\t}());\n\t\tvar codePointAt = function(position) {\n\t\t\tif (this == null) {\n\t\t\t\tthrow TypeError();\n\t\t\t}\n\t\t\tvar string = String(this);\n\t\t\tvar size = string.length;\n\t\t\t// `ToInteger`\n\t\t\tvar index = position ? Number(position) : 0;\n\t\t\tif (index != index) { // better `isNaN`\n\t\t\t\tindex = 0;\n\t\t\t}\n\t\t\t// Account for out-of-bounds indices:\n\t\t\tif (index < 0 || index >= size) {\n\t\t\t\treturn undefined;\n\t\t\t}\n\t\t\t// Get the first code unit\n\t\t\tvar first = string.charCodeAt(index);\n\t\t\tvar second;\n\t\t\tif ( // check if it’s the start of a surrogate pair\n\t\t\t\tfirst >= 0xD800 && first <= 0xDBFF && // high surrogate\n\t\t\t\tsize > index + 1 // there is a next code unit\n\t\t\t) {\n\t\t\t\tsecond = string.charCodeAt(index + 1);\n\t\t\t\tif (second >= 0xDC00 && second <= 0xDFFF) { // low surrogate\n\t\t\t\t\t// https://mathiasbynens.be/notes/javascript-encoding#surrogate-formulae\n\t\t\t\t\treturn (first - 0xD800) * 0x400 + second - 0xDC00 + 0x10000;\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn first;\n\t\t};\n\t\tif (defineProperty) {\n\t\t\tdefineProperty(String.prototype, 'codePointAt', {\n\t\t\t\t'value': codePointAt,\n\t\t\t\t'configurable': true,\n\t\t\t\t'writable': true\n\t\t\t});\n\t\t} else {\n\t\t\tString.prototype.codePointAt = codePointAt;\n\t\t}\n\t}());\n}\n\n\n//# sourceURL=webpack:///./antlr4/polyfills/codepointat.js?");

/***/ }),

/***/ "./antlr4/polyfills/fromcodepoint.js":
/*!*******************************************!*\
  !*** ./antlr4/polyfills/fromcodepoint.js ***!
  \*******************************************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("/*! https://mths.be/fromcodepoint v0.2.1 by @mathias */\nif (!String.fromCodePoint) {\n\t(function() {\n\t\tvar defineProperty = (function() {\n\t\t\t// IE 8 only supports `Object.defineProperty` on DOM elements\n\t\t\ttry {\n\t\t\t\tvar object = {};\n\t\t\t\tvar $defineProperty = Object.defineProperty;\n\t\t\t\tvar result = $defineProperty(object, object, object) && $defineProperty;\n\t\t\t} catch(error) {}\n\t\t\treturn result;\n\t\t}());\n\t\tvar stringFromCharCode = String.fromCharCode;\n\t\tvar floor = Math.floor;\n\t\tvar fromCodePoint = function(_) {\n\t\t\tvar MAX_SIZE = 0x4000;\n\t\t\tvar codeUnits = [];\n\t\t\tvar highSurrogate;\n\t\t\tvar lowSurrogate;\n\t\t\tvar index = -1;\n\t\t\tvar length = arguments.length;\n\t\t\tif (!length) {\n\t\t\t\treturn '';\n\t\t\t}\n\t\t\tvar result = '';\n\t\t\twhile (++index < length) {\n\t\t\t\tvar codePoint = Number(arguments[index]);\n\t\t\t\tif (\n\t\t\t\t\t!isFinite(codePoint) || // `NaN`, `+Infinity`, or `-Infinity`\n\t\t\t\t\tcodePoint < 0 || // not a valid Unicode code point\n\t\t\t\t\tcodePoint > 0x10FFFF || // not a valid Unicode code point\n\t\t\t\t\tfloor(codePoint) != codePoint // not an integer\n\t\t\t\t) {\n\t\t\t\t\tthrow RangeError('Invalid code point: ' + codePoint);\n\t\t\t\t}\n\t\t\t\tif (codePoint <= 0xFFFF) { // BMP code point\n\t\t\t\t\tcodeUnits.push(codePoint);\n\t\t\t\t} else { // Astral code point; split in surrogate halves\n\t\t\t\t\t// https://mathiasbynens.be/notes/javascript-encoding#surrogate-formulae\n\t\t\t\t\tcodePoint -= 0x10000;\n\t\t\t\t\thighSurrogate = (codePoint >> 10) + 0xD800;\n\t\t\t\t\tlowSurrogate = (codePoint % 0x400) + 0xDC00;\n\t\t\t\t\tcodeUnits.push(highSurrogate, lowSurrogate);\n\t\t\t\t}\n\t\t\t\tif (index + 1 == length || codeUnits.length > MAX_SIZE) {\n\t\t\t\t\tresult += stringFromCharCode.apply(null, codeUnits);\n\t\t\t\t\tcodeUnits.length = 0;\n\t\t\t\t}\n\t\t\t}\n\t\t\treturn result;\n\t\t};\n\t\tif (defineProperty) {\n\t\t\tdefineProperty(String, 'fromCodePoint', {\n\t\t\t\t'value': fromCodePoint,\n\t\t\t\t'configurable': true,\n\t\t\t\t'writable': true\n\t\t\t});\n\t\t} else {\n\t\t\tString.fromCodePoint = fromCodePoint;\n\t\t}\n\t}());\n}\n\n\n//# sourceURL=webpack:///./antlr4/polyfills/fromcodepoint.js?");

/***/ }),

/***/ "./antlr4/tree/Tree.js":
/*!*****************************!*\
  !*** ./antlr4/tree/Tree.js ***!
  \*****************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n///\n\n// The basic notion of a tree has a parent, a payload, and a list of children.\n//  It is the most abstract interface for all the trees used by ANTLR.\n///\n\nvar Token = __webpack_require__(/*! ./../Token */ \"./antlr4/Token.js\").Token;\nvar Interval = __webpack_require__(/*! ./../IntervalSet */ \"./antlr4/IntervalSet.js\").Interval;\nvar INVALID_INTERVAL = new Interval(-1, -2);\nvar Utils = __webpack_require__(/*! ../Utils.js */ \"./antlr4/Utils.js\");\n\n\nfunction Tree() {\n\treturn this;\n}\n\nfunction SyntaxTree() {\n\tTree.call(this);\n\treturn this;\n}\n\nSyntaxTree.prototype = Object.create(Tree.prototype);\nSyntaxTree.prototype.constructor = SyntaxTree;\n\nfunction ParseTree() {\n\tSyntaxTree.call(this);\n\treturn this;\n}\n\nParseTree.prototype = Object.create(SyntaxTree.prototype);\nParseTree.prototype.constructor = ParseTree;\n\nfunction RuleNode() {\n\tParseTree.call(this);\n\treturn this;\n}\n\nRuleNode.prototype = Object.create(ParseTree.prototype);\nRuleNode.prototype.constructor = RuleNode;\n\nfunction TerminalNode() {\n\tParseTree.call(this);\n\treturn this;\n}\n\nTerminalNode.prototype = Object.create(ParseTree.prototype);\nTerminalNode.prototype.constructor = TerminalNode;\n\nfunction ErrorNode() {\n\tTerminalNode.call(this);\n\treturn this;\n}\n\nErrorNode.prototype = Object.create(TerminalNode.prototype);\nErrorNode.prototype.constructor = ErrorNode;\n\nfunction ParseTreeVisitor() {\n\treturn this;\n}\n\nParseTreeVisitor.prototype.visit = function(ctx) {\n \tif (Array.isArray(ctx)) {\n\t\treturn ctx.map(function(child) {\n            return child.accept(this);\n        }, this);\n\t} else {\n\t\treturn ctx.accept(this);\n\t}\n};\n\nParseTreeVisitor.prototype.visitChildren = function(ctx) {\n  return this.visit(ctx.children);\n}\n\nParseTreeVisitor.prototype.visitTerminal = function(node) {\n};\n\nParseTreeVisitor.prototype.visitErrorNode = function(node) {\n};\n\n\nfunction ParseTreeListener() {\n\treturn this;\n}\n\nParseTreeListener.prototype.visitTerminal = function(node) {\n};\n\nParseTreeListener.prototype.visitErrorNode = function(node) {\n};\n\nParseTreeListener.prototype.enterEveryRule = function(node) {\n};\n\nParseTreeListener.prototype.exitEveryRule = function(node) {\n};\n\nfunction TerminalNodeImpl(symbol) {\n\tTerminalNode.call(this);\n\tthis.parentCtx = null;\n\tthis.symbol = symbol;\n\treturn this;\n}\n\nTerminalNodeImpl.prototype = Object.create(TerminalNode.prototype);\nTerminalNodeImpl.prototype.constructor = TerminalNodeImpl;\n\nTerminalNodeImpl.prototype.getChild = function(i) {\n\treturn null;\n};\n\nTerminalNodeImpl.prototype.getSymbol = function() {\n\treturn this.symbol;\n};\n\nTerminalNodeImpl.prototype.getParent = function() {\n\treturn this.parentCtx;\n};\n\nTerminalNodeImpl.prototype.getPayload = function() {\n\treturn this.symbol;\n};\n\nTerminalNodeImpl.prototype.getSourceInterval = function() {\n\tif (this.symbol === null) {\n\t\treturn INVALID_INTERVAL;\n\t}\n\tvar tokenIndex = this.symbol.tokenIndex;\n\treturn new Interval(tokenIndex, tokenIndex);\n};\n\nTerminalNodeImpl.prototype.getChildCount = function() {\n\treturn 0;\n};\n\nTerminalNodeImpl.prototype.accept = function(visitor) {\n\treturn visitor.visitTerminal(this);\n};\n\nTerminalNodeImpl.prototype.getText = function() {\n\treturn this.symbol.text;\n};\n\nTerminalNodeImpl.prototype.toString = function() {\n\tif (this.symbol.type === Token.EOF) {\n\t\treturn \"<EOF>\";\n\t} else {\n\t\treturn this.symbol.text;\n\t}\n};\n\n// Represents a token that was consumed during resynchronization\n// rather than during a valid match operation. For example,\n// we will create this kind of a node during single token insertion\n// and deletion as well as during \"consume until error recovery set\"\n// upon no viable alternative exceptions.\n\nfunction ErrorNodeImpl(token) {\n\tTerminalNodeImpl.call(this, token);\n\treturn this;\n}\n\nErrorNodeImpl.prototype = Object.create(TerminalNodeImpl.prototype);\nErrorNodeImpl.prototype.constructor = ErrorNodeImpl;\n\nErrorNodeImpl.prototype.isErrorNode = function() {\n\treturn true;\n};\n\nErrorNodeImpl.prototype.accept = function(visitor) {\n\treturn visitor.visitErrorNode(this);\n};\n\nfunction ParseTreeWalker() {\n\treturn this;\n}\n\nParseTreeWalker.prototype.walk = function(listener, t) {\n\tvar errorNode = t instanceof ErrorNode ||\n\t\t\t(t.isErrorNode !== undefined && t.isErrorNode());\n\tif (errorNode) {\n\t\tlistener.visitErrorNode(t);\n\t} else if (t instanceof TerminalNode) {\n\t\tlistener.visitTerminal(t);\n\t} else {\n\t\tthis.enterRule(listener, t);\n\t\tfor (var i = 0; i < t.getChildCount(); i++) {\n\t\t\tvar child = t.getChild(i);\n\t\t\tthis.walk(listener, child);\n\t\t}\n\t\tthis.exitRule(listener, t);\n\t}\n};\n//\n// The discovery of a rule node, involves sending two events: the generic\n// {@link ParseTreeListener//enterEveryRule} and a\n// {@link RuleContext}-specific event. First we trigger the generic and then\n// the rule specific. We to them in reverse order upon finishing the node.\n//\nParseTreeWalker.prototype.enterRule = function(listener, r) {\n\tvar ctx = r.getRuleContext();\n\tlistener.enterEveryRule(ctx);\n\tctx.enterRule(listener);\n};\n\nParseTreeWalker.prototype.exitRule = function(listener, r) {\n\tvar ctx = r.getRuleContext();\n\tctx.exitRule(listener);\n\tlistener.exitEveryRule(ctx);\n};\n\nParseTreeWalker.DEFAULT = new ParseTreeWalker();\n\nexports.RuleNode = RuleNode;\nexports.ErrorNode = ErrorNode;\nexports.TerminalNode = TerminalNode;\nexports.ErrorNodeImpl = ErrorNodeImpl;\nexports.TerminalNodeImpl = TerminalNodeImpl;\nexports.ParseTreeListener = ParseTreeListener;\nexports.ParseTreeVisitor = ParseTreeVisitor;\nexports.ParseTreeWalker = ParseTreeWalker;\nexports.INVALID_INTERVAL = INVALID_INTERVAL;\n\n\n//# sourceURL=webpack:///./antlr4/tree/Tree.js?");

/***/ }),

/***/ "./antlr4/tree/Trees.js":
/*!******************************!*\
  !*** ./antlr4/tree/Trees.js ***!
  \******************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nvar Utils = __webpack_require__(/*! ./../Utils */ \"./antlr4/Utils.js\");\nvar Token = __webpack_require__(/*! ./../Token */ \"./antlr4/Token.js\").Token;\nvar RuleNode = __webpack_require__(/*! ./Tree */ \"./antlr4/tree/Tree.js\").RuleNode;\nvar ErrorNode = __webpack_require__(/*! ./Tree */ \"./antlr4/tree/Tree.js\").ErrorNode;\nvar TerminalNode = __webpack_require__(/*! ./Tree */ \"./antlr4/tree/Tree.js\").TerminalNode;\nvar ParserRuleContext = __webpack_require__(/*! ./../ParserRuleContext */ \"./antlr4/ParserRuleContext.js\").ParserRuleContext;\nvar RuleContext = __webpack_require__(/*! ./../RuleContext */ \"./antlr4/RuleContext.js\").RuleContext;\nvar INVALID_ALT_NUMBER = __webpack_require__(/*! ./../atn/ATN */ \"./antlr4/atn/ATN.js\").INVALID_ALT_NUMBER;\n\n\n/** A set of utility routines useful for all kinds of ANTLR trees. */\nfunction Trees() {\n}\n\n// Print out a whole tree in LISP form. {@link //getNodeText} is used on the\n//  node payloads to get the text for the nodes.  Detect\n//  parse trees and extract data appropriately.\nTrees.toStringTree = function(tree, ruleNames, recog) {\n\truleNames = ruleNames || null;\n\trecog = recog || null;\n    if(recog!==null) {\n       ruleNames = recog.ruleNames;\n    }\n    var s = Trees.getNodeText(tree, ruleNames);\n    s = Utils.escapeWhitespace(s, false);\n    var c = tree.getChildCount();\n    if(c===0) {\n        return s;\n    }\n    var res = \"(\" + s + ' ';\n    if(c>0) {\n        s = Trees.toStringTree(tree.getChild(0), ruleNames);\n        res = res.concat(s);\n    }\n    for(var i=1;i<c;i++) {\n        s = Trees.toStringTree(tree.getChild(i), ruleNames);\n        res = res.concat(' ' + s);\n    }\n    res = res.concat(\")\");\n    return res;\n};\n\nTrees.getNodeText = function(t, ruleNames, recog) {\n\truleNames = ruleNames || null;\n\trecog = recog || null;\n    if(recog!==null) {\n        ruleNames = recog.ruleNames;\n    }\n    if(ruleNames!==null) {\n       if (t instanceof RuleContext) {\n           var altNumber = t.getAltNumber();\n           if ( altNumber!=INVALID_ALT_NUMBER ) {\n               return ruleNames[t.ruleIndex]+\":\"+altNumber;\n           }\n           return ruleNames[t.ruleIndex];\n       } else if ( t instanceof ErrorNode) {\n           return t.toString();\n       } else if(t instanceof TerminalNode) {\n           if(t.symbol!==null) {\n               return t.symbol.text;\n           }\n       }\n    }\n    // no recog for rule names\n    var payload = t.getPayload();\n    if (payload instanceof Token ) {\n       return payload.text;\n    }\n    return t.getPayload().toString();\n};\n\n\n// Return ordered list of all children of this node\nTrees.getChildren = function(t) {\n\tvar list = [];\n\tfor(var i=0;i<t.getChildCount();i++) {\n\t\tlist.push(t.getChild(i));\n\t}\n\treturn list;\n};\n\n// Return a list of all ancestors of this node.  The first node of\n//  list is the root and the last is the parent of this node.\n//\nTrees.getAncestors = function(t) {\n    var ancestors = [];\n    t = t.getParent();\n    while(t!==null) {\n        ancestors = [t].concat(ancestors);\n        t = t.getParent();\n    }\n    return ancestors;\n};\n\nTrees.findAllTokenNodes = function(t, ttype) {\n    return Trees.findAllNodes(t, ttype, true);\n};\n\nTrees.findAllRuleNodes = function(t, ruleIndex) {\n\treturn Trees.findAllNodes(t, ruleIndex, false);\n};\n\nTrees.findAllNodes = function(t, index, findTokens) {\n\tvar nodes = [];\n\tTrees._findAllNodes(t, index, findTokens, nodes);\n\treturn nodes;\n};\n\nTrees._findAllNodes = function(t, index, findTokens, nodes) {\n\t// check this node (the root) first\n\tif(findTokens && (t instanceof TerminalNode)) {\n\t\tif(t.symbol.type===index) {\n\t\t\tnodes.push(t);\n\t\t}\n\t} else if(!findTokens && (t instanceof ParserRuleContext)) {\n\t\tif(t.ruleIndex===index) {\n\t\t\tnodes.push(t);\n\t\t}\n\t}\n\t// check children\n\tfor(var i=0;i<t.getChildCount();i++) {\n\t\tTrees._findAllNodes(t.getChild(i), index, findTokens, nodes);\n\t}\n};\n\nTrees.descendants = function(t) {\n\tvar nodes = [t];\n    for(var i=0;i<t.getChildCount();i++) {\n        nodes = nodes.concat(Trees.descendants(t.getChild(i)));\n    }\n    return nodes;\n};\n\n\nexports.Trees = Trees;\n\n//# sourceURL=webpack:///./antlr4/tree/Trees.js?");

/***/ }),

/***/ "./antlr4/tree/index.js":
/*!******************************!*\
  !*** ./antlr4/tree/index.js ***!
  \******************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("/* Copyright (c) 2012-2017 The ANTLR Project. All rights reserved.\n * Use of this file is governed by the BSD 3-clause license that\n * can be found in the LICENSE.txt file in the project root.\n */\n\nvar Tree = __webpack_require__(/*! ./Tree */ \"./antlr4/tree/Tree.js\");\nexports.Trees = __webpack_require__(/*! ./Trees */ \"./antlr4/tree/Trees.js\").Trees;\nexports.RuleNode = Tree.RuleNode;\nexports.ParseTreeListener = Tree.ParseTreeListener;\nexports.ParseTreeVisitor = Tree.ParseTreeVisitor;\nexports.ParseTreeWalker = Tree.ParseTreeWalker;\n\n\n//# sourceURL=webpack:///./antlr4/tree/index.js?");

/***/ }),

/***/ "./childListener.js":
/*!**************************!*\
  !*** ./childListener.js ***!
  \**************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("const antlr4 = __webpack_require__(/*! ./antlr4/index */ \"./antlr4/index.js\");\r\nconst glGrammarLexer = __webpack_require__(/*! ./glGrammarLexer */ \"./glGrammarLexer.js\");\r\nconst glGrammarParser = __webpack_require__(/*! ./glGrammarParser */ \"./glGrammarParser.js\");\r\nvar glGrammarListener = __webpack_require__(/*! ./glGrammarListener */ \"./glGrammarListener.js\").glGrammarListener;\r\n\r\nvar webglImpl = __webpack_require__(/*! ./lab */ \"./lab.js\");\r\n\r\nChildGlGrammarListener = function() {  \r\n    glGrammarListener.call(this); // inherit default listener\r\n    return this;\r\n\r\n};\r\n\r\n// inherit default listener\r\nChildGlGrammarListener.prototype = Object.create(glGrammarListener.prototype);\r\nChildGlGrammarListener.prototype.constructor = ChildGlGrammarListener;\r\n\r\n// override default listener behavior\r\nChildGlGrammarListener.prototype.enterProgram = function(ctx) {             \r\n    console.log(\"Program detected! Proceeding to PARSE....\");\r\n};\r\n\r\nglGrammarListener.prototype.exitProgram = function(ctx) {\r\n    console.log(\"Program END reached! Compilation successful!!!\");\r\n};\r\n\r\n// Enter a parse tree produced by glGrammarParser#programName.\r\nglGrammarListener.prototype.enterProgramName = function(ctx) {\r\n};\r\n    \r\nChildGlGrammarListener.prototype.exitProgramName = function(ctx) {      \r\n\r\n}; \r\n\r\n// Enter a parse tree produced by glGrammarParser#statements.\r\nglGrammarListener.prototype.enterStatements = function(ctx) {\r\n};\r\n\r\n// Exit a parse tree produced by glGrammarParser#statements.\r\nglGrammarListener.prototype.exitStatements = function(ctx) {\r\n\r\n};\r\n\r\n// Enter a parse tree produced by glGrammarParser#action.\r\nglGrammarListener.prototype.enterAction = function(ctx) {\r\n\r\n    webglImpl.setAction(ctx.getText());\r\n\r\n};\r\n\r\n// Exit a parse tree produced by glGrammarParser#action.\r\nglGrammarListener.prototype.exitAction = function(ctx) {\r\n};\r\n\r\n// Enter a parse tree produced by glGrammarParser#argument.\r\nglGrammarListener.prototype.enterArgument = function(ctx) {\r\n};\r\n\r\n// Exit a parse tree produced by glGrammarParser#argument.\r\nglGrammarListener.prototype.exitArgument = function(ctx) {\r\n};\r\n\r\n// Enter a parse tree produced by glGrammarParser#shape.\r\nglGrammarListener.prototype.enterShape = function(ctx) {\r\n    if (ctx.getText() == \"CIRCLE\"){\r\n        webglImpl.setShapeCircle();\r\n    } else if (ctx.getText() == \"SQUARE\"){\r\n        webglImpl.setShapeSquare();\r\n    }\r\n};\r\n\r\n// Exit a parse tree produced by glGrammarParser#shape.\r\nglGrammarListener.prototype.exitShape = function(ctx) {\r\n};\r\n\r\n\r\nChildGlGrammarListener.prototype.enterColor = function(ctx) {\r\n    if (ctx.getText() == 'RED')\r\n        webglImpl.setRedColor();\r\n    else if (ctx.getText() == 'BLUE')\r\n        webglImpl.setBlueColor();\r\n    else if (ctx.getText() == 'BLACK')\r\n        webglImpl.setBlackColor();\r\n    else if (ctx.getText() == 'GREEN')\r\n        webglImpl.setGreenColor();\r\n};\r\n\r\n// Exit a parse tree produced by glGrammarParser#color.\r\nChildGlGrammarListener.prototype.exitColor = function(ctx) {\r\n};\r\n\r\n// Enter a parse tree produced by glGrammarParser#position.\r\nglGrammarListener.prototype.enterPosition = function(ctx) {\r\n    webglImpl.setGlobalXCoord(ctx.DIGIT(0));\r\n    webglImpl.setGlobalYCoord(ctx.DIGIT(1));\r\n};\r\n\r\n// Exit a parse tree produced by glGrammarParser#position.\r\nglGrammarListener.prototype.exitPosition = function(ctx) {\r\n    if (webglImpl.getAction() == 'DRAW')\r\n        webglImpl.drawShape();\r\n    else if (webglImpl.getAction() == 'ROTATE'){\r\n        \r\n    }\r\n};\r\n\r\n// Enter a parse tree produced by glGrammarParser#id.\r\nglGrammarListener.prototype.enterId = function(ctx) {\r\n};\r\n\r\n// Exit a parse tree produced by glGrammarParser#id.\r\nglGrammarListener.prototype.exitId = function(ctx) {\r\n    webglImpl.setObjectId(ctx.getText());\r\n};\r\n\r\n// Enter a parse tree produced by glGrammarParser#alphaNum.\r\nglGrammarListener.prototype.enterAlphaNum = function(ctx) {\r\n};\r\n\r\n// Exit a parse tree produced by glGrammarParser#alphaNum.\r\nglGrammarListener.prototype.exitAlphaNum = function(ctx) {\r\n};\r\n\r\n\r\n// Enter a parse tree produced by glGrammarParser#start.\r\nglGrammarListener.prototype.enterStart = function(ctx) {\r\n};\r\n\r\n// Exit a parse tree produced by glGrammarParser#start.\r\nglGrammarListener.prototype.exitStart = function(ctx) {\r\n};\r\n\r\n\r\n// Enter a parse tree produced by glGrammarParser#size.\r\nglGrammarListener.prototype.enterSize = function(ctx) {\r\n    webglImpl.setGlobalSize(ctx.getText());\r\n};\r\n\r\n// Exit a parse tree produced by glGrammarParser#size.\r\nglGrammarListener.prototype.exitSize = function(ctx) {\r\n    if (webglImpl.getAction() == 'ROTATE'){\r\n        webglImpl.rotateObject();\r\n    }\r\n};\r\n\r\n// Enter a parse tree produced by glGrammarParser#endProgram.\r\nChildGlGrammarListener.prototype.enterEndProgram = function(ctx) {\r\n};\r\n\r\n// Exit a parse tree produced by glGrammarParser#endProgram.\r\nChildGlGrammarListener.prototype.exitEndProgram = function(ctx) {\r\n};\r\n\r\n\r\nexports.ChildGlGrammarListener = ChildGlGrammarListener;\n\n//# sourceURL=webpack:///./childListener.js?");

/***/ }),

/***/ "./ello.js":
/*!*****************!*\
  !*** ./ello.js ***!
  \*****************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\r\nconsole.log(\"Webpack loaded files successfully!!!\");\r\n\r\n\n\n//# sourceURL=webpack:///./ello.js?");

/***/ }),

/***/ "./glGrammarLexer.js":
/*!***************************!*\
  !*** ./glGrammarLexer.js ***!
  \***************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("// Generated from glGrammar.g4 by ANTLR 4.7.1\n// jshint ignore: start\nvar antlr4 = __webpack_require__(/*! ./antlr4/index */ \"./antlr4/index.js\");\n\n\nvar serializedATN = [\"\\u0003\\u608b\\ua72a\\u8133\\ub9ed\\u417c\\u3be7\\u7786\\u5964\",\n    \"\\u0002\\u001f\\u00d4\\b\\u0001\\u0004\\u0002\\t\\u0002\\u0004\\u0003\\t\\u0003\\u0004\",\n    \"\\u0004\\t\\u0004\\u0004\\u0005\\t\\u0005\\u0004\\u0006\\t\\u0006\\u0004\\u0007\\t\",\n    \"\\u0007\\u0004\\b\\t\\b\\u0004\\t\\t\\t\\u0004\\n\\t\\n\\u0004\\u000b\\t\\u000b\\u0004\",\n    \"\\f\\t\\f\\u0004\\r\\t\\r\\u0004\\u000e\\t\\u000e\\u0004\\u000f\\t\\u000f\\u0004\\u0010\",\n    \"\\t\\u0010\\u0004\\u0011\\t\\u0011\\u0004\\u0012\\t\\u0012\\u0004\\u0013\\t\\u0013\",\n    \"\\u0004\\u0014\\t\\u0014\\u0004\\u0015\\t\\u0015\\u0004\\u0016\\t\\u0016\\u0004\\u0017\",\n    \"\\t\\u0017\\u0004\\u0018\\t\\u0018\\u0004\\u0019\\t\\u0019\\u0004\\u001a\\t\\u001a\",\n    \"\\u0004\\u001b\\t\\u001b\\u0004\\u001c\\t\\u001c\\u0004\\u001d\\t\\u001d\\u0004\\u001e\",\n    \"\\t\\u001e\\u0003\\u0002\\u0003\\u0002\\u0003\\u0002\\u0003\\u0002\\u0003\\u0002\",\n    \"\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0003\\u0004\",\n    \"\\u0003\\u0004\\u0003\\u0004\\u0003\\u0004\\u0003\\u0004\\u0003\\u0004\\u0003\\u0005\",\n    \"\\u0003\\u0005\\u0003\\u0005\\u0003\\u0005\\u0003\\u0005\\u0003\\u0005\\u0003\\u0005\",\n    \"\\u0003\\u0006\\u0003\\u0006\\u0003\\u0006\\u0003\\u0006\\u0003\\u0006\\u0003\\u0007\",\n    \"\\u0003\\u0007\\u0003\\u0007\\u0003\\u0007\\u0003\\u0007\\u0003\\u0007\\u0003\\b\",\n    \"\\u0003\\b\\u0003\\b\\u0003\\t\\u0003\\t\\u0003\\t\\u0003\\t\\u0003\\t\\u0003\\t\\u0003\",\n    \"\\t\\u0003\\n\\u0003\\n\\u0003\\n\\u0003\\n\\u0003\\n\\u0003\\n\\u0003\\n\\u0003\\u000b\",\n    \"\\u0003\\u000b\\u0003\\u000b\\u0003\\u000b\\u0003\\u000b\\u0003\\u000b\\u0003\\f\",\n    \"\\u0003\\f\\u0003\\f\\u0003\\f\\u0003\\f\\u0003\\r\\u0003\\r\\u0003\\r\\u0003\\r\\u0003\",\n    \"\\r\\u0003\\r\\u0003\\u000e\\u0003\\u000e\\u0003\\u000e\\u0003\\u000e\\u0003\\u000e\",\n    \"\\u0003\\u000e\\u0003\\u000f\\u0003\\u000f\\u0003\\u000f\\u0003\\u000f\\u0003\\u0010\",\n    \"\\u0003\\u0010\\u0003\\u0010\\u0003\\u0010\\u0003\\u0010\\u0003\\u0010\\u0003\\u0010\",\n    \"\\u0003\\u0011\\u0003\\u0011\\u0003\\u0011\\u0003\\u0011\\u0003\\u0011\\u0003\\u0011\",\n    \"\\u0003\\u0011\\u0003\\u0012\\u0003\\u0012\\u0003\\u0012\\u0003\\u0012\\u0003\\u0012\",\n    \"\\u0003\\u0012\\u0003\\u0012\\u0003\\u0013\\u0003\\u0013\\u0003\\u0013\\u0003\\u0013\",\n    \"\\u0003\\u0013\\u0003\\u0013\\u0003\\u0014\\u0003\\u0014\\u0003\\u0014\\u0003\\u0014\",\n    \"\\u0003\\u0014\\u0003\\u0014\\u0003\\u0015\\u0003\\u0015\\u0003\\u0015\\u0003\\u0015\",\n    \"\\u0003\\u0016\\u0006\\u0016\\u00b2\\n\\u0016\\r\\u0016\\u000e\\u0016\\u00b3\\u0003\",\n    \"\\u0016\\u0006\\u0016\\u00b7\\n\\u0016\\r\\u0016\\u000e\\u0016\\u00b8\\u0005\\u0016\",\n    \"\\u00bb\\n\\u0016\\u0003\\u0017\\u0006\\u0017\\u00be\\n\\u0017\\r\\u0017\\u000e\\u0017\",\n    \"\\u00bf\\u0003\\u0018\\u0003\\u0018\\u0003\\u0019\\u0003\\u0019\\u0003\\u001a\\u0003\",\n    \"\\u001a\\u0003\\u001b\\u0003\\u001b\\u0003\\u001c\\u0003\\u001c\\u0003\\u001d\\u0003\",\n    \"\\u001d\\u0003\\u001e\\u0006\\u001e\\u00cf\\n\\u001e\\r\\u001e\\u000e\\u001e\\u00d0\",\n    \"\\u0003\\u001e\\u0003\\u001e\\u0002\\u0002\\u001f\\u0003\\u0003\\u0005\\u0004\\u0007\",\n    \"\\u0005\\t\\u0006\\u000b\\u0007\\r\\b\\u000f\\t\\u0011\\n\\u0013\\u000b\\u0015\\f\\u0017\",\n    \"\\r\\u0019\\u000e\\u001b\\u000f\\u001d\\u0010\\u001f\\u0011!\\u0012#\\u0013%\\u0014\",\n    \"\\'\\u0015)\\u0016+\\u0017-\\u0018/\\u00191\\u001a3\\u001b5\\u001c7\\u001d9\\u001e\",\n    \";\\u001f\\u0003\\u0002\\u0003\\u0005\\u0002\\u000b\\f\\u000f\\u000f\\\"\\\"\\u0002\",\n    \"\\u00d8\\u0002\\u0003\\u0003\\u0002\\u0002\\u0002\\u0002\\u0005\\u0003\\u0002\\u0002\",\n    \"\\u0002\\u0002\\u0007\\u0003\\u0002\\u0002\\u0002\\u0002\\t\\u0003\\u0002\\u0002\",\n    \"\\u0002\\u0002\\u000b\\u0003\\u0002\\u0002\\u0002\\u0002\\r\\u0003\\u0002\\u0002\",\n    \"\\u0002\\u0002\\u000f\\u0003\\u0002\\u0002\\u0002\\u0002\\u0011\\u0003\\u0002\\u0002\",\n    \"\\u0002\\u0002\\u0013\\u0003\\u0002\\u0002\\u0002\\u0002\\u0015\\u0003\\u0002\\u0002\",\n    \"\\u0002\\u0002\\u0017\\u0003\\u0002\\u0002\\u0002\\u0002\\u0019\\u0003\\u0002\\u0002\",\n    \"\\u0002\\u0002\\u001b\\u0003\\u0002\\u0002\\u0002\\u0002\\u001d\\u0003\\u0002\\u0002\",\n    \"\\u0002\\u0002\\u001f\\u0003\\u0002\\u0002\\u0002\\u0002!\\u0003\\u0002\\u0002\",\n    \"\\u0002\\u0002#\\u0003\\u0002\\u0002\\u0002\\u0002%\\u0003\\u0002\\u0002\\u0002\",\n    \"\\u0002\\'\\u0003\\u0002\\u0002\\u0002\\u0002)\\u0003\\u0002\\u0002\\u0002\\u0002\",\n    \"+\\u0003\\u0002\\u0002\\u0002\\u0002-\\u0003\\u0002\\u0002\\u0002\\u0002/\\u0003\",\n    \"\\u0002\\u0002\\u0002\\u00021\\u0003\\u0002\\u0002\\u0002\\u00023\\u0003\\u0002\",\n    \"\\u0002\\u0002\\u00025\\u0003\\u0002\\u0002\\u0002\\u00027\\u0003\\u0002\\u0002\",\n    \"\\u0002\\u00029\\u0003\\u0002\\u0002\\u0002\\u0002;\\u0003\\u0002\\u0002\\u0002\",\n    \"\\u0003=\\u0003\\u0002\\u0002\\u0002\\u0005B\\u0003\\u0002\\u0002\\u0002\\u0007\",\n    \"G\\u0003\\u0002\\u0002\\u0002\\tM\\u0003\\u0002\\u0002\\u0002\\u000bT\\u0003\\u0002\",\n    \"\\u0002\\u0002\\rY\\u0003\\u0002\\u0002\\u0002\\u000f_\\u0003\\u0002\\u0002\\u0002\",\n    \"\\u0011b\\u0003\\u0002\\u0002\\u0002\\u0013i\\u0003\\u0002\\u0002\\u0002\\u0015\",\n    \"p\\u0003\\u0002\\u0002\\u0002\\u0017v\\u0003\\u0002\\u0002\\u0002\\u0019{\\u0003\",\n    \"\\u0002\\u0002\\u0002\\u001b\\u0081\\u0003\\u0002\\u0002\\u0002\\u001d\\u0087\\u0003\",\n    \"\\u0002\\u0002\\u0002\\u001f\\u008b\\u0003\\u0002\\u0002\\u0002!\\u0092\\u0003\",\n    \"\\u0002\\u0002\\u0002#\\u0099\\u0003\\u0002\\u0002\\u0002%\\u00a0\\u0003\\u0002\",\n    \"\\u0002\\u0002\\'\\u00a6\\u0003\\u0002\\u0002\\u0002)\\u00ac\\u0003\\u0002\\u0002\",\n    \"\\u0002+\\u00ba\\u0003\\u0002\\u0002\\u0002-\\u00bd\\u0003\\u0002\\u0002\\u0002\",\n    \"/\\u00c1\\u0003\\u0002\\u0002\\u00021\\u00c3\\u0003\\u0002\\u0002\\u00023\\u00c5\",\n    \"\\u0003\\u0002\\u0002\\u00025\\u00c7\\u0003\\u0002\\u0002\\u00027\\u00c9\\u0003\",\n    \"\\u0002\\u0002\\u00029\\u00cb\\u0003\\u0002\\u0002\\u0002;\\u00ce\\u0003\\u0002\",\n    \"\\u0002\\u0002=>\\u0007F\\u0002\\u0002>?\\u0007T\\u0002\\u0002?@\\u0007C\\u0002\",\n    \"\\u0002@A\\u0007Y\\u0002\\u0002A\\u0004\\u0003\\u0002\\u0002\\u0002BC\\u0007O\",\n    \"\\u0002\\u0002CD\\u0007Q\\u0002\\u0002DE\\u0007X\\u0002\\u0002EF\\u0007G\\u0002\",\n    \"\\u0002F\\u0006\\u0003\\u0002\\u0002\\u0002GH\\u0007U\\u0002\\u0002HI\\u0007E\",\n    \"\\u0002\\u0002IJ\\u0007C\\u0002\\u0002JK\\u0007N\\u0002\\u0002KL\\u0007G\\u0002\",\n    \"\\u0002L\\b\\u0003\\u0002\\u0002\\u0002MN\\u0007T\\u0002\\u0002NO\\u0007Q\\u0002\",\n    \"\\u0002OP\\u0007V\\u0002\\u0002PQ\\u0007C\\u0002\\u0002QR\\u0007V\\u0002\\u0002\",\n    \"RS\\u0007G\\u0002\\u0002S\\n\\u0003\\u0002\\u0002\\u0002TU\\u0007U\\u0002\\u0002\",\n    \"UV\\u0007K\\u0002\\u0002VW\\u0007\\\\\\u0002\\u0002WX\\u0007G\\u0002\\u0002X\\f\",\n    \"\\u0003\\u0002\\u0002\\u0002YZ\\u0007E\\u0002\\u0002Z[\\u0007Q\\u0002\\u0002[\",\n    \"\\\\\\u0007N\\u0002\\u0002\\\\]\\u0007Q\\u0002\\u0002]^\\u0007T\\u0002\\u0002^\\u000e\",\n    \"\\u0003\\u0002\\u0002\\u0002_`\\u0007C\\u0002\\u0002`a\\u0007V\\u0002\\u0002a\",\n    \"\\u0010\\u0003\\u0002\\u0002\\u0002bc\\u0007E\\u0002\\u0002cd\\u0007K\\u0002\\u0002\",\n    \"de\\u0007T\\u0002\\u0002ef\\u0007E\\u0002\\u0002fg\\u0007N\\u0002\\u0002gh\\u0007\",\n    \"G\\u0002\\u0002h\\u0012\\u0003\\u0002\\u0002\\u0002ij\\u0007U\\u0002\\u0002jk\",\n    \"\\u0007S\\u0002\\u0002kl\\u0007W\\u0002\\u0002lm\\u0007C\\u0002\\u0002mn\\u0007\",\n    \"T\\u0002\\u0002no\\u0007G\\u0002\\u0002o\\u0014\\u0003\\u0002\\u0002\\u0002pq\",\n    \"\\u0007D\\u0002\\u0002qr\\u0007N\\u0002\\u0002rs\\u0007C\\u0002\\u0002st\\u0007\",\n    \"E\\u0002\\u0002tu\\u0007M\\u0002\\u0002u\\u0016\\u0003\\u0002\\u0002\\u0002vw\",\n    \"\\u0007D\\u0002\\u0002wx\\u0007N\\u0002\\u0002xy\\u0007W\\u0002\\u0002yz\\u0007\",\n    \"G\\u0002\\u0002z\\u0018\\u0003\\u0002\\u0002\\u0002{|\\u0007D\\u0002\\u0002|}\",\n    \"\\u0007T\\u0002\\u0002}~\\u0007Q\\u0002\\u0002~\\u007f\\u0007Y\\u0002\\u0002\\u007f\",\n    \"\\u0080\\u0007P\\u0002\\u0002\\u0080\\u001a\\u0003\\u0002\\u0002\\u0002\\u0081\",\n    \"\\u0082\\u0007I\\u0002\\u0002\\u0082\\u0083\\u0007T\\u0002\\u0002\\u0083\\u0084\",\n    \"\\u0007G\\u0002\\u0002\\u0084\\u0085\\u0007G\\u0002\\u0002\\u0085\\u0086\\u0007\",\n    \"P\\u0002\\u0002\\u0086\\u001c\\u0003\\u0002\\u0002\\u0002\\u0087\\u0088\\u0007\",\n    \"T\\u0002\\u0002\\u0088\\u0089\\u0007G\\u0002\\u0002\\u0089\\u008a\\u0007F\\u0002\",\n    \"\\u0002\\u008a\\u001e\\u0003\\u0002\\u0002\\u0002\\u008b\\u008c\\u0007Q\\u0002\",\n    \"\\u0002\\u008c\\u008d\\u0007T\\u0002\\u0002\\u008d\\u008e\\u0007C\\u0002\\u0002\",\n    \"\\u008e\\u008f\\u0007P\\u0002\\u0002\\u008f\\u0090\\u0007I\\u0002\\u0002\\u0090\",\n    \"\\u0091\\u0007G\\u0002\\u0002\\u0091 \\u0003\\u0002\\u0002\\u0002\\u0092\\u0093\",\n    \"\\u0007R\\u0002\\u0002\\u0093\\u0094\\u0007W\\u0002\\u0002\\u0094\\u0095\\u0007\",\n    \"T\\u0002\\u0002\\u0095\\u0096\\u0007R\\u0002\\u0002\\u0096\\u0097\\u0007N\\u0002\",\n    \"\\u0002\\u0097\\u0098\\u0007G\\u0002\\u0002\\u0098\\\"\\u0003\\u0002\\u0002\\u0002\",\n    \"\\u0099\\u009a\\u0007[\\u0002\\u0002\\u009a\\u009b\\u0007G\\u0002\\u0002\\u009b\",\n    \"\\u009c\\u0007N\\u0002\\u0002\\u009c\\u009d\\u0007N\\u0002\\u0002\\u009d\\u009e\",\n    \"\\u0007Q\\u0002\\u0002\\u009e\\u009f\\u0007Y\\u0002\\u0002\\u009f$\\u0003\\u0002\",\n    \"\\u0002\\u0002\\u00a0\\u00a1\\u0007Y\\u0002\\u0002\\u00a1\\u00a2\\u0007J\\u0002\",\n    \"\\u0002\\u00a2\\u00a3\\u0007K\\u0002\\u0002\\u00a3\\u00a4\\u0007V\\u0002\\u0002\",\n    \"\\u00a4\\u00a5\\u0007G\\u0002\\u0002\\u00a5&\\u0003\\u0002\\u0002\\u0002\\u00a6\",\n    \"\\u00a7\\u0007D\\u0002\\u0002\\u00a7\\u00a8\\u0007G\\u0002\\u0002\\u00a8\\u00a9\",\n    \"\\u0007I\\u0002\\u0002\\u00a9\\u00aa\\u0007K\\u0002\\u0002\\u00aa\\u00ab\\u0007\",\n    \"P\\u0002\\u0002\\u00ab(\\u0003\\u0002\\u0002\\u0002\\u00ac\\u00ad\\u0007G\\u0002\",\n    \"\\u0002\\u00ad\\u00ae\\u0007P\\u0002\\u0002\\u00ae\\u00af\\u0007F\\u0002\\u0002\",\n    \"\\u00af*\\u0003\\u0002\\u0002\\u0002\\u00b0\\u00b2\\u0004c|\\u0002\\u00b1\\u00b0\",\n    \"\\u0003\\u0002\\u0002\\u0002\\u00b2\\u00b3\\u0003\\u0002\\u0002\\u0002\\u00b3\\u00b1\",\n    \"\\u0003\\u0002\\u0002\\u0002\\u00b3\\u00b4\\u0003\\u0002\\u0002\\u0002\\u00b4\\u00bb\",\n    \"\\u0003\\u0002\\u0002\\u0002\\u00b5\\u00b7\\u0004C\\\\\\u0002\\u00b6\\u00b5\\u0003\",\n    \"\\u0002\\u0002\\u0002\\u00b7\\u00b8\\u0003\\u0002\\u0002\\u0002\\u00b8\\u00b6\\u0003\",\n    \"\\u0002\\u0002\\u0002\\u00b8\\u00b9\\u0003\\u0002\\u0002\\u0002\\u00b9\\u00bb\\u0003\",\n    \"\\u0002\\u0002\\u0002\\u00ba\\u00b1\\u0003\\u0002\\u0002\\u0002\\u00ba\\u00b6\\u0003\",\n    \"\\u0002\\u0002\\u0002\\u00bb,\\u0003\\u0002\\u0002\\u0002\\u00bc\\u00be\\u0004\",\n    \"2;\\u0002\\u00bd\\u00bc\\u0003\\u0002\\u0002\\u0002\\u00be\\u00bf\\u0003\\u0002\",\n    \"\\u0002\\u0002\\u00bf\\u00bd\\u0003\\u0002\\u0002\\u0002\\u00bf\\u00c0\\u0003\\u0002\",\n    \"\\u0002\\u0002\\u00c0.\\u0003\\u0002\\u0002\\u0002\\u00c1\\u00c2\\u0007.\\u0002\",\n    \"\\u0002\\u00c20\\u0003\\u0002\\u0002\\u0002\\u00c3\\u00c4\\u0007*\\u0002\\u0002\",\n    \"\\u00c42\\u0003\\u0002\\u0002\\u0002\\u00c5\\u00c6\\u0007+\\u0002\\u0002\\u00c6\",\n    \"4\\u0003\\u0002\\u0002\\u0002\\u00c7\\u00c8\\u0007}\\u0002\\u0002\\u00c86\\u0003\",\n    \"\\u0002\\u0002\\u0002\\u00c9\\u00ca\\u0007\\u007f\\u0002\\u0002\\u00ca8\\u0003\",\n    \"\\u0002\\u0002\\u0002\\u00cb\\u00cc\\u0007=\\u0002\\u0002\\u00cc:\\u0003\\u0002\",\n    \"\\u0002\\u0002\\u00cd\\u00cf\\t\\u0002\\u0002\\u0002\\u00ce\\u00cd\\u0003\\u0002\",\n    \"\\u0002\\u0002\\u00cf\\u00d0\\u0003\\u0002\\u0002\\u0002\\u00d0\\u00ce\\u0003\\u0002\",\n    \"\\u0002\\u0002\\u00d0\\u00d1\\u0003\\u0002\\u0002\\u0002\\u00d1\\u00d2\\u0003\\u0002\",\n    \"\\u0002\\u0002\\u00d2\\u00d3\\b\\u001e\\u0002\\u0002\\u00d3<\\u0003\\u0002\\u0002\",\n    \"\\u0002\\b\\u0002\\u00b3\\u00b8\\u00ba\\u00bf\\u00d0\\u0003\\b\\u0002\\u0002\"].join(\"\");\n\n\nvar atn = new antlr4.atn.ATNDeserializer().deserialize(serializedATN);\n\nvar decisionsToDFA = atn.decisionToState.map( function(ds, index) { return new antlr4.dfa.DFA(ds, index); });\n\nfunction glGrammarLexer(input) {\n\tantlr4.Lexer.call(this, input);\n    this._interp = new antlr4.atn.LexerATNSimulator(this, atn, decisionsToDFA, new antlr4.PredictionContextCache());\n    return this;\n}\n\nglGrammarLexer.prototype = Object.create(antlr4.Lexer.prototype);\nglGrammarLexer.prototype.constructor = glGrammarLexer;\n\nObject.defineProperty(glGrammarLexer.prototype, \"atn\", {\n        get : function() {\n                return atn;\n        }\n});\n\nglGrammarLexer.EOF = antlr4.Token.EOF;\nglGrammarLexer.T__0 = 1;\nglGrammarLexer.T__1 = 2;\nglGrammarLexer.T__2 = 3;\nglGrammarLexer.T__3 = 4;\nglGrammarLexer.T__4 = 5;\nglGrammarLexer.T__5 = 6;\nglGrammarLexer.T__6 = 7;\nglGrammarLexer.T__7 = 8;\nglGrammarLexer.T__8 = 9;\nglGrammarLexer.T__9 = 10;\nglGrammarLexer.T__10 = 11;\nglGrammarLexer.T__11 = 12;\nglGrammarLexer.T__12 = 13;\nglGrammarLexer.T__13 = 14;\nglGrammarLexer.T__14 = 15;\nglGrammarLexer.T__15 = 16;\nglGrammarLexer.T__16 = 17;\nglGrammarLexer.T__17 = 18;\nglGrammarLexer.T__18 = 19;\nglGrammarLexer.T__19 = 20;\nglGrammarLexer.ALPHA = 21;\nglGrammarLexer.DIGIT = 22;\nglGrammarLexer.COMMA = 23;\nglGrammarLexer.LPAREN = 24;\nglGrammarLexer.RPAREN = 25;\nglGrammarLexer.LCBRACE = 26;\nglGrammarLexer.RCBRACE = 27;\nglGrammarLexer.PANDC = 28;\nglGrammarLexer.WS = 29;\n\nglGrammarLexer.prototype.channelNames = [ \"DEFAULT_TOKEN_CHANNEL\", \"HIDDEN\" ];\n\nglGrammarLexer.prototype.modeNames = [ \"DEFAULT_MODE\" ];\n\nglGrammarLexer.prototype.literalNames = [ null, \"'DRAW'\", \"'MOVE'\", \"'SCALE'\", \n                                          \"'ROTATE'\", \"'SIZE'\", \"'COLOR'\", \n                                          \"'AT'\", \"'CIRCLE'\", \"'SQUARE'\", \n                                          \"'BLACK'\", \"'BLUE'\", \"'BROWN'\", \n                                          \"'GREEN'\", \"'RED'\", \"'ORANGE'\", \n                                          \"'PURPLE'\", \"'YELLOW'\", \"'WHITE'\", \n                                          \"'BEGIN'\", \"'END'\", null, null, \n                                          \"','\", \"'('\", \"')'\", \"'{'\", \"'}'\", \n                                          \"';'\" ];\n\nglGrammarLexer.prototype.symbolicNames = [ null, null, null, null, null, \n                                           null, null, null, null, null, \n                                           null, null, null, null, null, \n                                           null, null, null, null, null, \n                                           null, \"ALPHA\", \"DIGIT\", \"COMMA\", \n                                           \"LPAREN\", \"RPAREN\", \"LCBRACE\", \n                                           \"RCBRACE\", \"PANDC\", \"WS\" ];\n\nglGrammarLexer.prototype.ruleNames = [ \"T__0\", \"T__1\", \"T__2\", \"T__3\", \"T__4\", \n                                       \"T__5\", \"T__6\", \"T__7\", \"T__8\", \"T__9\", \n                                       \"T__10\", \"T__11\", \"T__12\", \"T__13\", \n                                       \"T__14\", \"T__15\", \"T__16\", \"T__17\", \n                                       \"T__18\", \"T__19\", \"ALPHA\", \"DIGIT\", \n                                       \"COMMA\", \"LPAREN\", \"RPAREN\", \"LCBRACE\", \n                                       \"RCBRACE\", \"PANDC\", \"WS\" ];\n\nglGrammarLexer.prototype.grammarFileName = \"glGrammar.g4\";\n\n\n\nexports.glGrammarLexer = glGrammarLexer;\n\n\n\n//# sourceURL=webpack:///./glGrammarLexer.js?");

/***/ }),

/***/ "./glGrammarListener.js":
/*!******************************!*\
  !*** ./glGrammarListener.js ***!
  \******************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("// Generated from glGrammar.g4 by ANTLR 4.7.1\n// jshint ignore: start\nvar antlr4 = __webpack_require__(/*! ./antlr4/index */ \"./antlr4/index.js\");\n\n// This class defines a complete listener for a parse tree produced by glGrammarParser.\nfunction glGrammarListener() {\n\tantlr4.tree.ParseTreeListener.call(this);\n\treturn this;\n}\n\nglGrammarListener.prototype = Object.create(antlr4.tree.ParseTreeListener.prototype);\nglGrammarListener.prototype.constructor = glGrammarListener;\n\n// Enter a parse tree produced by glGrammarParser#program.\nglGrammarListener.prototype.enterProgram = function(ctx) {\n};\n\n// Exit a parse tree produced by glGrammarParser#program.\nglGrammarListener.prototype.exitProgram = function(ctx) {\n};\n\n\n// Enter a parse tree produced by glGrammarParser#programName.\nglGrammarListener.prototype.enterProgramName = function(ctx) {\n};\n\n// Exit a parse tree produced by glGrammarParser#programName.\nglGrammarListener.prototype.exitProgramName = function(ctx) {\n};\n\n\n// Enter a parse tree produced by glGrammarParser#statements.\nglGrammarListener.prototype.enterStatements = function(ctx) {\n};\n\n// Exit a parse tree produced by glGrammarParser#statements.\nglGrammarListener.prototype.exitStatements = function(ctx) {\n};\n\n\n// Enter a parse tree produced by glGrammarParser#action.\nglGrammarListener.prototype.enterAction = function(ctx) {\n};\n\n// Exit a parse tree produced by glGrammarParser#action.\nglGrammarListener.prototype.exitAction = function(ctx) {\n};\n\n\n// Enter a parse tree produced by glGrammarParser#argument.\nglGrammarListener.prototype.enterArgument = function(ctx) {\n};\n\n// Exit a parse tree produced by glGrammarParser#argument.\nglGrammarListener.prototype.exitArgument = function(ctx) {\n};\n\n\n// Enter a parse tree produced by glGrammarParser#size.\nglGrammarListener.prototype.enterSize = function(ctx) {\n};\n\n// Exit a parse tree produced by glGrammarParser#size.\nglGrammarListener.prototype.exitSize = function(ctx) {\n};\n\n\n// Enter a parse tree produced by glGrammarParser#shape.\nglGrammarListener.prototype.enterShape = function(ctx) {\n};\n\n// Exit a parse tree produced by glGrammarParser#shape.\nglGrammarListener.prototype.exitShape = function(ctx) {\n};\n\n\n// Enter a parse tree produced by glGrammarParser#color.\nglGrammarListener.prototype.enterColor = function(ctx) {\n};\n\n// Exit a parse tree produced by glGrammarParser#color.\nglGrammarListener.prototype.exitColor = function(ctx) {\n};\n\n\n// Enter a parse tree produced by glGrammarParser#position.\nglGrammarListener.prototype.enterPosition = function(ctx) {\n};\n\n// Exit a parse tree produced by glGrammarParser#position.\nglGrammarListener.prototype.exitPosition = function(ctx) {\n};\n\n\n// Enter a parse tree produced by glGrammarParser#id.\nglGrammarListener.prototype.enterId = function(ctx) {\n};\n\n// Exit a parse tree produced by glGrammarParser#id.\nglGrammarListener.prototype.exitId = function(ctx) {\n};\n\n\n// Enter a parse tree produced by glGrammarParser#alphaNum.\nglGrammarListener.prototype.enterAlphaNum = function(ctx) {\n};\n\n// Exit a parse tree produced by glGrammarParser#alphaNum.\nglGrammarListener.prototype.exitAlphaNum = function(ctx) {\n};\n\n\n// Enter a parse tree produced by glGrammarParser#start.\nglGrammarListener.prototype.enterStart = function(ctx) {\n};\n\n// Exit a parse tree produced by glGrammarParser#start.\nglGrammarListener.prototype.exitStart = function(ctx) {\n};\n\n\n// Enter a parse tree produced by glGrammarParser#endProgram.\nglGrammarListener.prototype.enterEndProgram = function(ctx) {\n};\n\n// Exit a parse tree produced by glGrammarParser#endProgram.\nglGrammarListener.prototype.exitEndProgram = function(ctx) {\n};\n\n\n\nexports.glGrammarListener = glGrammarListener;\n\n//# sourceURL=webpack:///./glGrammarListener.js?");

/***/ }),

/***/ "./glGrammarParser.js":
/*!****************************!*\
  !*** ./glGrammarParser.js ***!
  \****************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("// Generated from glGrammar.g4 by ANTLR 4.7.1\n// jshint ignore: start\nvar antlr4 = __webpack_require__(/*! ./antlr4/index */ \"./antlr4/index.js\");\nvar glGrammarListener = __webpack_require__(/*! ./glGrammarListener */ \"./glGrammarListener.js\").glGrammarListener;\nvar grammarFileName = \"glGrammar.g4\";\n\nvar serializedATN = [\"\\u0003\\u608b\\ua72a\\u8133\\ub9ed\\u417c\\u3be7\\u7786\\u5964\",\n    \"\\u0003\\u001f]\\u0004\\u0002\\t\\u0002\\u0004\\u0003\\t\\u0003\\u0004\\u0004\\t\",\n    \"\\u0004\\u0004\\u0005\\t\\u0005\\u0004\\u0006\\t\\u0006\\u0004\\u0007\\t\\u0007\\u0004\",\n    \"\\b\\t\\b\\u0004\\t\\t\\t\\u0004\\n\\t\\n\\u0004\\u000b\\t\\u000b\\u0004\\f\\t\\f\\u0004\",\n    \"\\r\\t\\r\\u0004\\u000e\\t\\u000e\\u0003\\u0002\\u0003\\u0002\\u0003\\u0002\\u0003\",\n    \"\\u0002\\u0003\\u0002\\u0003\\u0002\\u0003\\u0002\\u0003\\u0003\\u0003\\u0003\\u0003\",\n    \"\\u0004\\u0003\\u0004\\u0003\\u0004\\u0003\\u0004\\u0003\\u0004\\u0003\\u0004\\u0007\",\n    \"\\u0004,\\n\\u0004\\f\\u0004\\u000e\\u0004/\\u000b\\u0004\\u0003\\u0005\\u0003\\u0005\",\n    \"\\u0003\\u0006\\u0003\\u0006\\u0003\\u0006\\u0003\\u0006\\u0003\\u0006\\u0003\\u0006\",\n    \"\\u0003\\u0006\\u0003\\u0006\\u0003\\u0006\\u0003\\u0006\\u0003\\u0006\\u0003\\u0006\",\n    \"\\u0003\\u0006\\u0003\\u0006\\u0003\\u0006\\u0003\\u0006\\u0003\\u0006\\u0005\\u0006\",\n    \"D\\n\\u0006\\u0003\\u0007\\u0003\\u0007\\u0003\\b\\u0003\\b\\u0003\\t\\u0003\\t\\u0003\",\n    \"\\n\\u0003\\n\\u0003\\n\\u0003\\n\\u0003\\u000b\\u0003\\u000b\\u0007\\u000bR\\n\\u000b\",\n    \"\\f\\u000b\\u000e\\u000bU\\u000b\\u000b\\u0003\\f\\u0003\\f\\u0003\\r\\u0003\\r\\u0003\",\n    \"\\u000e\\u0003\\u000e\\u0003\\u000e\\u0002\\u0002\\u000f\\u0002\\u0004\\u0006\\b\",\n    \"\\n\\f\\u000e\\u0010\\u0012\\u0014\\u0016\\u0018\\u001a\\u0002\\u0006\\u0003\\u0002\",\n    \"\\u0003\\u0006\\u0003\\u0002\\n\\u000b\\u0003\\u0002\\f\\u0014\\u0003\\u0002\\u0017\",\n    \"\\u0018\\u0002T\\u0002\\u001c\\u0003\\u0002\\u0002\\u0002\\u0004#\\u0003\\u0002\",\n    \"\\u0002\\u0002\\u0006-\\u0003\\u0002\\u0002\\u0002\\b0\\u0003\\u0002\\u0002\\u0002\",\n    \"\\nC\\u0003\\u0002\\u0002\\u0002\\fE\\u0003\\u0002\\u0002\\u0002\\u000eG\\u0003\",\n    \"\\u0002\\u0002\\u0002\\u0010I\\u0003\\u0002\\u0002\\u0002\\u0012K\\u0003\\u0002\",\n    \"\\u0002\\u0002\\u0014O\\u0003\\u0002\\u0002\\u0002\\u0016V\\u0003\\u0002\\u0002\",\n    \"\\u0002\\u0018X\\u0003\\u0002\\u0002\\u0002\\u001aZ\\u0003\\u0002\\u0002\\u0002\",\n    \"\\u001c\\u001d\\u0005\\u0018\\r\\u0002\\u001d\\u001e\\u0005\\u0004\\u0003\\u0002\",\n    \"\\u001e\\u001f\\u0007\\u001c\\u0002\\u0002\\u001f \\u0005\\u0006\\u0004\\u0002\",\n    \" !\\u0007\\u001d\\u0002\\u0002!\\\"\\u0005\\u001a\\u000e\\u0002\\\"\\u0003\\u0003\",\n    \"\\u0002\\u0002\\u0002#$\\u0005\\u0014\\u000b\\u0002$\\u0005\\u0003\\u0002\\u0002\",\n    \"\\u0002%&\\u0005\\b\\u0005\\u0002&\\'\\u0007\\u001a\\u0002\\u0002\\'(\\u0005\\n\\u0006\",\n    \"\\u0002()\\u0007\\u001b\\u0002\\u0002)*\\u0007\\u001e\\u0002\\u0002*,\\u0003\\u0002\",\n    \"\\u0002\\u0002+%\\u0003\\u0002\\u0002\\u0002,/\\u0003\\u0002\\u0002\\u0002-+\\u0003\",\n    \"\\u0002\\u0002\\u0002-.\\u0003\\u0002\\u0002\\u0002.\\u0007\\u0003\\u0002\\u0002\",\n    \"\\u0002/-\\u0003\\u0002\\u0002\\u000201\\t\\u0002\\u0002\\u00021\\t\\u0003\\u0002\",\n    \"\\u0002\\u000223\\u0005\\u000e\\b\\u000234\\u0005\\u0014\\u000b\\u000245\\u0007\",\n    \"\\u0007\\u0002\\u000256\\u0005\\f\\u0007\\u000267\\u0007\\b\\u0002\\u000278\\u0005\",\n    \"\\u0010\\t\\u000289\\u0007\\t\\u0002\\u00029:\\u0005\\u0012\\n\\u0002:D\\u0003\\u0002\",\n    \"\\u0002\\u0002;<\\u0005\\u0014\\u000b\\u0002<=\\u0007\\t\\u0002\\u0002=>\\u0005\",\n    \"\\u0012\\n\\u0002>D\\u0003\\u0002\\u0002\\u0002?@\\u0005\\u0014\\u000b\\u0002@\",\n    \"A\\u0005\\f\\u0007\\u0002AD\\u0003\\u0002\\u0002\\u0002BD\\u0005\\u0014\\u000b\",\n    \"\\u0002C2\\u0003\\u0002\\u0002\\u0002C;\\u0003\\u0002\\u0002\\u0002C?\\u0003\\u0002\",\n    \"\\u0002\\u0002CB\\u0003\\u0002\\u0002\\u0002D\\u000b\\u0003\\u0002\\u0002\\u0002\",\n    \"EF\\u0007\\u0018\\u0002\\u0002F\\r\\u0003\\u0002\\u0002\\u0002GH\\t\\u0003\\u0002\",\n    \"\\u0002H\\u000f\\u0003\\u0002\\u0002\\u0002IJ\\t\\u0004\\u0002\\u0002J\\u0011\\u0003\",\n    \"\\u0002\\u0002\\u0002KL\\u0007\\u0018\\u0002\\u0002LM\\u0007\\u0019\\u0002\\u0002\",\n    \"MN\\u0007\\u0018\\u0002\\u0002N\\u0013\\u0003\\u0002\\u0002\\u0002OS\\u0007\\u0017\",\n    \"\\u0002\\u0002PR\\u0005\\u0016\\f\\u0002QP\\u0003\\u0002\\u0002\\u0002RU\\u0003\",\n    \"\\u0002\\u0002\\u0002SQ\\u0003\\u0002\\u0002\\u0002ST\\u0003\\u0002\\u0002\\u0002\",\n    \"T\\u0015\\u0003\\u0002\\u0002\\u0002US\\u0003\\u0002\\u0002\\u0002VW\\t\\u0005\",\n    \"\\u0002\\u0002W\\u0017\\u0003\\u0002\\u0002\\u0002XY\\u0007\\u0015\\u0002\\u0002\",\n    \"Y\\u0019\\u0003\\u0002\\u0002\\u0002Z[\\u0007\\u0016\\u0002\\u0002[\\u001b\\u0003\",\n    \"\\u0002\\u0002\\u0002\\u0005-CS\"].join(\"\");\n\n\nvar atn = new antlr4.atn.ATNDeserializer().deserialize(serializedATN);\n\nvar decisionsToDFA = atn.decisionToState.map( function(ds, index) { return new antlr4.dfa.DFA(ds, index); });\n\nvar sharedContextCache = new antlr4.PredictionContextCache();\n\nvar literalNames = [ null, \"'DRAW'\", \"'MOVE'\", \"'SCALE'\", \"'ROTATE'\", \"'SIZE'\", \n                     \"'COLOR'\", \"'AT'\", \"'CIRCLE'\", \"'SQUARE'\", \"'BLACK'\", \n                     \"'BLUE'\", \"'BROWN'\", \"'GREEN'\", \"'RED'\", \"'ORANGE'\", \n                     \"'PURPLE'\", \"'YELLOW'\", \"'WHITE'\", \"'BEGIN'\", \"'END'\", \n                     null, null, \"','\", \"'('\", \"')'\", \"'{'\", \"'}'\", \"';'\" ];\n\nvar symbolicNames = [ null, null, null, null, null, null, null, null, null, \n                      null, null, null, null, null, null, null, null, null, \n                      null, null, null, \"ALPHA\", \"DIGIT\", \"COMMA\", \"LPAREN\", \n                      \"RPAREN\", \"LCBRACE\", \"RCBRACE\", \"PANDC\", \"WS\" ];\n\nvar ruleNames =  [ \"program\", \"programName\", \"statements\", \"action\", \"argument\", \n                   \"size\", \"shape\", \"color\", \"position\", \"id\", \"alphaNum\", \n                   \"start\", \"endProgram\" ];\n\nfunction glGrammarParser (input) {\n\tantlr4.Parser.call(this, input);\n    this._interp = new antlr4.atn.ParserATNSimulator(this, atn, decisionsToDFA, sharedContextCache);\n    this.ruleNames = ruleNames;\n    this.literalNames = literalNames;\n    this.symbolicNames = symbolicNames;\n    return this;\n}\n\nglGrammarParser.prototype = Object.create(antlr4.Parser.prototype);\nglGrammarParser.prototype.constructor = glGrammarParser;\n\nObject.defineProperty(glGrammarParser.prototype, \"atn\", {\n\tget : function() {\n\t\treturn atn;\n\t}\n});\n\nglGrammarParser.EOF = antlr4.Token.EOF;\nglGrammarParser.T__0 = 1;\nglGrammarParser.T__1 = 2;\nglGrammarParser.T__2 = 3;\nglGrammarParser.T__3 = 4;\nglGrammarParser.T__4 = 5;\nglGrammarParser.T__5 = 6;\nglGrammarParser.T__6 = 7;\nglGrammarParser.T__7 = 8;\nglGrammarParser.T__8 = 9;\nglGrammarParser.T__9 = 10;\nglGrammarParser.T__10 = 11;\nglGrammarParser.T__11 = 12;\nglGrammarParser.T__12 = 13;\nglGrammarParser.T__13 = 14;\nglGrammarParser.T__14 = 15;\nglGrammarParser.T__15 = 16;\nglGrammarParser.T__16 = 17;\nglGrammarParser.T__17 = 18;\nglGrammarParser.T__18 = 19;\nglGrammarParser.T__19 = 20;\nglGrammarParser.ALPHA = 21;\nglGrammarParser.DIGIT = 22;\nglGrammarParser.COMMA = 23;\nglGrammarParser.LPAREN = 24;\nglGrammarParser.RPAREN = 25;\nglGrammarParser.LCBRACE = 26;\nglGrammarParser.RCBRACE = 27;\nglGrammarParser.PANDC = 28;\nglGrammarParser.WS = 29;\n\nglGrammarParser.RULE_program = 0;\nglGrammarParser.RULE_programName = 1;\nglGrammarParser.RULE_statements = 2;\nglGrammarParser.RULE_action = 3;\nglGrammarParser.RULE_argument = 4;\nglGrammarParser.RULE_size = 5;\nglGrammarParser.RULE_shape = 6;\nglGrammarParser.RULE_color = 7;\nglGrammarParser.RULE_position = 8;\nglGrammarParser.RULE_id = 9;\nglGrammarParser.RULE_alphaNum = 10;\nglGrammarParser.RULE_start = 11;\nglGrammarParser.RULE_endProgram = 12;\n\nfunction ProgramContext(parser, parent, invokingState) {\n\tif(parent===undefined) {\n\t    parent = null;\n\t}\n\tif(invokingState===undefined || invokingState===null) {\n\t\tinvokingState = -1;\n\t}\n\tantlr4.ParserRuleContext.call(this, parent, invokingState);\n    this.parser = parser;\n    this.ruleIndex = glGrammarParser.RULE_program;\n    return this;\n}\n\nProgramContext.prototype = Object.create(antlr4.ParserRuleContext.prototype);\nProgramContext.prototype.constructor = ProgramContext;\n\nProgramContext.prototype.start = function() {\n    return this.getTypedRuleContext(StartContext,0);\n};\n\nProgramContext.prototype.programName = function() {\n    return this.getTypedRuleContext(ProgramNameContext,0);\n};\n\nProgramContext.prototype.LCBRACE = function() {\n    return this.getToken(glGrammarParser.LCBRACE, 0);\n};\n\nProgramContext.prototype.statements = function() {\n    return this.getTypedRuleContext(StatementsContext,0);\n};\n\nProgramContext.prototype.RCBRACE = function() {\n    return this.getToken(glGrammarParser.RCBRACE, 0);\n};\n\nProgramContext.prototype.endProgram = function() {\n    return this.getTypedRuleContext(EndProgramContext,0);\n};\n\nProgramContext.prototype.enterRule = function(listener) {\n    if(listener instanceof glGrammarListener ) {\n        listener.enterProgram(this);\n\t}\n};\n\nProgramContext.prototype.exitRule = function(listener) {\n    if(listener instanceof glGrammarListener ) {\n        listener.exitProgram(this);\n\t}\n};\n\n\n\n\nglGrammarParser.ProgramContext = ProgramContext;\n\nglGrammarParser.prototype.program = function() {\n\n    var localctx = new ProgramContext(this, this._ctx, this.state);\n    this.enterRule(localctx, 0, glGrammarParser.RULE_program);\n    try {\n        this.enterOuterAlt(localctx, 1);\n        this.state = 26;\n        this.start();\n        this.state = 27;\n        this.programName();\n        this.state = 28;\n        this.match(glGrammarParser.LCBRACE);\n        this.state = 29;\n        this.statements();\n        this.state = 30;\n        this.match(glGrammarParser.RCBRACE);\n        this.state = 31;\n        this.endProgram();\n    } catch (re) {\n    \tif(re instanceof antlr4.error.RecognitionException) {\n\t        localctx.exception = re;\n\t        this._errHandler.reportError(this, re);\n\t        this._errHandler.recover(this, re);\n\t    } else {\n\t    \tthrow re;\n\t    }\n    } finally {\n        this.exitRule();\n    }\n    return localctx;\n};\n\nfunction ProgramNameContext(parser, parent, invokingState) {\n\tif(parent===undefined) {\n\t    parent = null;\n\t}\n\tif(invokingState===undefined || invokingState===null) {\n\t\tinvokingState = -1;\n\t}\n\tantlr4.ParserRuleContext.call(this, parent, invokingState);\n    this.parser = parser;\n    this.ruleIndex = glGrammarParser.RULE_programName;\n    return this;\n}\n\nProgramNameContext.prototype = Object.create(antlr4.ParserRuleContext.prototype);\nProgramNameContext.prototype.constructor = ProgramNameContext;\n\nProgramNameContext.prototype.id = function() {\n    return this.getTypedRuleContext(IdContext,0);\n};\n\nProgramNameContext.prototype.enterRule = function(listener) {\n    if(listener instanceof glGrammarListener ) {\n        listener.enterProgramName(this);\n\t}\n};\n\nProgramNameContext.prototype.exitRule = function(listener) {\n    if(listener instanceof glGrammarListener ) {\n        listener.exitProgramName(this);\n\t}\n};\n\n\n\n\nglGrammarParser.ProgramNameContext = ProgramNameContext;\n\nglGrammarParser.prototype.programName = function() {\n\n    var localctx = new ProgramNameContext(this, this._ctx, this.state);\n    this.enterRule(localctx, 2, glGrammarParser.RULE_programName);\n    try {\n        this.enterOuterAlt(localctx, 1);\n        this.state = 33;\n        this.id();\n    } catch (re) {\n    \tif(re instanceof antlr4.error.RecognitionException) {\n\t        localctx.exception = re;\n\t        this._errHandler.reportError(this, re);\n\t        this._errHandler.recover(this, re);\n\t    } else {\n\t    \tthrow re;\n\t    }\n    } finally {\n        this.exitRule();\n    }\n    return localctx;\n};\n\nfunction StatementsContext(parser, parent, invokingState) {\n\tif(parent===undefined) {\n\t    parent = null;\n\t}\n\tif(invokingState===undefined || invokingState===null) {\n\t\tinvokingState = -1;\n\t}\n\tantlr4.ParserRuleContext.call(this, parent, invokingState);\n    this.parser = parser;\n    this.ruleIndex = glGrammarParser.RULE_statements;\n    return this;\n}\n\nStatementsContext.prototype = Object.create(antlr4.ParserRuleContext.prototype);\nStatementsContext.prototype.constructor = StatementsContext;\n\nStatementsContext.prototype.action = function(i) {\n    if(i===undefined) {\n        i = null;\n    }\n    if(i===null) {\n        return this.getTypedRuleContexts(ActionContext);\n    } else {\n        return this.getTypedRuleContext(ActionContext,i);\n    }\n};\n\nStatementsContext.prototype.LPAREN = function(i) {\n\tif(i===undefined) {\n\t\ti = null;\n\t}\n    if(i===null) {\n        return this.getTokens(glGrammarParser.LPAREN);\n    } else {\n        return this.getToken(glGrammarParser.LPAREN, i);\n    }\n};\n\n\nStatementsContext.prototype.argument = function(i) {\n    if(i===undefined) {\n        i = null;\n    }\n    if(i===null) {\n        return this.getTypedRuleContexts(ArgumentContext);\n    } else {\n        return this.getTypedRuleContext(ArgumentContext,i);\n    }\n};\n\nStatementsContext.prototype.RPAREN = function(i) {\n\tif(i===undefined) {\n\t\ti = null;\n\t}\n    if(i===null) {\n        return this.getTokens(glGrammarParser.RPAREN);\n    } else {\n        return this.getToken(glGrammarParser.RPAREN, i);\n    }\n};\n\n\nStatementsContext.prototype.PANDC = function(i) {\n\tif(i===undefined) {\n\t\ti = null;\n\t}\n    if(i===null) {\n        return this.getTokens(glGrammarParser.PANDC);\n    } else {\n        return this.getToken(glGrammarParser.PANDC, i);\n    }\n};\n\n\nStatementsContext.prototype.enterRule = function(listener) {\n    if(listener instanceof glGrammarListener ) {\n        listener.enterStatements(this);\n\t}\n};\n\nStatementsContext.prototype.exitRule = function(listener) {\n    if(listener instanceof glGrammarListener ) {\n        listener.exitStatements(this);\n\t}\n};\n\n\n\n\nglGrammarParser.StatementsContext = StatementsContext;\n\nglGrammarParser.prototype.statements = function() {\n\n    var localctx = new StatementsContext(this, this._ctx, this.state);\n    this.enterRule(localctx, 4, glGrammarParser.RULE_statements);\n    var _la = 0; // Token type\n    try {\n        this.enterOuterAlt(localctx, 1);\n        this.state = 43;\n        this._errHandler.sync(this);\n        _la = this._input.LA(1);\n        while((((_la) & ~0x1f) == 0 && ((1 << _la) & ((1 << glGrammarParser.T__0) | (1 << glGrammarParser.T__1) | (1 << glGrammarParser.T__2) | (1 << glGrammarParser.T__3))) !== 0)) {\n            this.state = 35;\n            this.action();\n            this.state = 36;\n            this.match(glGrammarParser.LPAREN);\n            this.state = 37;\n            this.argument();\n            this.state = 38;\n            this.match(glGrammarParser.RPAREN);\n            this.state = 39;\n            this.match(glGrammarParser.PANDC);\n            this.state = 45;\n            this._errHandler.sync(this);\n            _la = this._input.LA(1);\n        }\n    } catch (re) {\n    \tif(re instanceof antlr4.error.RecognitionException) {\n\t        localctx.exception = re;\n\t        this._errHandler.reportError(this, re);\n\t        this._errHandler.recover(this, re);\n\t    } else {\n\t    \tthrow re;\n\t    }\n    } finally {\n        this.exitRule();\n    }\n    return localctx;\n};\n\nfunction ActionContext(parser, parent, invokingState) {\n\tif(parent===undefined) {\n\t    parent = null;\n\t}\n\tif(invokingState===undefined || invokingState===null) {\n\t\tinvokingState = -1;\n\t}\n\tantlr4.ParserRuleContext.call(this, parent, invokingState);\n    this.parser = parser;\n    this.ruleIndex = glGrammarParser.RULE_action;\n    return this;\n}\n\nActionContext.prototype = Object.create(antlr4.ParserRuleContext.prototype);\nActionContext.prototype.constructor = ActionContext;\n\n\nActionContext.prototype.enterRule = function(listener) {\n    if(listener instanceof glGrammarListener ) {\n        listener.enterAction(this);\n\t}\n};\n\nActionContext.prototype.exitRule = function(listener) {\n    if(listener instanceof glGrammarListener ) {\n        listener.exitAction(this);\n\t}\n};\n\n\n\n\nglGrammarParser.ActionContext = ActionContext;\n\nglGrammarParser.prototype.action = function() {\n\n    var localctx = new ActionContext(this, this._ctx, this.state);\n    this.enterRule(localctx, 6, glGrammarParser.RULE_action);\n    var _la = 0; // Token type\n    try {\n        this.enterOuterAlt(localctx, 1);\n        this.state = 46;\n        _la = this._input.LA(1);\n        if(!((((_la) & ~0x1f) == 0 && ((1 << _la) & ((1 << glGrammarParser.T__0) | (1 << glGrammarParser.T__1) | (1 << glGrammarParser.T__2) | (1 << glGrammarParser.T__3))) !== 0))) {\n        this._errHandler.recoverInline(this);\n        }\n        else {\n        \tthis._errHandler.reportMatch(this);\n            this.consume();\n        }\n    } catch (re) {\n    \tif(re instanceof antlr4.error.RecognitionException) {\n\t        localctx.exception = re;\n\t        this._errHandler.reportError(this, re);\n\t        this._errHandler.recover(this, re);\n\t    } else {\n\t    \tthrow re;\n\t    }\n    } finally {\n        this.exitRule();\n    }\n    return localctx;\n};\n\nfunction ArgumentContext(parser, parent, invokingState) {\n\tif(parent===undefined) {\n\t    parent = null;\n\t}\n\tif(invokingState===undefined || invokingState===null) {\n\t\tinvokingState = -1;\n\t}\n\tantlr4.ParserRuleContext.call(this, parent, invokingState);\n    this.parser = parser;\n    this.ruleIndex = glGrammarParser.RULE_argument;\n    return this;\n}\n\nArgumentContext.prototype = Object.create(antlr4.ParserRuleContext.prototype);\nArgumentContext.prototype.constructor = ArgumentContext;\n\nArgumentContext.prototype.shape = function() {\n    return this.getTypedRuleContext(ShapeContext,0);\n};\n\nArgumentContext.prototype.id = function() {\n    return this.getTypedRuleContext(IdContext,0);\n};\n\nArgumentContext.prototype.size = function() {\n    return this.getTypedRuleContext(SizeContext,0);\n};\n\nArgumentContext.prototype.color = function() {\n    return this.getTypedRuleContext(ColorContext,0);\n};\n\nArgumentContext.prototype.position = function() {\n    return this.getTypedRuleContext(PositionContext,0);\n};\n\nArgumentContext.prototype.enterRule = function(listener) {\n    if(listener instanceof glGrammarListener ) {\n        listener.enterArgument(this);\n\t}\n};\n\nArgumentContext.prototype.exitRule = function(listener) {\n    if(listener instanceof glGrammarListener ) {\n        listener.exitArgument(this);\n\t}\n};\n\n\n\n\nglGrammarParser.ArgumentContext = ArgumentContext;\n\nglGrammarParser.prototype.argument = function() {\n\n    var localctx = new ArgumentContext(this, this._ctx, this.state);\n    this.enterRule(localctx, 8, glGrammarParser.RULE_argument);\n    try {\n        this.state = 65;\n        this._errHandler.sync(this);\n        var la_ = this._interp.adaptivePredict(this._input,1,this._ctx);\n        switch(la_) {\n        case 1:\n            this.enterOuterAlt(localctx, 1);\n            this.state = 48;\n            this.shape();\n            this.state = 49;\n            this.id();\n            this.state = 50;\n            this.match(glGrammarParser.T__4);\n            this.state = 51;\n            this.size();\n            this.state = 52;\n            this.match(glGrammarParser.T__5);\n            this.state = 53;\n            this.color();\n            this.state = 54;\n            this.match(glGrammarParser.T__6);\n            this.state = 55;\n            this.position();\n            break;\n\n        case 2:\n            this.enterOuterAlt(localctx, 2);\n            this.state = 57;\n            this.id();\n            this.state = 58;\n            this.match(glGrammarParser.T__6);\n            this.state = 59;\n            this.position();\n            break;\n\n        case 3:\n            this.enterOuterAlt(localctx, 3);\n            this.state = 61;\n            this.id();\n            this.state = 62;\n            this.size();\n            break;\n\n        case 4:\n            this.enterOuterAlt(localctx, 4);\n            this.state = 64;\n            this.id();\n            break;\n\n        }\n    } catch (re) {\n    \tif(re instanceof antlr4.error.RecognitionException) {\n\t        localctx.exception = re;\n\t        this._errHandler.reportError(this, re);\n\t        this._errHandler.recover(this, re);\n\t    } else {\n\t    \tthrow re;\n\t    }\n    } finally {\n        this.exitRule();\n    }\n    return localctx;\n};\n\nfunction SizeContext(parser, parent, invokingState) {\n\tif(parent===undefined) {\n\t    parent = null;\n\t}\n\tif(invokingState===undefined || invokingState===null) {\n\t\tinvokingState = -1;\n\t}\n\tantlr4.ParserRuleContext.call(this, parent, invokingState);\n    this.parser = parser;\n    this.ruleIndex = glGrammarParser.RULE_size;\n    return this;\n}\n\nSizeContext.prototype = Object.create(antlr4.ParserRuleContext.prototype);\nSizeContext.prototype.constructor = SizeContext;\n\nSizeContext.prototype.DIGIT = function() {\n    return this.getToken(glGrammarParser.DIGIT, 0);\n};\n\nSizeContext.prototype.enterRule = function(listener) {\n    if(listener instanceof glGrammarListener ) {\n        listener.enterSize(this);\n\t}\n};\n\nSizeContext.prototype.exitRule = function(listener) {\n    if(listener instanceof glGrammarListener ) {\n        listener.exitSize(this);\n\t}\n};\n\n\n\n\nglGrammarParser.SizeContext = SizeContext;\n\nglGrammarParser.prototype.size = function() {\n\n    var localctx = new SizeContext(this, this._ctx, this.state);\n    this.enterRule(localctx, 10, glGrammarParser.RULE_size);\n    try {\n        this.enterOuterAlt(localctx, 1);\n        this.state = 67;\n        this.match(glGrammarParser.DIGIT);\n    } catch (re) {\n    \tif(re instanceof antlr4.error.RecognitionException) {\n\t        localctx.exception = re;\n\t        this._errHandler.reportError(this, re);\n\t        this._errHandler.recover(this, re);\n\t    } else {\n\t    \tthrow re;\n\t    }\n    } finally {\n        this.exitRule();\n    }\n    return localctx;\n};\n\nfunction ShapeContext(parser, parent, invokingState) {\n\tif(parent===undefined) {\n\t    parent = null;\n\t}\n\tif(invokingState===undefined || invokingState===null) {\n\t\tinvokingState = -1;\n\t}\n\tantlr4.ParserRuleContext.call(this, parent, invokingState);\n    this.parser = parser;\n    this.ruleIndex = glGrammarParser.RULE_shape;\n    return this;\n}\n\nShapeContext.prototype = Object.create(antlr4.ParserRuleContext.prototype);\nShapeContext.prototype.constructor = ShapeContext;\n\n\nShapeContext.prototype.enterRule = function(listener) {\n    if(listener instanceof glGrammarListener ) {\n        listener.enterShape(this);\n\t}\n};\n\nShapeContext.prototype.exitRule = function(listener) {\n    if(listener instanceof glGrammarListener ) {\n        listener.exitShape(this);\n\t}\n};\n\n\n\n\nglGrammarParser.ShapeContext = ShapeContext;\n\nglGrammarParser.prototype.shape = function() {\n\n    var localctx = new ShapeContext(this, this._ctx, this.state);\n    this.enterRule(localctx, 12, glGrammarParser.RULE_shape);\n    var _la = 0; // Token type\n    try {\n        this.enterOuterAlt(localctx, 1);\n        this.state = 69;\n        _la = this._input.LA(1);\n        if(!(_la===glGrammarParser.T__7 || _la===glGrammarParser.T__8)) {\n        this._errHandler.recoverInline(this);\n        }\n        else {\n        \tthis._errHandler.reportMatch(this);\n            this.consume();\n        }\n    } catch (re) {\n    \tif(re instanceof antlr4.error.RecognitionException) {\n\t        localctx.exception = re;\n\t        this._errHandler.reportError(this, re);\n\t        this._errHandler.recover(this, re);\n\t    } else {\n\t    \tthrow re;\n\t    }\n    } finally {\n        this.exitRule();\n    }\n    return localctx;\n};\n\nfunction ColorContext(parser, parent, invokingState) {\n\tif(parent===undefined) {\n\t    parent = null;\n\t}\n\tif(invokingState===undefined || invokingState===null) {\n\t\tinvokingState = -1;\n\t}\n\tantlr4.ParserRuleContext.call(this, parent, invokingState);\n    this.parser = parser;\n    this.ruleIndex = glGrammarParser.RULE_color;\n    return this;\n}\n\nColorContext.prototype = Object.create(antlr4.ParserRuleContext.prototype);\nColorContext.prototype.constructor = ColorContext;\n\n\nColorContext.prototype.enterRule = function(listener) {\n    if(listener instanceof glGrammarListener ) {\n        listener.enterColor(this);\n\t}\n};\n\nColorContext.prototype.exitRule = function(listener) {\n    if(listener instanceof glGrammarListener ) {\n        listener.exitColor(this);\n\t}\n};\n\n\n\n\nglGrammarParser.ColorContext = ColorContext;\n\nglGrammarParser.prototype.color = function() {\n\n    var localctx = new ColorContext(this, this._ctx, this.state);\n    this.enterRule(localctx, 14, glGrammarParser.RULE_color);\n    var _la = 0; // Token type\n    try {\n        this.enterOuterAlt(localctx, 1);\n        this.state = 71;\n        _la = this._input.LA(1);\n        if(!((((_la) & ~0x1f) == 0 && ((1 << _la) & ((1 << glGrammarParser.T__9) | (1 << glGrammarParser.T__10) | (1 << glGrammarParser.T__11) | (1 << glGrammarParser.T__12) | (1 << glGrammarParser.T__13) | (1 << glGrammarParser.T__14) | (1 << glGrammarParser.T__15) | (1 << glGrammarParser.T__16) | (1 << glGrammarParser.T__17))) !== 0))) {\n        this._errHandler.recoverInline(this);\n        }\n        else {\n        \tthis._errHandler.reportMatch(this);\n            this.consume();\n        }\n    } catch (re) {\n    \tif(re instanceof antlr4.error.RecognitionException) {\n\t        localctx.exception = re;\n\t        this._errHandler.reportError(this, re);\n\t        this._errHandler.recover(this, re);\n\t    } else {\n\t    \tthrow re;\n\t    }\n    } finally {\n        this.exitRule();\n    }\n    return localctx;\n};\n\nfunction PositionContext(parser, parent, invokingState) {\n\tif(parent===undefined) {\n\t    parent = null;\n\t}\n\tif(invokingState===undefined || invokingState===null) {\n\t\tinvokingState = -1;\n\t}\n\tantlr4.ParserRuleContext.call(this, parent, invokingState);\n    this.parser = parser;\n    this.ruleIndex = glGrammarParser.RULE_position;\n    return this;\n}\n\nPositionContext.prototype = Object.create(antlr4.ParserRuleContext.prototype);\nPositionContext.prototype.constructor = PositionContext;\n\nPositionContext.prototype.DIGIT = function(i) {\n\tif(i===undefined) {\n\t\ti = null;\n\t}\n    if(i===null) {\n        return this.getTokens(glGrammarParser.DIGIT);\n    } else {\n        return this.getToken(glGrammarParser.DIGIT, i);\n    }\n};\n\n\nPositionContext.prototype.COMMA = function() {\n    return this.getToken(glGrammarParser.COMMA, 0);\n};\n\nPositionContext.prototype.enterRule = function(listener) {\n    if(listener instanceof glGrammarListener ) {\n        listener.enterPosition(this);\n\t}\n};\n\nPositionContext.prototype.exitRule = function(listener) {\n    if(listener instanceof glGrammarListener ) {\n        listener.exitPosition(this);\n\t}\n};\n\n\n\n\nglGrammarParser.PositionContext = PositionContext;\n\nglGrammarParser.prototype.position = function() {\n\n    var localctx = new PositionContext(this, this._ctx, this.state);\n    this.enterRule(localctx, 16, glGrammarParser.RULE_position);\n    try {\n        this.enterOuterAlt(localctx, 1);\n        this.state = 73;\n        this.match(glGrammarParser.DIGIT);\n        this.state = 74;\n        this.match(glGrammarParser.COMMA);\n        this.state = 75;\n        this.match(glGrammarParser.DIGIT);\n    } catch (re) {\n    \tif(re instanceof antlr4.error.RecognitionException) {\n\t        localctx.exception = re;\n\t        this._errHandler.reportError(this, re);\n\t        this._errHandler.recover(this, re);\n\t    } else {\n\t    \tthrow re;\n\t    }\n    } finally {\n        this.exitRule();\n    }\n    return localctx;\n};\n\nfunction IdContext(parser, parent, invokingState) {\n\tif(parent===undefined) {\n\t    parent = null;\n\t}\n\tif(invokingState===undefined || invokingState===null) {\n\t\tinvokingState = -1;\n\t}\n\tantlr4.ParserRuleContext.call(this, parent, invokingState);\n    this.parser = parser;\n    this.ruleIndex = glGrammarParser.RULE_id;\n    return this;\n}\n\nIdContext.prototype = Object.create(antlr4.ParserRuleContext.prototype);\nIdContext.prototype.constructor = IdContext;\n\nIdContext.prototype.ALPHA = function() {\n    return this.getToken(glGrammarParser.ALPHA, 0);\n};\n\nIdContext.prototype.alphaNum = function(i) {\n    if(i===undefined) {\n        i = null;\n    }\n    if(i===null) {\n        return this.getTypedRuleContexts(AlphaNumContext);\n    } else {\n        return this.getTypedRuleContext(AlphaNumContext,i);\n    }\n};\n\nIdContext.prototype.enterRule = function(listener) {\n    if(listener instanceof glGrammarListener ) {\n        listener.enterId(this);\n\t}\n};\n\nIdContext.prototype.exitRule = function(listener) {\n    if(listener instanceof glGrammarListener ) {\n        listener.exitId(this);\n\t}\n};\n\n\n\n\nglGrammarParser.IdContext = IdContext;\n\nglGrammarParser.prototype.id = function() {\n\n    var localctx = new IdContext(this, this._ctx, this.state);\n    this.enterRule(localctx, 18, glGrammarParser.RULE_id);\n    try {\n        this.enterOuterAlt(localctx, 1);\n        this.state = 77;\n        this.match(glGrammarParser.ALPHA);\n        this.state = 81;\n        this._errHandler.sync(this);\n        var _alt = this._interp.adaptivePredict(this._input,2,this._ctx)\n        while(_alt!=2 && _alt!=antlr4.atn.ATN.INVALID_ALT_NUMBER) {\n            if(_alt===1) {\n                this.state = 78;\n                this.alphaNum(); \n            }\n            this.state = 83;\n            this._errHandler.sync(this);\n            _alt = this._interp.adaptivePredict(this._input,2,this._ctx);\n        }\n\n    } catch (re) {\n    \tif(re instanceof antlr4.error.RecognitionException) {\n\t        localctx.exception = re;\n\t        this._errHandler.reportError(this, re);\n\t        this._errHandler.recover(this, re);\n\t    } else {\n\t    \tthrow re;\n\t    }\n    } finally {\n        this.exitRule();\n    }\n    return localctx;\n};\n\nfunction AlphaNumContext(parser, parent, invokingState) {\n\tif(parent===undefined) {\n\t    parent = null;\n\t}\n\tif(invokingState===undefined || invokingState===null) {\n\t\tinvokingState = -1;\n\t}\n\tantlr4.ParserRuleContext.call(this, parent, invokingState);\n    this.parser = parser;\n    this.ruleIndex = glGrammarParser.RULE_alphaNum;\n    return this;\n}\n\nAlphaNumContext.prototype = Object.create(antlr4.ParserRuleContext.prototype);\nAlphaNumContext.prototype.constructor = AlphaNumContext;\n\nAlphaNumContext.prototype.ALPHA = function() {\n    return this.getToken(glGrammarParser.ALPHA, 0);\n};\n\nAlphaNumContext.prototype.DIGIT = function() {\n    return this.getToken(glGrammarParser.DIGIT, 0);\n};\n\nAlphaNumContext.prototype.enterRule = function(listener) {\n    if(listener instanceof glGrammarListener ) {\n        listener.enterAlphaNum(this);\n\t}\n};\n\nAlphaNumContext.prototype.exitRule = function(listener) {\n    if(listener instanceof glGrammarListener ) {\n        listener.exitAlphaNum(this);\n\t}\n};\n\n\n\n\nglGrammarParser.AlphaNumContext = AlphaNumContext;\n\nglGrammarParser.prototype.alphaNum = function() {\n\n    var localctx = new AlphaNumContext(this, this._ctx, this.state);\n    this.enterRule(localctx, 20, glGrammarParser.RULE_alphaNum);\n    var _la = 0; // Token type\n    try {\n        this.enterOuterAlt(localctx, 1);\n        this.state = 84;\n        _la = this._input.LA(1);\n        if(!(_la===glGrammarParser.ALPHA || _la===glGrammarParser.DIGIT)) {\n        this._errHandler.recoverInline(this);\n        }\n        else {\n        \tthis._errHandler.reportMatch(this);\n            this.consume();\n        }\n    } catch (re) {\n    \tif(re instanceof antlr4.error.RecognitionException) {\n\t        localctx.exception = re;\n\t        this._errHandler.reportError(this, re);\n\t        this._errHandler.recover(this, re);\n\t    } else {\n\t    \tthrow re;\n\t    }\n    } finally {\n        this.exitRule();\n    }\n    return localctx;\n};\n\nfunction StartContext(parser, parent, invokingState) {\n\tif(parent===undefined) {\n\t    parent = null;\n\t}\n\tif(invokingState===undefined || invokingState===null) {\n\t\tinvokingState = -1;\n\t}\n\tantlr4.ParserRuleContext.call(this, parent, invokingState);\n    this.parser = parser;\n    this.ruleIndex = glGrammarParser.RULE_start;\n    return this;\n}\n\nStartContext.prototype = Object.create(antlr4.ParserRuleContext.prototype);\nStartContext.prototype.constructor = StartContext;\n\n\nStartContext.prototype.enterRule = function(listener) {\n    if(listener instanceof glGrammarListener ) {\n        listener.enterStart(this);\n\t}\n};\n\nStartContext.prototype.exitRule = function(listener) {\n    if(listener instanceof glGrammarListener ) {\n        listener.exitStart(this);\n\t}\n};\n\n\n\n\nglGrammarParser.StartContext = StartContext;\n\nglGrammarParser.prototype.start = function() {\n\n    var localctx = new StartContext(this, this._ctx, this.state);\n    this.enterRule(localctx, 22, glGrammarParser.RULE_start);\n    try {\n        this.enterOuterAlt(localctx, 1);\n        this.state = 86;\n        this.match(glGrammarParser.T__18);\n    } catch (re) {\n    \tif(re instanceof antlr4.error.RecognitionException) {\n\t        localctx.exception = re;\n\t        this._errHandler.reportError(this, re);\n\t        this._errHandler.recover(this, re);\n\t    } else {\n\t    \tthrow re;\n\t    }\n    } finally {\n        this.exitRule();\n    }\n    return localctx;\n};\n\nfunction EndProgramContext(parser, parent, invokingState) {\n\tif(parent===undefined) {\n\t    parent = null;\n\t}\n\tif(invokingState===undefined || invokingState===null) {\n\t\tinvokingState = -1;\n\t}\n\tantlr4.ParserRuleContext.call(this, parent, invokingState);\n    this.parser = parser;\n    this.ruleIndex = glGrammarParser.RULE_endProgram;\n    return this;\n}\n\nEndProgramContext.prototype = Object.create(antlr4.ParserRuleContext.prototype);\nEndProgramContext.prototype.constructor = EndProgramContext;\n\n\nEndProgramContext.prototype.enterRule = function(listener) {\n    if(listener instanceof glGrammarListener ) {\n        listener.enterEndProgram(this);\n\t}\n};\n\nEndProgramContext.prototype.exitRule = function(listener) {\n    if(listener instanceof glGrammarListener ) {\n        listener.exitEndProgram(this);\n\t}\n};\n\n\n\n\nglGrammarParser.EndProgramContext = EndProgramContext;\n\nglGrammarParser.prototype.endProgram = function() {\n\n    var localctx = new EndProgramContext(this, this._ctx, this.state);\n    this.enterRule(localctx, 24, glGrammarParser.RULE_endProgram);\n    try {\n        this.enterOuterAlt(localctx, 1);\n        this.state = 88;\n        this.match(glGrammarParser.T__19);\n    } catch (re) {\n    \tif(re instanceof antlr4.error.RecognitionException) {\n\t        localctx.exception = re;\n\t        this._errHandler.reportError(this, re);\n\t        this._errHandler.recover(this, re);\n\t    } else {\n\t    \tthrow re;\n\t    }\n    } finally {\n        this.exitRule();\n    }\n    return localctx;\n};\n\n\nexports.glGrammarParser = glGrammarParser;\n\n\n//# sourceURL=webpack:///./glGrammarParser.js?");

/***/ }),

/***/ "./lab.js":
/*!****************!*\
  !*** ./lab.js ***!
  \****************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

"use strict";
eval("\n\nvar gl;\nvar canvas;\nvar program;\n\nvar i = 0;\n\nvar thetaLoc;\n\nvar objects = [];\nvar obj_buttons_array = [];\n\nvar obj_index = 1;\nvar currently_selected_index = 0;\n\nvar rotating = false;\nvar color = vec4(0.5, 0.5, 0.5, 1);\n\nvar globalPosition;\nvar globalScale;\n\nvar v_Position;\nvar colorPosition;\n\nvar shape_to_draw;\n\nvar global_size = 0;\nvar global_x = 0;\nvar global_y = 0;\n\nvar action;\nvar targetObject;\n\n//ANTLR STUFF\nconst antlr4 = __webpack_require__(/*! ./antlr4/index */ \"./antlr4/index.js\");\nconst glGrammarLexer = __webpack_require__(/*! ./glGrammarLexer */ \"./glGrammarLexer.js\");\nconst glGrammarParser = __webpack_require__(/*! ./glGrammarParser */ \"./glGrammarParser.js\");\nvar ChildGlGrammarListener = __webpack_require__(/*! ./childListener */ \"./childListener.js\").ChildGlGrammarListener;\n\n//INPUT CODE\nconst txt = __webpack_require__(/*! text-loader!./code.txt */ \"./node_modules/text-loader/index.js!./code.txt\");\n\nwindow.onload = function init () {\n    canvas = document.getElementById(\"gl-canvas\");\n\n    gl = WebGLUtils.setupWebGL(canvas);\n    if (!gl) { alert(\"WebGL isn't available\"); }\n\n    console.log(\"Input code is ----> \" + (txt));\n\n    gl.viewport(0, 0, canvas.width, canvas.height);\n    gl.clearColor(1.0, 1.0, 1.0, 1.0);\n\n    program = initShaders(gl, \"vertex-shader\", \"fragment-shader\");\n\n    gl.useProgram(program);\n\n    v_Position = gl.getAttribLocation(program, \"v_Position\");\n    colorPosition = gl.getAttribLocation(program, \"a_color\");\n    \n    thetaLoc = gl.getUniformLocation(program, \"theta\");\n    globalPosition = gl.getUniformLocation(program, \"tr\");\n    globalScale = gl.getUniformLocation(program, \"scale\");\n\n    var input = txt;   \n    var chars = new antlr4.InputStream(input);\n    var lexer = new glGrammarLexer.glGrammarLexer(chars);\n    var tokens  = new antlr4.CommonTokenStream(lexer);\n    var parser = new glGrammarParser.glGrammarParser(tokens);\n    parser.buildParseTrees = true;   \n    var tree = parser.program();   \n    var customListener = new ChildGlGrammarListener();\n    antlr4.tree.ParseTreeWalker.DEFAULT.walk(customListener, tree);\n\n    // spinX_button.onclick = function () {objects[currently_selected_index].axis = objects[currently_selected_index].xAxis; objects[currently_selected_index].rotating = true; objects[currently_selected_index].rotation = 0;};\n    // spinY_button.onclick = function () {objects[currently_selected_index].axis = objects[currently_selected_index].yAxis; objects[currently_selected_index].rotating = true; objects[currently_selected_index].rotation = 0;};\n    // spinZ_button.onclick = function () {objects[currently_selected_index].axis = objects[currently_selected_index].zAxis; objects[currently_selected_index].rotating = true; objects[currently_selected_index].rotation = 0;};\n\n    // var sliderRotationx = document.getElementById(\"X_rotation_slider\");\n    // sliderRotationx.oninput = function() {objects[currently_selected_index].axis = objects[currently_selected_index].xAxis; objects[currently_selected_index].rotating = false; objects[currently_selected_index].rotation = sliderRotationx.value;};\n\n    // var sliderx = document.getElementById(\"X_translation_slider\");\n    // sliderx.oninput = function() {objects[currently_selected_index].taxis = objects[currently_selected_index].txAxis; objects[currently_selected_index].translation = sliderx.value;};\n\n    // var sliderScalex = document.getElementById(\"X_scale_slider\");\n    // sliderScalex.oninput = function() {objects[currently_selected_index].saxis = objects[currently_selected_index].sxAxis; objects[currently_selected_index].scale = sliderScalex.value;};\n\n\n    function render_scene() {\n\n        gl.clear(gl.COLOR_BUFFER_BIT | gl.DEPTH_BUFFER_BIT);\n        for (var i = 0; i < objects.length; i++) {\n            objects[i].render();\n        }\n\n        requestAnimFrame(render_scene);\n\n    }\n\n    render_scene();\n\n};\n\nfunction builder () {\n    \n    this.square = function(x, y, z, scl, id) {  \n\n        this.translation = 0;\n        this.id = id;\n        \n        this.center_matrix = [-3, -3, -3];\n        \n        this.select_color = vec4(0, 0, 1, 0.1);\n\n        this.selected = false;\n\n        this.txAxis = 0;\n        this.tyAxis = 1;\n        this.tzAxis = 2;\n        this.taxis = this.txAxis;\n\n        this.theta = [0, 0, 0];\n        this.xAxis = 0;\n        this.yAxis = 1;\n        this.zAxis = 2;\n        this.axis = this.xAxis;\n\n        this.sxAxis = 0;\n        this.syAxis = 1;\n        this.szAxis = 2;\n        this.saxis = this.sxAxis;\n        this.scale_x = 1;\n        this.scale_y = 1;\n        this.scale_z = 1;\n        this.scale_matrix = [this.scale_x, this.scale_y, this.scale_z];\n        this.scale = 1;\n\n        this.rotationSpeed;\n        \n        this.rotating = false;\n        this.vertices = [];\n        this.colors = [];\n        this.rotation = 0;\n        this.translation_x = x;\n        this.translation_y = y;\n        this.translation_z = z;\n        this.scaleparam = scl;\n        this.translation_matrix = [this.translation_x, this.translation_y, this.translation_z];\n\n        this.bottom_left_corner = vec3(this.translation_x, this.translation_y, this.translation_z);\n        this.top_left_corner = vec3(this.translation_x, this.translation_y + this.scaleparam, this.translation_z);\n        this.bottom_right_corner = vec3(this.translation_x + this.scaleparam, this.translation_y, this.translation_z);\n        this.top_right_corner = vec3(this.translation_x + this.scaleparam, this.translation_y + this.scaleparam, this.translation_z);\n\n        this.top_right_corner_2 = vec3(this.translation_x + this.scaleparam, this.translation_y + this.scaleparam, this.translation_z + this.scaleparam);\n        this.bottom_right_corner_2 = vec3(this.translation_x + this.scaleparam, this.translation_y, this.translation_z + this.scaleparam);\n        this.bottom_left_corner_2 = vec3(this.translation_x, this.translation_y, this.translation_z + this.scaleparam);\n        this.top_left_corner_2 = vec3(this.translation_x, this.translation_y + this.scaleparam, this.translation_z + this.scaleparam);\n\n        this.draw = function () {\n\n            this.vertices.push(this.bottom_left_corner);\n            this.vertices.push(this.top_left_corner);\n            this.vertices.push(this.bottom_right_corner);\n            this.vertices.push(this.top_left_corner);\n            this.vertices.push(this.bottom_right_corner);\n            this.vertices.push(this.top_right_corner);\n\n            for (i = 0; i <= 5; i++) {\n                this.colors.push(color);\n            }\n\n        }\n\n        this.render = function () {\n\n            var buffer = gl.createBuffer();\n            gl.bindBuffer(gl.ARRAY_BUFFER, buffer);\n            gl.bufferData(gl.ARRAY_BUFFER, flatten(this.vertices), gl.STATIC_DRAW);\n\n            gl.vertexAttribPointer(v_Position, 3, gl.FLOAT, false, 0, 0);\n            gl.enableVertexAttribArray(v_Position);\n\n            var colorBuffer = gl.createBuffer();\n            gl.bindBuffer(gl.ARRAY_BUFFER, colorBuffer);\n            gl.bufferData(gl.ARRAY_BUFFER, flatten(this.colors), gl.STATIC_DRAW);\n\n            gl.vertexAttribPointer(colorPosition, 4, gl.FLOAT, false, 0, 0);\n            gl.enableVertexAttribArray(colorPosition);\n\n            if (this.rotating){\n               this.rotation += this.rotationSpeed;\n            }   \n\n                gl.uniform3fv(globalPosition, this.center_matrix);          \n\n                this.theta[this.axis] = this.rotation;\n                gl.uniform3fv(thetaLoc, this.theta);\n\n                this.scale_matrix[this.saxis] = this.scale;\n                gl.uniform3fv(globalScale, this.scale_matrix);\n\n                this.translation_matrix[this.taxis] = this.translation;\n                gl.uniform3fv(globalPosition, this.translation_matrix);  \n\n                gl.drawArrays(gl.TRIANGLES, 0, this.vertices.length);\n\n\n        }\n    }\n\n    this.circle = function(x, y, z, r, id) {\n\n        this.theta = [0, 0, 0];\n\n        this.id = id;\n\n        this.center_matrix = [0, 0, 0];\n\n        this.txAxis = 0;\n        this.tyAxis = 1;\n        this.tzAxis = 2;\n        this.taxis = this.txAxis;\n\n        this.xAxis = 0;\n        this.yAxis = 1;\n        this.zAxis = 2;\n        this.axis = this.xAxis;\n\n        this.sxAxis = 0;\n        this.syAxis = 1;\n        this.szAxis = 2;\n        this.saxis = this.sxAxis;\n        this.scale_x = 1;\n        this.scale_y = 1;\n        this.scale_z = 1;\n        this.scale_matrix = [this.scale_x, this.scale_y, this.scale_z];\n        this.scale = 1;\n\n        this.translation = 0;\n\n        this.rotationSpeed;\n\n        this.rotating = false;\n        this.vertices = [];\n        this.colors = [];\n        this.rotation = 0;\n        this.translation_x = x;\n        this.translation_y = y;\n        this.translation_z = z;\n        this.translation_matrix = [this.translation_x, this.translation_y, this.translation_z];\n\n        this.j = 0;\n        this.center = vec3(this.translation_x, this.translation_y, this.translation_z);\n        this.second_point = vec3(this.translation_x, this.translation_y + 0.15, this.translation_z);\n        this.color = color;\n        this.r = r;\n\n        this.draw = function () {\n\n            for (i = 0; i <= 200; i += 1) {\n\n                this.vertices.push(this.center);\n                this.vertices.push(vec3(this.r * Math.cos((i+1) * 2 * Math.PI / 200) + this.translation_x, this.r * Math.sin((i+1) * 2 * Math.PI / 200) + this.translation_y, this.translation_z));\n                this.vertices.push(vec3(this.r * Math.cos(i * 2 * Math.PI / 200) + this.translation_x, this.r * Math.sin(i * 2 * Math.PI / 200) + this.translation_y, this.translation_z));\n                this.colors.push(this.color);\n                this.colors.push(this.color);\n                this.colors.push(this.color);\n            }\n\n        }\n\n\n        this.render = function () {\n\n            var buffer = gl.createBuffer();\n            gl.bindBuffer(gl.ARRAY_BUFFER, buffer);\n            gl.bufferData(gl.ARRAY_BUFFER, flatten(this.vertices), gl.STATIC_DRAW);\n\n            gl.vertexAttribPointer(v_Position, 3, gl.FLOAT, false, 0, 0);\n            gl.enableVertexAttribArray(v_Position);\n\n            var colorBuffer = gl.createBuffer();\n            gl.bindBuffer(gl.ARRAY_BUFFER, colorBuffer);\n            gl.bufferData(gl.ARRAY_BUFFER, flatten(this.colors), gl.STATIC_DRAW);\n\n            gl.vertexAttribPointer(colorPosition, 4, gl.FLOAT, false, 0, 0);\n            gl.enableVertexAttribArray(colorPosition);\n\n            if (this.rotating){\n                this.rotation += this.rotationSpeed;\n            }\n\n                gl.uniform3fv(globalPosition, this.center_matrix);          \n\n                this.theta[this.axis] = this.rotation;\n                gl.uniform3fv(thetaLoc, this.theta);\n\n                this.scale_matrix[this.saxis] = this.scale;\n                gl.uniform3fv(globalScale, this.scale_matrix);\n\n        \n                this.translation_matrix[this.taxis] = this.translation;\n                gl.uniform3fv(globalPosition, this.translation_matrix);\n\n            \n            gl.drawArrays(gl.TRIANGLES, 0, this.vertices.length);\n\n        }\n\n\n    }\n\n    this.createCircle = function (x,y,r,id) {\n        var newCircle = new this.circle(0, 0, 0, r, id);\n        newCircle.draw();\n\n        newCircle.taxis = newCircle.txAxis;\n        newCircle.translation = x;\n\n        newCircle.taxis = newCircle.tyAxis;\n        newCircle.translation = y;\n\n        objects.push(newCircle);\n    }\n\n    this.createSquare = function (x,y,scl,id) {\n        var newSquare = new this.square(0, 0, 0, scl, id);\n        newSquare.draw();\n        \n        newSquare.taxis = newSquare.txAxis;\n        newSquare.translation = x;\n\n        newSquare.taxis = newSquare.tyAxis;\n        newSquare.translation = y;\n\n        objects.push(newSquare);\n    }\n\n}\n\nexports.drawShape = function () {\n    if (shape_to_draw == \"circle\"){\n        new builder().createCircle(global_x, global_y, global_size, targetObject);\n    }\n    else {\n        new builder().createSquare(global_x, global_y, global_size, targetObject); \n    }\n}; \n\nexports.setRedColor = function ()\n{\n    color = new vec4(1,0,0,1);\n};\n\nexports.setGreenColor = function ()\n{\n    color = new vec4(0,1,0,1);\n};\n\nexports.setBlueColor = function ()\n{\n    color = new vec4(0,0,1,1);\n};\n\nexports.setBlackColor = function ()\n{\n    color = new vec4(0,0,0,1);\n};\n\nexports.setShapeSquare = function ()\n{\n    shape_to_draw = \"square\";\n};\n\nexports.setShapeCircle = function ()\n{\n    shape_to_draw = \"circle\";\n};\n\nexports.setGlobalSize = function (size)\n{\n    global_size = size/6;\n};\n\nexports.setGlobalXCoord = function (x)\n{\n    global_x = (x-10) / 10;\n};\n\nexports.setGlobalYCoord = function (y)\n{\n    global_y = (y-5) / 10;\n};\n\nexports.setAction = function (act)\n{\n    action = act;\n}\n\nexports.getAction = function ()\n{\n    return action;\n}\n\nexports.setObjectId = function (id)\n{\n    targetObject = id;\n}\n\nexports.rotateObject = function ()\n{\n    objects.forEach(element => {\n        if (element.id == targetObject){\n            element.axis = element.zAxis;\n            element.rotationSpeed = global_size;\n            element.rotating = true;\n        }\n    });\n}\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n//# sourceURL=webpack:///./lab.js?");

/***/ }),

/***/ "./node_modules/text-loader/index.js!./code.txt":
/*!*********************************************!*\
  !*** ./node_modules/text-loader!./code.txt ***!
  \*********************************************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("module.exports = \"BEGIN \\r\\n    myProgram \\r\\n        { \\r\\n            DRAW (CIRCLE myCircle SIZE 1 COLOR RED AT 3,2);\\r\\n            DRAW (SQUARE mySquare SIZE 1 COLOR BLUE AT 0,0);\\r\\n           \\r\\n            ROTATE (mySquare 10);\\r\\n        } \\r\\nEND\"\n\n//# sourceURL=webpack:///./code.txt?./node_modules/text-loader");

/***/ }),

/***/ "./webgl-libs/MV.js":
/*!**************************!*\
  !*** ./webgl-libs/MV.js ***!
  \**************************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("//////////////////////////////////////////////////////////////////////////////\n//\n//  Angel.js\n//\n//////////////////////////////////////////////////////////////////////////////\n\n//----------------------------------------------------------------------------\n//\n//  Helper functions\n//\n\nfunction _argumentsToArray( args )\n{\n    return [].concat.apply( [], Array.prototype.slice.apply(args) );\n}\n\n//----------------------------------------------------------------------------\n\nfunction radians( degrees ) {\n    return degrees * Math.PI / 180.0;\n}\n\n//----------------------------------------------------------------------------\n//\n//  Vector Constructors\n//\n\nfunction vec2()\n{\n    var result = _argumentsToArray( arguments );\n\n    switch ( result.length ) {\n    case 0: result.push( 0.0 );\n    case 1: result.push( 0.0 );\n    }\n\n    return result.splice( 0, 2 );\n}\n\nfunction vec3()\n{\n    var result = _argumentsToArray( arguments );\n\n    switch ( result.length ) {\n    case 0: result.push( 0.0 );\n    case 1: result.push( 0.0 );\n    case 2: result.push( 0.0 );\n    }\n\n    return result.splice( 0, 3 );\n}\n\nfunction vec4()\n{\n    var result = _argumentsToArray( arguments );\n\n    switch ( result.length ) {\n    case 0: result.push( 0.0 );\n    case 1: result.push( 0.0 );\n    case 2: result.push( 0.0 );\n    case 3: result.push( 1.0 );\n    }\n\n    return result.splice( 0, 4 );\n}\n\n//----------------------------------------------------------------------------\n//\n//  Matrix Constructors\n//\n\nfunction mat2()\n{\n    var v = _argumentsToArray( arguments );\n\n    var m = [];\n    switch ( v.length ) {\n    case 0:\n        v[0] = 1;\n    case 1:\n        m = [\n            vec2( v[0],  0.0 ),\n            vec2(  0.0, v[0] )\n        ];\n        break;\n\n    default:\n        m.push( vec2(v) );  v.splice( 0, 2 );\n        m.push( vec2(v) );\n        break;\n    }\n\n    m.matrix = true;\n\n    return m;\n}\n\n//----------------------------------------------------------------------------\n\nfunction mat3()\n{\n    var v = _argumentsToArray( arguments );\n\n    var m = [];\n    switch ( v.length ) {\n    case 0:\n        v[0] = 1;\n    case 1:\n        m = [\n            vec3( v[0],  0.0,  0.0 ),\n            vec3(  0.0, v[0],  0.0 ),\n            vec3(  0.0,  0.0, v[0] )\n        ];\n        break;\n\n    default:\n        m.push( vec3(v) );  v.splice( 0, 3 );\n        m.push( vec3(v) );  v.splice( 0, 3 );\n        m.push( vec3(v) );\n        break;\n    }\n\n    m.matrix = true;\n\n    return m;\n}\n\n//----------------------------------------------------------------------------\n\nfunction mat4()\n{\n    var v = _argumentsToArray( arguments );\n\n    var m = [];\n    switch ( v.length ) {\n    case 0:\n        v[0] = 1;\n    case 1:\n        m = [\n            vec4( v[0], 0.0,  0.0,   0.0 ),\n            vec4( 0.0,  v[0], 0.0,   0.0 ),\n            vec4( 0.0,  0.0,  v[0],  0.0 ),\n            vec4( 0.0,  0.0,  0.0,  v[0] )\n        ];\n        break;\n\n    default:\n        m.push( vec4(v) );  v.splice( 0, 4 );\n        m.push( vec4(v) );  v.splice( 0, 4 );\n        m.push( vec4(v) );  v.splice( 0, 4 );\n        m.push( vec4(v) );\n        break;\n    }\n\n    m.matrix = true;\n\n    return m;\n}\n\n//----------------------------------------------------------------------------\n//\n//  Generic Mathematical Operations for Vectors and Matrices\n//\n\nfunction equal( u, v )\n{\n    if ( u.length != v.length ) { return false; }\n\n    if ( u.matrix && v.matrix ) {\n        for ( var i = 0; i < u.length; ++i ) {\n            if ( u[i].length != v[i].length ) { return false; }\n            for ( var j = 0; j < u[i].length; ++j ) {\n                if ( u[i][j] !== v[i][j] ) { return false; }\n            }\n        }\n    }\n    else if ( u.matrix && !v.matrix || !u.matrix && v.matrix ) {\n        return false;\n    }\n    else {\n        for ( var i = 0; i < u.length; ++i ) {\n            if ( u[i] !== v[i] ) { return false; }\n        }\n    }\n\n    return true;\n}\n\n//----------------------------------------------------------------------------\n\nfunction add( u, v )\n{\n    var result = [];\n\n    if ( u.matrix && v.matrix ) {\n        if ( u.length != v.length ) {\n            throw \"add(): trying to add matrices of different dimensions\";\n        }\n\n        for ( var i = 0; i < u.length; ++i ) {\n            if ( u[i].length != v[i].length ) {\n                throw \"add(): trying to add matrices of different dimensions\";\n            }\n            result.push( [] );\n            for ( var j = 0; j < u[i].length; ++j ) {\n                result[i].push( u[i][j] + v[i][j] );\n            }\n        }\n\n        result.matrix = true;\n\n        return result;\n    }\n    else if ( u.matrix && !v.matrix || !u.matrix && v.matrix ) {\n        throw \"add(): trying to add matrix and non-matrix variables\";\n    }\n    else {\n        if ( u.length != v.length ) {\n            throw \"add(): vectors are not the same dimension\";\n        }\n\n        for ( var i = 0; i < u.length; ++i ) {\n            result.push( u[i] + v[i] );\n        }\n\n        return result;\n    }\n}\n\n//----------------------------------------------------------------------------\n\nfunction subtract( u, v )\n{\n    var result = [];\n\n    if ( u.matrix && v.matrix ) {\n        if ( u.length != v.length ) {\n            throw \"subtract(): trying to subtract matrices\" +\n                \" of different dimensions\";\n        }\n\n        for ( var i = 0; i < u.length; ++i ) {\n            if ( u[i].length != v[i].length ) {\n                throw \"subtract(): trying to subtact matrices\" +\n                    \" of different dimensions\";\n            }\n            result.push( [] );\n            for ( var j = 0; j < u[i].length; ++j ) {\n                result[i].push( u[i][j] - v[i][j] );\n            }\n        }\n\n        result.matrix = true;\n\n        return result;\n    }\n    else if ( u.matrix && !v.matrix || !u.matrix && v.matrix ) {\n        throw \"subtact(): trying to subtact  matrix and non-matrix variables\";\n    }\n    else {\n        if ( u.length != v.length ) {\n            throw \"subtract(): vectors are not the same length\";\n        }\n\n        for ( var i = 0; i < u.length; ++i ) {\n            result.push( u[i] - v[i] );\n        }\n\n        return result;\n    }\n}\n\n//----------------------------------------------------------------------------\n\nfunction mult( u, v )\n{\n    var result = [];\n\n    if ( u.matrix && v.matrix ) {\n        if ( u.length != v.length ) {\n            throw \"mult(): trying to add matrices of different dimensions\";\n        }\n\n        for ( var i = 0; i < u.length; ++i ) {\n            if ( u[i].length != v[i].length ) {\n                throw \"mult(): trying to add matrices of different dimensions\";\n            }\n        }\n\n        for ( var i = 0; i < u.length; ++i ) {\n            result.push( [] );\n\n            for ( var j = 0; j < v.length; ++j ) {\n                var sum = 0.0;\n                for ( var k = 0; k < u.length; ++k ) {\n                    sum += u[i][k] * v[k][j];\n                }\n                result[i].push( sum );\n            }\n        }\n\n        result.matrix = true;\n\n        return result;\n    }\n\n      if(u.matrix&& (u.length == v.length)) {\n        for(var i = 0; i<v.length; i++) {\n          var sum = 0.0;\n          for(var j=0; j<v.length; j++) {\n            sum += u[i][j]*v[j];\n          }\n          result.push(sum);\n        }\n      return result;\n      }\n\n\n\n    else {\n        if ( u.length != v.length ) {\n            throw \"mult(): vectors are not the same dimension\";\n        }\n\n        for ( var i = 0; i < u.length; ++i ) {\n            result.push( u[i] * v[i] );\n        }\n\n        return result;\n    }\n}\n\n//----------------------------------------------------------------------------\n//\n//  Basic Transformation Matrix Generators\n//\n\nfunction translate( x, y, z )\n{\n    if ( Array.isArray(x) && x.length == 3 ) {\n        z = x[2];\n        y = x[1];\n        x = x[0];\n    }\n\n    var result = mat4();\n    result[0][3] = x;\n    result[1][3] = y;\n    result[2][3] = z;\n\n    return result;\n}\n\n//----------------------------------------------------------------------------\n\nfunction rotate( angle, axis )\n{\n    if ( !Array.isArray(axis) ) {\n        axis = [ arguments[1], arguments[2], arguments[3] ];\n    }\n\n    var v = normalize( axis );\n\n    var x = v[0];\n    var y = v[1];\n    var z = v[2];\n\n    var c = Math.cos( radians(angle) );\n    var omc = 1.0 - c;\n    var s = Math.sin( radians(angle) );\n\n    var result = mat4(\n        vec4( x*x*omc + c,   x*y*omc - z*s, x*z*omc + y*s, 0.0 ),\n        vec4( x*y*omc + z*s, y*y*omc + c,   y*z*omc - x*s, 0.0 ),\n        vec4( x*z*omc - y*s, y*z*omc + x*s, z*z*omc + c,   0.0 ),\n        vec4()\n    );\n\n    return result;\n}\n\nfunction rotateX(theta) {\n  var c = Math.cos( radians(theta) );\n  var s = Math.sin( radians(theta) );\n  var rx = mat4( 1.0,  0.0,  0.0, 0.0,\n      0.0,  c,  -s, 0.0,\n      0.0, s,  c, 0.0,\n      0.0,  0.0,  0.0, 1.0 );\n  return rx;\n}\nfunction rotateY(theta) {\n  var c = Math.cos( radians(theta) );\n  var s = Math.sin( radians(theta) );\n  var ry = mat4( c, 0.0, s, 0.0,\n      0.0, 1.0,  0.0, 0.0,\n      -s, 0.0,  c, 0.0,\n      0.0, 0.0,  0.0, 1.0 );\n  return ry;\n}\nfunction rotateZ(theta) {\n  var c = Math.cos( radians(theta) );\n  var s = Math.sin( radians(theta) );\n  var rz = mat4( c, -s, 0.0, 0.0,\n      s,  c, 0.0, 0.0,\n      0.0,  0.0, 1.0, 0.0,\n      0.0,  0.0, 0.0, 1.0 );\n  return rz;\n}\n\n\n//----------------------------------------------------------------------------\n\nfunction scalem( x, y, z )\n{\n    if ( Array.isArray(x) && x.length == 3 ) {\n        z = x[2];\n        y = x[1];\n        x = x[0];\n    }\n\n    var result = mat4();\n    result[0][0] = x;\n    result[1][1] = y;\n    result[2][2] = z;\n\n    return result;\n}\n\n//----------------------------------------------------------------------------\n//\n//  ModelView Matrix Generators\n//\n\nfunction lookAt( eye, at, up )\n{\n    if ( !Array.isArray(eye) || eye.length != 3) {\n        throw \"lookAt(): first parameter [eye] must be an a vec3\";\n    }\n\n    if ( !Array.isArray(at) || at.length != 3) {\n        throw \"lookAt(): first parameter [at] must be an a vec3\";\n    }\n\n    if ( !Array.isArray(up) || up.length != 3) {\n        throw \"lookAt(): first parameter [up] must be an a vec3\";\n    }\n\n    if ( equal(eye, at) ) {\n        return mat4();\n    }\n\n    var v = normalize( subtract(at, eye) );  // view direction vector\n    var n = normalize( cross(v, up) );       // perpendicular vector\n    var u = normalize( cross(n, v) );        // \"new\" up vector\n\n    v = negate( v );\n\n    var result = mat4(\n        vec4( n, -dot(n, eye) ),\n        vec4( u, -dot(u, eye) ),\n        vec4( v, -dot(v, eye) ),\n        vec4()\n    );\n\n    return result;\n}\n\n//----------------------------------------------------------------------------\n//\n//  Projection Matrix Generators\n//\n\nfunction ortho( left, right, bottom, top, near, far )\n{\n    if ( left == right ) { throw \"ortho(): left and right are equal\"; }\n    if ( bottom == top ) { throw \"ortho(): bottom and top are equal\"; }\n    if ( near == far )   { throw \"ortho(): near and far are equal\"; }\n\n    var w = right - left;\n    var h = top - bottom;\n    var d = far - near;\n\n    var result = mat4();\n    result[0][0] = 2.0 / w;\n    result[1][1] = 2.0 / h;\n    result[2][2] = -2.0 / d;\n    result[0][3] = -(left + right) / w;\n    result[1][3] = -(top + bottom) / h;\n    result[2][3] = -(near + far) / d;\n\n    return result;\n}\n\n//----------------------------------------------------------------------------\n\nfunction perspective( fovy, aspect, near, far )\n{\n    var f = 1.0 / Math.tan( radians(fovy) / 2 );\n    var d = far - near;\n\n    var result = mat4();\n    result[0][0] = f / aspect;\n    result[1][1] = f;\n    result[2][2] = -(near + far) / d;\n    result[2][3] = -2 * near * far / d;\n    result[3][2] = -1;\n    result[3][3] = 0.0;\n\n    return result;\n}\n\n//----------------------------------------------------------------------------\n//\n//  Matrix Functions\n//\n\nfunction transpose( m )\n{\n    if ( !m.matrix ) {\n        return \"transpose(): trying to transpose a non-matrix\";\n    }\n\n    var result = [];\n    for ( var i = 0; i < m.length; ++i ) {\n        result.push( [] );\n        for ( var j = 0; j < m[i].length; ++j ) {\n            result[i].push( m[j][i] );\n        }\n    }\n\n    result.matrix = true;\n\n    return result;\n}\n\n//----------------------------------------------------------------------------\n//\n//  Vector Functions\n//\n\nfunction dot( u, v )\n{\n    if ( u.length != v.length ) {\n        throw \"dot(): vectors are not the same dimension\";\n    }\n\n    var sum = 0.0;\n    for ( var i = 0; i < u.length; ++i ) {\n        sum += u[i] * v[i];\n    }\n\n    return sum;\n}\n\n//----------------------------------------------------------------------------\n\nfunction negate( u )\n{\n    var result = [];\n    for ( var i = 0; i < u.length; ++i ) {\n        result.push( -u[i] );\n    }\n\n    return result;\n}\n\n//----------------------------------------------------------------------------\n\nfunction cross( u, v )\n{\n    if ( !Array.isArray(u) || u.length < 3 ) {\n        throw \"cross(): first argument is not a vector of at least 3\";\n    }\n\n    if ( !Array.isArray(v) || v.length < 3 ) {\n        throw \"cross(): second argument is not a vector of at least 3\";\n    }\n\n    var result = [\n        u[1]*v[2] - u[2]*v[1],\n        u[2]*v[0] - u[0]*v[2],\n        u[0]*v[1] - u[1]*v[0]\n    ];\n\n    return result;\n}\n\n//----------------------------------------------------------------------------\n\nfunction length( u )\n{\n    return Math.sqrt( dot(u, u) );\n}\n\n//----------------------------------------------------------------------------\n\nfunction normalize( u, excludeLastComponent )\n{\n    if ( excludeLastComponent ) {\n        var last = u.pop();\n    }\n\n    var len = length( u );\n\n    if ( !isFinite(len) ) {\n        throw \"normalize: vector \" + u + \" has zero length\";\n    }\n\n    for ( var i = 0; i < u.length; ++i ) {\n        u[i] /= len;\n    }\n\n    if ( excludeLastComponent ) {\n        u.push( last );\n    }\n\n    return u;\n}\n\n//----------------------------------------------------------------------------\n\nfunction mix( u, v, s )\n{\n    if ( typeof s !== \"number\" ) {\n        throw \"mix: the last paramter \" + s + \" must be a number\";\n    }\n\n    if ( u.length != v.length ) {\n        throw \"vector dimension mismatch\";\n    }\n\n    var result = [];\n    for ( var i = 0; i < u.length; ++i ) {\n        result.push( (1.0 - s) * u[i] + s * v[i] );\n    }\n\n    return result;\n}\n\n//----------------------------------------------------------------------------\n//\n// Vector and Matrix functions\n//\n\nfunction scale( s, u )\n{\n    if ( !Array.isArray(u) ) {\n        throw \"scale: second parameter \" + u + \" is not a vector\";\n    }\n\n    var result = [];\n    for ( var i = 0; i < u.length; ++i ) {\n        result.push( s * u[i] );\n    }\n\n    return result;\n}\n\n//----------------------------------------------------------------------------\n//\n//\n//\n\nfunction flatten( v )\n{\n    if ( v.matrix === true ) {\n        v = transpose( v );\n    }\n\n    var n = v.length;\n    var elemsAreArrays = false;\n\n    if ( Array.isArray(v[0]) ) {\n        elemsAreArrays = true;\n        n *= v[0].length;\n    }\n\n    var floats = new Float32Array( n );\n\n    if ( elemsAreArrays ) {\n        var idx = 0;\n        for ( var i = 0; i < v.length; ++i ) {\n            for ( var j = 0; j < v[i].length; ++j ) {\n                floats[idx++] = v[i][j];\n            }\n        }\n    }\n    else {\n        for ( var i = 0; i < v.length; ++i ) {\n            floats[i] = v[i];\n        }\n    }\n\n    return floats;\n}\n\n//----------------------------------------------------------------------------\n\nvar sizeof = {\n    'vec2' : new Float32Array( flatten(vec2()) ).byteLength,\n    'vec3' : new Float32Array( flatten(vec3()) ).byteLength,\n    'vec4' : new Float32Array( flatten(vec4()) ).byteLength,\n    'mat2' : new Float32Array( flatten(mat2()) ).byteLength,\n    'mat3' : new Float32Array( flatten(mat3()) ).byteLength,\n    'mat4' : new Float32Array( flatten(mat4()) ).byteLength\n};\n\n// new functions 5/2/2015\n\n// printing\n\nfunction printm(m)\n{\n    if(m.length == 2)\n    for(var i=0; i<m.length; i++)\n       console.log(m[i][0], m[i][1]);\n    else if(m.length == 3)\n    for(var i=0; i<m.length; i++)\n       console.log(m[i][0], m[i][1], m[i][2]);\n    else if(m.length == 4)\n    for(var i=0; i<m.length; i++)\n       console.log(m[i][0], m[i][1], m[i][2], m[i][3]);\n}\n// determinants\n\nfunction det2(m)\n{\n\n     return m[0][0]*m[1][1]-m[0][1]*m[1][0];\n\n}\n\nfunction det3(m)\n{\n     var d = m[0][0]*m[1][1]*m[2][2]\n           + m[0][1]*m[1][2]*m[2][0]\n           + m[0][2]*m[2][1]*m[1][0]\n           - m[2][0]*m[1][1]*m[0][2]\n           - m[1][0]*m[0][1]*m[2][2]\n           - m[0][0]*m[1][2]*m[2][1]\n           ;\n     return d;\n}\n\nfunction det4(m)\n{\n     var m0 = [\n         vec3(m[1][1], m[1][2], m[1][3]),\n         vec3(m[2][1], m[2][2], m[2][3]),\n         vec3(m[3][1], m[3][2], m[3][3])\n     ];\n     var m1 = [\n         vec3(m[1][0], m[1][2], m[1][3]),\n         vec3(m[2][0], m[2][2], m[2][3]),\n         vec3(m[3][0], m[3][2], m[3][3])\n     ];\n     var m2 = [\n         vec3(m[1][0], m[1][1], m[1][3]),\n         vec3(m[2][0], m[2][1], m[2][3]),\n         vec3(m[3][0], m[3][1], m[3][3])\n     ];\n     var m3 = [\n         vec3(m[1][0], m[1][1], m[1][2]),\n         vec3(m[2][0], m[2][1], m[2][2]),\n         vec3(m[3][0], m[3][1], m[3][2])\n     ];\n     return m[0][0]*det3(m0) - m[0][1]*det3(m1)\n         + m[0][2]*det3(m2) - m[0][3]*det3(m3);\n\n}\n\nfunction det(m)\n{\n     if(m.matrix != true) console.log(\"not a matrix\");\n     if(m.length == 2) return det2(m);\n     if(m.length == 3) return det3(m);\n     if(m.length == 4) return det4(m);\n}\n\n//---------------------------------------------------------\n\n// inverses\n\nfunction inverse2(m)\n{\n     var a = mat2();\n     var d = det2(m);\n     a[0][0] = m[1][1]/d;\n     a[0][1] = -m[0][1]/d;\n     a[1][0] = -m[1][0]/d;\n     a[1][1] = m[0][0]/d;\n     a.matrix = true;\n     return a;\n}\n\nfunction inverse3(m)\n{\n    var a = mat3();\n    var d = det3(m);\n\n    var a00 = [\n       vec2(m[1][1], m[1][2]),\n       vec2(m[2][1], m[2][2])\n    ];\n    var a01 = [\n       vec2(m[1][0], m[1][2]),\n       vec2(m[2][0], m[2][2])\n    ];\n    var a02 = [\n       vec2(m[1][0], m[1][1]),\n       vec2(m[2][0], m[2][1])\n    ];\n    var a10 = [\n       vec2(m[0][1], m[0][2]),\n       vec2(m[2][1], m[2][2])\n    ];\n    var a11 = [\n       vec2(m[0][0], m[0][2]),\n       vec2(m[2][0], m[2][2])\n    ];\n    var a12 = [\n       vec2(m[0][0], m[0][1]),\n       vec2(m[2][0], m[2][1])\n    ];\n    var a20 = [\n       vec2(m[0][1], m[0][2]),\n       vec2(m[1][1], m[1][2])\n    ];\n    var a21 = [\n       vec2(m[0][0], m[0][2]),\n       vec2(m[1][0], m[1][2])\n    ];\n    var a22 = [\n       vec2(m[0][0], m[0][1]),\n       vec2(m[1][0], m[1][1])\n    ];\n\n   a[0][0] = det2(a00)/d;\n   a[0][1] = -det2(a10)/d;\n   a[0][2] = det2(a20)/d;\n   a[1][0] = -det2(a01)/d;\n   a[1][1] = det2(a11)/d;\n   a[1][2] = -det2(a21)/d;\n   a[2][0] = det2(a02)/d;\n   a[2][1] = -det2(a12)/d;\n   a[2][2] = det2(a22)/d;\n\n   return a;\n\n}\n\nfunction inverse4(m)\n{\n    var a = mat4();\n    var d = det4(m);\n\n    var a00 = [\n       vec3(m[1][1], m[1][2], m[1][3]),\n       vec3(m[2][1], m[2][2], m[2][3]),\n       vec3(m[3][1], m[3][2], m[3][3])\n    ];\n    var a01 = [\n       vec3(m[1][0], m[1][2], m[1][3]),\n       vec3(m[2][0], m[2][2], m[2][3]),\n       vec3(m[3][0], m[3][2], m[3][3])\n    ];\n    var a02 = [\n       vec3(m[1][0], m[1][1], m[1][3]),\n       vec3(m[2][0], m[2][1], m[2][3]),\n       vec3(m[3][0], m[3][1], m[3][3])\n    ];\n    var a03 = [\n       vec3(m[1][0], m[1][1], m[1][2]),\n       vec3(m[2][0], m[2][1], m[2][2]),\n       vec3(m[3][0], m[3][1], m[3][2])\n    ];\n    var a10 = [\n       vec3(m[0][1], m[0][2], m[0][3]),\n       vec3(m[2][1], m[2][2], m[2][3]),\n       vec3(m[3][1], m[3][2], m[3][3])\n    ];\n    var a11 = [\n       vec3(m[0][0], m[0][2], m[0][3]),\n       vec3(m[2][0], m[2][2], m[2][3]),\n       vec3(m[3][0], m[3][2], m[3][3])\n    ];\n    var a12 = [\n       vec3(m[0][0], m[0][1], m[0][3]),\n       vec3(m[2][0], m[2][1], m[2][3]),\n       vec3(m[3][0], m[3][1], m[3][3])\n    ];\n    var a13 = [\n       vec3(m[0][0], m[0][1], m[0][2]),\n       vec3(m[2][0], m[2][1], m[2][2]),\n       vec3(m[3][0], m[3][1], m[3][2])\n    ];\n    var a20 = [\n       vec3(m[0][1], m[0][2], m[0][3]),\n       vec3(m[1][1], m[1][2], m[1][3]),\n       vec3(m[3][1], m[3][2], m[3][3])\n    ];\n    var a21 = [\n       vec3(m[0][0], m[0][2], m[0][3]),\n       vec3(m[1][0], m[1][2], m[1][3]),\n       vec3(m[3][0], m[3][2], m[3][3])\n    ];\n    var a22 = [\n       vec3(m[0][0], m[0][1], m[0][3]),\n       vec3(m[1][0], m[1][1], m[1][3]),\n       vec3(m[3][0], m[3][1], m[3][3])\n    ];\n    var a23 = [\n       vec3(m[0][0], m[0][1], m[0][2]),\n       vec3(m[1][0], m[1][1], m[1][2]),\n       vec3(m[3][0], m[3][1], m[3][2])\n    ];\n\n    var a30 = [\n       vec3(m[0][1], m[0][2], m[0][3]),\n       vec3(m[1][1], m[1][2], m[1][3]),\n       vec3(m[2][1], m[2][2], m[2][3])\n    ];\n    var a31 = [\n       vec3(m[0][0], m[0][2], m[0][3]),\n       vec3(m[1][0], m[1][2], m[1][3]),\n       vec3(m[2][0], m[2][2], m[2][3])\n    ];\n    var a32 = [\n       vec3(m[0][0], m[0][1], m[0][3]),\n       vec3(m[1][0], m[1][1], m[1][3]),\n       vec3(m[2][0], m[2][1], m[2][3])\n    ];\n    var a33 = [\n       vec3(m[0][0], m[0][1], m[0][2]),\n       vec3(m[1][0], m[1][1], m[1][2]),\n       vec3(m[2][0], m[2][1], m[2][2])\n    ];\n\n\n\n   a[0][0] = det3(a00)/d;\n   a[0][1] = -det3(a10)/d;\n   a[0][2] = det3(a20)/d;\n   a[0][3] = -det3(a30)/d;\n   a[1][0] = -det3(a01)/d;\n   a[1][1] = det3(a11)/d;\n   a[1][2] = -det3(a21)/d;\n   a[1][3] = det3(a31)/d;\n   a[2][0] = det3(a02)/d;\n   a[2][1] = -det3(a12)/d;\n   a[2][2] = det3(a22)/d;\n   a[2][3] = -det3(a32)/d;\n   a[3][0] = -det3(a03)/d;\n   a[3][1] = det3(a13)/d;\n   a[3][2] = -det3(a23)/d;\n   a[3][3] = det3(a33)/d;\n\n   return a;\n}\nfunction inverse(m)\n{\n   if(m.matrix != true) console.log(\"not a matrix\");\n   if(m.length == 2) return inverse2(m);\n   if(m.length == 3) return inverse3(m);\n   if(m.length == 4) return inverse4(m);\n}\n\nfunction normalMatrix(m, flag)\n{\n    var a = mat4();\n    a = inverse(transpose(m));\n    if(flag != true) return a;\n    else {\n    var b = mat3();\n    for(var i=0;i<3;i++) for(var j=0; j<3; j++) b[i][j] = a[i][j];\n    return b;\n    }\n\n}\n\n\n//# sourceURL=webpack:///./webgl-libs/MV.js?");

/***/ }),

/***/ "./webgl-libs/initShaders.js":
/*!***********************************!*\
  !*** ./webgl-libs/initShaders.js ***!
  \***********************************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("//\n//  initShaders.js\n//\n\nfunction initShaders( gl, vertexShaderId, fragmentShaderId )\n{\n    var vertShdr;\n    var fragShdr;\n\n    var vertElem = document.getElementById( vertexShaderId );\n    if ( !vertElem ) { \n        alert( \"Unable to load vertex shader \" + vertexShaderId );\n        return -1;\n    }\n    else {\n        vertShdr = gl.createShader( gl.VERTEX_SHADER );\n        gl.shaderSource( vertShdr, vertElem.text );\n        gl.compileShader( vertShdr );\n        if ( !gl.getShaderParameter(vertShdr, gl.COMPILE_STATUS) ) {\n            var msg = \"Vertex shader failed to compile.  The error log is:\"\n        \t+ \"<pre>\" + gl.getShaderInfoLog( vertShdr ) + \"</pre>\";\n            alert( msg );\n            return -1;\n        }\n    }\n\n    var fragElem = document.getElementById( fragmentShaderId );\n    if ( !fragElem ) { \n        alert( \"Unable to load vertex shader \" + fragmentShaderId );\n        return -1;\n    }\n    else {\n        fragShdr = gl.createShader( gl.FRAGMENT_SHADER );\n        gl.shaderSource( fragShdr, fragElem.text );\n        gl.compileShader( fragShdr );\n        if ( !gl.getShaderParameter(fragShdr, gl.COMPILE_STATUS) ) {\n            var msg = \"Fragment shader failed to compile.  The error log is:\"\n        \t+ \"<pre>\" + gl.getShaderInfoLog( fragShdr ) + \"</pre>\";\n            alert( msg );\n            return -1;\n        }\n    }\n\n    var program = gl.createProgram();\n    gl.attachShader( program, vertShdr );\n    gl.attachShader( program, fragShdr );\n    gl.linkProgram( program );\n    \n    if ( !gl.getProgramParameter(program, gl.LINK_STATUS) ) {\n        var msg = \"Shader program failed to link.  The error log is:\"\n            + \"<pre>\" + gl.getProgramInfoLog( program ) + \"</pre>\";\n        alert( msg );\n        return -1;\n    }\n\n    return program;\n}\n\n\n//# sourceURL=webpack:///./webgl-libs/initShaders.js?");

/***/ }),

/***/ "./webgl-libs/webgl-utils.js":
/*!***********************************!*\
  !*** ./webgl-libs/webgl-utils.js ***!
  \***********************************/
/*! no static exports found */
/***/ (function(module, exports) {

eval("/*\r\n * Copyright 2010, Google Inc.\r\n * All rights reserved.\r\n *\r\n * Redistribution and use in source and binary forms, with or without\r\n * modification, are permitted provided that the following conditions are\r\n * met:\r\n *\r\n *     * Redistributions of source code must retain the above copyright\r\n * notice, this list of conditions and the following disclaimer.\r\n *     * Redistributions in binary form must reproduce the above\r\n * copyright notice, this list of conditions and the following disclaimer\r\n * in the documentation and/or other materials provided with the\r\n * distribution.\r\n *     * Neither the name of Google Inc. nor the names of its\r\n * contributors may be used to endorse or promote products derived from\r\n * this software without specific prior written permission.\r\n *\r\n * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS\r\n * \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT\r\n * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR\r\n * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT\r\n * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,\r\n * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT\r\n * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,\r\n * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY\r\n * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT\r\n * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE\r\n * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\r\n */\r\n\r\n\r\n/**\r\n * @fileoverview This file contains functions every webgl program will need\r\n * a version of one way or another.\r\n *\r\n * Instead of setting up a context manually it is recommended to\r\n * use. This will check for success or failure. On failure it\r\n * will attempt to present an approriate message to the user.\r\n *\r\n *       gl = WebGLUtils.setupWebGL(canvas);\r\n *\r\n * For animated WebGL apps use of setTimeout or setInterval are\r\n * discouraged. It is recommended you structure your rendering\r\n * loop like this.\r\n *\r\n *       function render() {\r\n *         window.requestAnimFrame(render, canvas);\r\n *\r\n *         // do rendering\r\n *         ...\r\n *       }\r\n *       render();\r\n *\r\n * This will call your rendering function up to the refresh rate\r\n * of your display but will stop rendering if your app is not\r\n * visible.\r\n */\r\n\r\nWebGLUtils = function() {\r\n\r\n/**\r\n * Creates the HTLM for a failure message\r\n * @param {string} canvasContainerId id of container of th\r\n *        canvas.\r\n * @return {string} The html.\r\n */\r\nvar makeFailHTML = function(msg) {\r\n  return '' +\r\n    '<table style=\"background-color: #8CE; width: 100%; height: 100%;\"><tr>' +\r\n    '<td align=\"center\">' +\r\n    '<div style=\"display: table-cell; vertical-align: middle;\">' +\r\n    '<div style=\"\">' + msg + '</div>' +\r\n    '</div>' +\r\n    '</td></tr></table>';\r\n};\r\n\r\n/**\r\n * Mesasge for getting a webgl browser\r\n * @type {string}\r\n */\r\nvar GET_A_WEBGL_BROWSER = '' +\r\n  'This page requires a browser that supports WebGL.<br/>' +\r\n  '<a href=\"http://get.webgl.org\">Click here to upgrade your browser.</a>';\r\n\r\n/**\r\n * Mesasge for need better hardware\r\n * @type {string}\r\n */\r\nvar OTHER_PROBLEM = '' +\r\n  \"It doesn't appear your computer can support WebGL.<br/>\" +\r\n  '<a href=\"http://get.webgl.org/troubleshooting/\">Click here for more information.</a>';\r\n\r\n/**\r\n * Creates a webgl context. If creation fails it will\r\n * change the contents of the container of the <canvas>\r\n * tag to an error message with the correct links for WebGL.\r\n * @param {Element} canvas. The canvas element to create a\r\n *     context from.\r\n * @param {WebGLContextCreationAttirbutes} opt_attribs Any\r\n *     creation attributes you want to pass in.\r\n * @return {WebGLRenderingContext} The created context.\r\n */\r\nvar setupWebGL = function(canvas, opt_attribs) {\r\n  function showLink(str) {\r\n    var container = canvas.parentNode;\r\n    if (container) {\r\n      container.innerHTML = makeFailHTML(str);\r\n    }\r\n  };\r\n\r\n  if (!window.WebGLRenderingContext) {\r\n    showLink(GET_A_WEBGL_BROWSER);\r\n    return null;\r\n  }\r\n\r\n  var context = create3DContext(canvas, opt_attribs);\r\n  if (!context) {\r\n    showLink(OTHER_PROBLEM);\r\n  }\r\n  return context;\r\n};\r\n\r\n/**\r\n * Creates a webgl context.\r\n * @param {!Canvas} canvas The canvas tag to get context\r\n *     from. If one is not passed in one will be created.\r\n * @return {!WebGLContext} The created context.\r\n */\r\nvar create3DContext = function(canvas, opt_attribs) {\r\n  var names = [\"webgl\", \"experimental-webgl\", \"webkit-3d\", \"moz-webgl\"];\r\n  var context = null;\r\n  for (var ii = 0; ii < names.length; ++ii) {\r\n    try {\r\n      context = canvas.getContext(names[ii], opt_attribs);\r\n    } catch(e) {}\r\n    if (context) {\r\n      break;\r\n    }\r\n  }\r\n  return context;\r\n}\r\n\r\nreturn {\r\n  create3DContext: create3DContext,\r\n  setupWebGL: setupWebGL\r\n};\r\n}();\r\n\r\n/**\r\n * Provides requestAnimationFrame in a cross browser way.\r\n */\r\nwindow.requestAnimFrame = (function() {\r\n  return window.requestAnimationFrame ||\r\n         window.webkitRequestAnimationFrame ||\r\n         window.mozRequestAnimationFrame ||\r\n         window.oRequestAnimationFrame ||\r\n         window.msRequestAnimationFrame ||\r\n         function(/* function FrameRequestCallback */ callback, /* DOMElement Element */ element) {\r\n           window.setTimeout(callback, 1000/60);\r\n         };\r\n})();\r\n\r\n\r\n\n\n//# sourceURL=webpack:///./webgl-libs/webgl-utils.js?");

/***/ }),

/***/ 0:
/*!***********************************************************************************************************!*\
  !*** multi ./webgl-libs/webgl-utils.js ./webgl-libs/initShaders.js ./webgl-libs/MV.js ./lab.js ./ello.js ***!
  \***********************************************************************************************************/
/*! no static exports found */
/***/ (function(module, exports, __webpack_require__) {

eval("__webpack_require__(/*! ./webgl-libs/webgl-utils.js */\"./webgl-libs/webgl-utils.js\");\n__webpack_require__(/*! ./webgl-libs/initShaders.js */\"./webgl-libs/initShaders.js\");\n__webpack_require__(/*! ./webgl-libs/MV.js */\"./webgl-libs/MV.js\");\n__webpack_require__(/*! ./lab.js */\"./lab.js\");\nmodule.exports = __webpack_require__(/*! ./ello.js */\"./ello.js\");\n\n\n//# sourceURL=webpack:///multi_./webgl-libs/webgl-utils.js_./webgl-libs/initShaders.js_./webgl-libs/MV.js_./lab.js_./ello.js?");

/***/ })

/******/ });